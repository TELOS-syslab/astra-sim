name: [pytorch|profiler|execution_trace|thread]
id: 6120
duration_micros: 0
attr: [name: "rf_id"
int64_val: 0
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122845905
]
name: aten::to
id: 6121
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122853863
]
name: aten::to
id: 6122
duration_micros: 17
attr: [name: "rf_id"
int64_val: 2
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122853863
]
name: aten::_to_copy
id: 6123
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122853899
]
name: aten::empty_strided
id: 6124
duration_micros: 51
attr: [name: "rf_id"
int64_val: 4
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122853913
]
name: aten::copy_
id: 6125
duration_micros: 25
attr: [name: "rf_id"
int64_val: 5
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122853968
]
name: Memcpy HtoD (Pinned -> Device)
id: 6126
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122853991
]
name: aten::copy_
id: 6127
duration_micros: 25
attr: [name: "rf_id"
int64_val: 5
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122853991
]
name: aten::to
id: 6129
duration_micros: 11
attr: [name: "rf_id"
int64_val: 6
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854047
]
name: aten::_to_copy
id: 6130
duration_micros: 18
attr: [name: "rf_id"
int64_val: 7
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854050
]
name: aten::empty_strided
id: 6131
duration_micros: 19
attr: [name: "rf_id"
int64_val: 8
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854055
]
name: aten::copy_
id: 6132
duration_micros: 17
attr: [name: "rf_id"
int64_val: 9
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854078
]
name: void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#1}::operator()() const::{lambda(unsigned char)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1> >(int, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#1}::operator()() const::{lambda(unsigned char)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1>)
id: 6133
duration_micros: 3
attr: [name: "rf_id"
int64_val: 9
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122854100
]
name: aten::copy_
id: 6134
duration_micros: 17
attr: [name: "rf_id"
int64_val: 9
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854100
]
name: aten::to
id: 6136
duration_micros: 7
attr: [name: "rf_id"
int64_val: 10
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854139
]
name: aten::to
id: 6137
duration_micros: 7
attr: [name: "rf_id"
int64_val: 11
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.dtype_layout(Tensor(a) self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854139
]
name: aten::_to_copy
id: 6138
duration_micros: 56
attr: [name: "rf_id"
int64_val: 12
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854154
]
name: aten::empty_strided
id: 6139
duration_micros: 14
attr: [name: "rf_id"
int64_val: 13
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854159
]
name: aten::copy_
id: 6140
duration_micros: 17
attr: [name: "rf_id"
int64_val: 14
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854176
]
name: Memcpy HtoD (Pinned -> Device)
id: 6141
duration_micros: 6
attr: [name: "rf_id"
int64_val: 14
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122854188
]
name: aten::copy_
id: 6142
duration_micros: 17
attr: [name: "rf_id"
int64_val: 14
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854188
]
name: aten::slice
id: 6144
duration_micros: 23
attr: [name: "rf_id"
int64_val: 15
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854290
]
name: aten::as_strided
id: 6145
duration_micros: 11
attr: [name: "rf_id"
int64_val: 16
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854301
]
name: aten::slice
id: 6146
duration_micros: 13
attr: [name: "rf_id"
int64_val: 17
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854328
]
name: aten::as_strided
id: 6147
duration_micros: 7
attr: [name: "rf_id"
int64_val: 18
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854333
]
name: aten::contiguous
id: 6148
duration_micros: 9
attr: [name: "rf_id"
int64_val: 19
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854356
]
name: aten::clone
id: 6149
duration_micros: 14
attr: [name: "rf_id"
int64_val: 20
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854359
]
name: aten::empty_like
id: 6150
duration_micros: 12
attr: [name: "rf_id"
int64_val: 21
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854364
]
name: aten::empty
id: 6151
duration_micros: 15
attr: [name: "rf_id"
int64_val: 22
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854368
]
name: aten::copy_
id: 6152
duration_micros: 16
attr: [name: "rf_id"
int64_val: 23
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854394
]
name: void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})
id: 6153
duration_micros: 3
attr: [name: "rf_id"
int64_val: 23
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122854416
]
name: aten::copy_
id: 6154
duration_micros: 16
attr: [name: "rf_id"
int64_val: 23
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854416
]
name: aten::slice
id: 6156
duration_micros: 15
attr: [name: "rf_id"
int64_val: 24
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854449
]
name: aten::as_strided
id: 6157
duration_micros: 8
attr: [name: "rf_id"
int64_val: 25
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854455
]
name: aten::slice
id: 6158
duration_micros: 12
attr: [name: "rf_id"
int64_val: 26
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854475
]
name: aten::as_strided
id: 6159
duration_micros: 7
attr: [name: "rf_id"
int64_val: 27
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854479
]
name: aten::contiguous
id: 6160
duration_micros: 8
attr: [name: "rf_id"
int64_val: 28
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854500
]
name: aten::clone
id: 6161
duration_micros: 12
attr: [name: "rf_id"
int64_val: 29
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854502
]
name: aten::empty_like
id: 6162
duration_micros: 14
attr: [name: "rf_id"
int64_val: 30
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854505
]
name: aten::empty
id: 6163
duration_micros: 41
attr: [name: "rf_id"
int64_val: 31
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854508
]
name: aten::copy_
id: 6164
duration_micros: 14
attr: [name: "rf_id"
int64_val: 32
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854564
]
name: void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})
id: 6165
duration_micros: 2
attr: [name: "rf_id"
int64_val: 32
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122854583
]
name: aten::copy_
id: 6166
duration_micros: 14
attr: [name: "rf_id"
int64_val: 32
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854583
]
name: aten::ones
id: 6168
duration_micros: 28
attr: [name: "rf_id"
int64_val: 33
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::ones(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854632
]
name: aten::empty
id: 6169
duration_micros: 17
attr: [name: "rf_id"
int64_val: 34
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854636
]
name: aten::fill_
id: 6170
duration_micros: 12
attr: [name: "rf_id"
int64_val: 35
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854661
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)
id: 6171
duration_micros: 9
attr: [name: "rf_id"
int64_val: 35
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122854676
]
name: aten::fill_
id: 6172
duration_micros: 12
attr: [name: "rf_id"
int64_val: 35
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854676
]
name: aten::tril
id: 6174
duration_micros: 15
attr: [name: "rf_id"
int64_val: 36
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::tril(Tensor self, int diagonal=0) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854710
]
name: void at::native::triu_tril_kernel<float, int, false>(at::cuda::detail::TensorInfo<float, int>, at::cuda::detail::TensorInfo<float, int>, long, long)
id: 6175
duration_micros: 42
attr: [name: "rf_id"
int64_val: 36
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::tril(Tensor self, int diagonal=0) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122854732
]
name: aten::tril
id: 6176
duration_micros: 15
attr: [name: "rf_id"
int64_val: 36
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::tril(Tensor self, int diagonal=0) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854732
]
name: aten::view
id: 6178
duration_micros: 12
attr: [name: "rf_id"
int64_val: 37
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854752
]
name: aten::ones
id: 6179
duration_micros: 16
attr: [name: "rf_id"
int64_val: 38
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::ones(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854773
]
name: aten::empty
id: 6180
duration_micros: 14
attr: [name: "rf_id"
int64_val: 39
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854777
]
name: aten::fill_
id: 6181
duration_micros: 10
attr: [name: "rf_id"
int64_val: 40
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854796
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)
id: 6182
duration_micros: 1
attr: [name: "rf_id"
int64_val: 40
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122854808
]
name: aten::fill_
id: 6183
duration_micros: 10
attr: [name: "rf_id"
int64_val: 40
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::fill_.Scalar(Tensor(a!) self, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854808
]
name: aten::arange
id: 6185
duration_micros: 44
attr: [name: "rf_id"
int64_val: 41
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::arange(Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854834
]
name: aten::empty
id: 6186
duration_micros: 13
attr: [name: "rf_id"
int64_val: 42
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854838
]
name: aten::arange
id: 6187
duration_micros: 28
attr: [name: "rf_id"
int64_val: 43
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854854
]
name: aten::resize_
id: 6188
duration_micros: 8
attr: [name: "rf_id"
int64_val: 44
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854860
]
name: void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)
id: 6189
duration_micros: 1
attr: [name: "rf_id"
int64_val: 44
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122854889
]
name: aten::resize_
id: 6190
duration_micros: 8
attr: [name: "rf_id"
int64_val: 44
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854889
]
name: aten::unsqueeze
id: 6192
duration_micros: 15
attr: [name: "rf_id"
int64_val: 45
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854946
]
name: aten::as_strided
id: 6193
duration_micros: 10
attr: [name: "rf_id"
int64_val: 46
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854953
]
name: aten::expand_as
id: 6194
duration_micros: 12
attr: [name: "rf_id"
int64_val: 47
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854977
]
name: aten::expand
id: 6195
duration_micros: 17
attr: [name: "rf_id"
int64_val: 48
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854983
]
name: aten::as_strided
id: 6196
duration_micros: 8
attr: [name: "rf_id"
int64_val: 49
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122854989
]
name: aten::lt
id: 6197
duration_micros: 23
attr: [name: "rf_id"
int64_val: 50
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855025
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::compare_scalar_kernel<float>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::compare_scalar_kernel<float>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, float)::{lambda(float)#1}, at::detail::Array<char*, 2>)
id: 6198
duration_micros: 8
attr: [name: "rf_id"
int64_val: 50
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122855060
]
name: aten::lt
id: 6199
duration_micros: 23
attr: [name: "rf_id"
int64_val: 50
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855060
]
name: aten::lt
id: 6201
duration_micros: 23
attr: [name: "rf_id"
int64_val: 51
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855025
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::compare_scalar_kernel<float>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, float)::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::compare_scalar_kernel<float>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, float)::{lambda(float)#1}, at::detail::Array<char*, 2>)
id: 6202
duration_micros: 8
attr: [name: "rf_id"
int64_val: 51
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122855060
]
name: aten::lt
id: 6203
duration_micros: 23
attr: [name: "rf_id"
int64_val: 51
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855060
]
name: aten::ge
id: 6205
duration_micros: 13
attr: [name: "rf_id"
int64_val: 52
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::ge.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855245
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::compare_scalar_kernel<long>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, long)::{lambda(long)#1}, at::detail::Array<char*, 2> >(int, at::native::compare_scalar_kernel<long>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, long)::{lambda(long)#1}, at::detail::Array<char*, 2>)
id: 6206
duration_micros: 2
attr: [name: "rf_id"
int64_val: 52
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::ge.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122855262
]
name: aten::ge
id: 6207
duration_micros: 13
attr: [name: "rf_id"
int64_val: 52
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::ge.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855262
]
name: aten::__or__
id: 6209
duration_micros: 9
attr: [name: "rf_id"
int64_val: 53
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::__or__.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855278
]
name: aten::bitwise_or
id: 6210
duration_micros: 13
attr: [name: "rf_id"
int64_val: 54
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bitwise_or.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855282
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<bool, bool, bool, at::native::BitwiseOrFunctor<bool> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<bool, bool, bool, at::native::BitwiseOrFunctor<bool> >, at::detail::Array<char*, 3>)
id: 6211
duration_micros: 1
attr: [name: "rf_id"
int64_val: 54
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bitwise_or.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122855299
]
name: aten::bitwise_or
id: 6212
duration_micros: 13
attr: [name: "rf_id"
int64_val: 54
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bitwise_or.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855299
]
name: aten::any
id: 6214
duration_micros: 36
attr: [name: "rf_id"
int64_val: 55
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::any(Tensor self) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855321
]
name: aten::as_strided
id: 6215
duration_micros: 4
attr: [name: "rf_id"
int64_val: 56
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855333
]
name: void at::native::reduce_kernel<512, 1, at::native::ReduceOp<bool, at::native::func_wrapper_t<bool, at::native::or_kernel_cuda(at::TensorIterator&)::{lambda()#1}::operator()() const::{lambda()#12}::operator()() const::{lambda(bool, bool)#1}>, unsigned int, bool, 4> >(at::native::ReduceOp<bool, at::native::func_wrapper_t<bool, at::native::or_kernel_cuda(at::TensorIterator&)::{lambda()#1}::operator()() const::{lambda()#12}::operator()() const::{lambda(bool, bool)#1}>, unsigned int, bool, 4>)
id: 6216
duration_micros: 5
attr: [name: "rf_id"
int64_val: 56
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122855358
]
name: aten::as_strided
id: 6217
duration_micros: 4
attr: [name: "rf_id"
int64_val: 56
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855358
]
name: aten::is_nonzero
id: 6219
duration_micros: 9
attr: [name: "rf_id"
int64_val: 57
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::is_nonzero(Tensor self) -> bool"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855374
]
name: aten::item
id: 6220
duration_micros: 7
attr: [name: "rf_id"
int64_val: 58
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855379
]
name: aten::_local_scalar_dense
id: 6221
duration_micros: 19
attr: [name: "rf_id"
int64_val: 59
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855382
]
name: Memcpy DtoH (Device -> Pageable)
id: 6222
duration_micros: 2
attr: [name: "rf_id"
int64_val: 59
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122855410
]
name: aten::_local_scalar_dense
id: 6223
duration_micros: 19
attr: [name: "rf_id"
int64_val: 59
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855410
]
name: aten::lt
id: 6225
duration_micros: 15
attr: [name: "rf_id"
int64_val: 60
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855438
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::compare_scalar_kernel<long>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, long)::{lambda(long)#1}, at::detail::Array<char*, 2> >(int, at::native::compare_scalar_kernel<long>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, long)::{lambda(long)#1}, at::detail::Array<char*, 2>)
id: 6226
duration_micros: 2
attr: [name: "rf_id"
int64_val: 60
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122855459
]
name: aten::lt
id: 6227
duration_micros: 15
attr: [name: "rf_id"
int64_val: 60
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855459
]
name: aten::ge
id: 6229
duration_micros: 11
attr: [name: "rf_id"
int64_val: 61
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::ge.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855475
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::compare_scalar_kernel<long>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, long)::{lambda(long)#1}, at::detail::Array<char*, 2> >(int, at::native::compare_scalar_kernel<long>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, long)::{lambda(long)#1}, at::detail::Array<char*, 2>)
id: 6230
duration_micros: 2
attr: [name: "rf_id"
int64_val: 61
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::ge.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122855490
]
name: aten::ge
id: 6231
duration_micros: 11
attr: [name: "rf_id"
int64_val: 61
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::ge.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855490
]
name: aten::__or__
id: 6233
duration_micros: 10
attr: [name: "rf_id"
int64_val: 62
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::__or__.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855504
]
name: aten::bitwise_or
id: 6234
duration_micros: 26
attr: [name: "rf_id"
int64_val: 63
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bitwise_or.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855506
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<bool, bool, bool, at::native::BitwiseOrFunctor<bool> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<bool, bool, bool, at::native::BitwiseOrFunctor<bool> >, at::detail::Array<char*, 3>)
id: 6235
duration_micros: 1
attr: [name: "rf_id"
int64_val: 63
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bitwise_or.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122855520
]
name: aten::bitwise_or
id: 6236
duration_micros: 26
attr: [name: "rf_id"
int64_val: 63
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bitwise_or.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122855520
]
name: aten::clone
id: 6238
duration_micros: 16
attr: [name: "rf_id"
int64_val: 64
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861712
]
name: aten::empty_strided
id: 6239
duration_micros: 21
attr: [name: "rf_id"
int64_val: 65
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861718
]
name: aten::copy_
id: 6240
duration_micros: 17
attr: [name: "rf_id"
int64_val: 66
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861743
]
name: Memcpy DtoD (Device -> Device)
id: 6241
duration_micros: 2
attr: [name: "rf_id"
int64_val: 66
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122861766
]
name: aten::copy_
id: 6242
duration_micros: 17
attr: [name: "rf_id"
int64_val: 66
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861766
]
name: aten::sub
id: 6244
duration_micros: 17
attr: [name: "rf_id"
int64_val: 67
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861796
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)
id: 6245
duration_micros: 2
attr: [name: "rf_id"
int64_val: 67
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122861820
]
name: aten::sub
id: 6246
duration_micros: 17
attr: [name: "rf_id"
int64_val: 67
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861820
]
name: aten::lift_fresh
id: 6248
duration_micros: 6
attr: [name: "rf_id"
int64_val: 68
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861843
]
name: aten::index_put_
id: 6249
duration_micros: 18
attr: [name: "rf_id"
int64_val: 69
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861858
]
name: aten::_index_put_impl_
id: 6250
duration_micros: 19
attr: [name: "rf_id"
int64_val: 70
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861865
]
name: aten::item
id: 6251
duration_micros: 6
attr: [name: "rf_id"
int64_val: 71
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861869
]
name: aten::_local_scalar_dense
id: 6252
duration_micros: 6
attr: [name: "rf_id"
int64_val: 72
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861871
]
name: aten::masked_fill_
id: 6253
duration_micros: 13
attr: [name: "rf_id"
int64_val: 73
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861886
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long, bool)#1}, at::detail::Array<char*, 3>)
id: 6254
duration_micros: 2
attr: [name: "rf_id"
int64_val: 73
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122861902
]
name: aten::masked_fill_
id: 6255
duration_micros: 13
attr: [name: "rf_id"
int64_val: 73
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861902
]
name: aten::index
id: 6257
duration_micros: 46
attr: [name: "rf_id"
int64_val: 74
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::index.Tensor(Tensor self, Tensor?[] indices) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861952
]
name: aten::as_strided
id: 6258
duration_micros: 9
attr: [name: "rf_id"
int64_val: 75
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861961
]
name: aten::reshape
id: 6259
duration_micros: 12
attr: [name: "rf_id"
int64_val: 76
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861974
]
name: aten::view
id: 6260
duration_micros: 4
attr: [name: "rf_id"
int64_val: 77
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122861977
]
name: void at::native::index_elementwise_kernel<128, 4, at::native::gpu_index_kernel<at::native::index_kernel_impl<at::native::OpaqueType<2> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_kernel_impl<at::native::OpaqueType<2> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1} const&)::{lambda(int)#1}>(long, at::native::gpu_index_kernel<at::native::index_kernel_impl<at::native::OpaqueType<2> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_kernel_impl<at::native::OpaqueType<2> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1} const&)::{lambda(int)#1})
id: 6261
duration_micros: 226
attr: [name: "rf_id"
int64_val: 77
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122862017
]
name: aten::view
id: 6262
duration_micros: 4
attr: [name: "rf_id"
int64_val: 77
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862017
]
name: aten::lift_fresh
id: 6264
duration_micros: 36
attr: [name: "rf_id"
int64_val: 78
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862038
]
name: aten::slice
id: 6265
duration_micros: 17
attr: [name: "rf_id"
int64_val: 79
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862084
]
name: aten::as_strided
id: 6266
duration_micros: 10
attr: [name: "rf_id"
int64_val: 80
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862091
]
name: aten::index_put_
id: 6267
duration_micros: 13
attr: [name: "rf_id"
int64_val: 81
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862116
]
name: aten::_index_put_impl_
id: 6268
duration_micros: 20
attr: [name: "rf_id"
int64_val: 82
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862122
]
name: aten::unsqueeze
id: 6269
duration_micros: 11
attr: [name: "rf_id"
int64_val: 83
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862127
]
name: aten::as_strided
id: 6270
duration_micros: 8
attr: [name: "rf_id"
int64_val: 84
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862132
]
name: aten::item
id: 6271
duration_micros: 6
attr: [name: "rf_id"
int64_val: 85
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862148
]
name: aten::_local_scalar_dense
id: 6272
duration_micros: 7
attr: [name: "rf_id"
int64_val: 86
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862150
]
name: aten::masked_fill_
id: 6273
duration_micros: 38
attr: [name: "rf_id"
int64_val: 87
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862165
]
name: aten::expand
id: 6274
duration_micros: 12
attr: [name: "rf_id"
int64_val: 88
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862171
]
name: aten::as_strided
id: 6275
duration_micros: 4
attr: [name: "rf_id"
int64_val: 89
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862177
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1}>(at::TensorIteratorBase&, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#11}::operator()() const::{lambda(c10::Half, bool)#1} const&)::{lambda(int)#1})
id: 6276
duration_micros: 155
attr: [name: "rf_id"
int64_val: 89
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122862211
]
name: aten::as_strided
id: 6277
duration_micros: 4
attr: [name: "rf_id"
int64_val: 89
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862211
]
name: _ReduceFromModelParallelRegion
id: 6279
duration_micros: 91
attr: [name: "rf_id"
int64_val: 90
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1661
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862263
]
name: c10d::allreduce_
id: 6280
duration_micros: 38
attr: [name: "rf_id"
int64_val: 91
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862310
]
name: record_param_comms
id: 6281
duration_micros: 27
attr: [name: "rf_id"
int64_val: 92
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862325
]
name: nccl:all_reduce
id: 6282
duration_micros: 30
attr: [name: "rf_id"
int64_val: 93
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862342
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 6283
duration_micros: 662
attr: [name: "rf_id"
int64_val: 93
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122862366
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 6284
duration_micros: 30
attr: [name: "rf_id"
int64_val: 93
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862366
]
name: record_param_comms
id: 6286
duration_micros: 37
attr: [name: "rf_id"
int64_val: 94
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862449
]
name: aten::view_as
id: 6287
duration_micros: 11
attr: [name: "rf_id"
int64_val: 95
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862510
]
name: aten::view
id: 6288
duration_micros: 13
attr: [name: "rf_id"
int64_val: 96
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862515
]
name: aten::embedding
id: 6289
duration_micros: 23
attr: [name: "rf_id"
int64_val: 97
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::embedding(Tensor weight, Tensor indices, SymInt padding_idx=-1, bool scale_grad_by_freq=False, bool sparse=False) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862577
]
name: aten::reshape
id: 6290
duration_micros: 16
attr: [name: "rf_id"
int64_val: 98
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862583
]
name: aten::clone
id: 6291
duration_micros: 12
attr: [name: "rf_id"
int64_val: 99
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862588
]
name: aten::empty_like
id: 6292
duration_micros: 12
attr: [name: "rf_id"
int64_val: 100
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862592
]
name: aten::empty
id: 6293
duration_micros: 19
attr: [name: "rf_id"
int64_val: 101
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862596
]
name: aten::copy_
id: 6294
duration_micros: 15
attr: [name: "rf_id"
int64_val: 102
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862626
]
name: void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1} const&)::{lambda(int)#1})
id: 6295
duration_micros: 3
attr: [name: "rf_id"
int64_val: 102
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122862646
]
name: aten::copy_
id: 6296
duration_micros: 15
attr: [name: "rf_id"
int64_val: 102
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862646
]
name: aten::_unsafe_view
id: 6298
duration_micros: 12
attr: [name: "rf_id"
int64_val: 103
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862667
]
name: aten::index_select
id: 6299
duration_micros: 35
attr: [name: "rf_id"
int64_val: 104
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::index_select(Tensor self, int dim, Tensor index) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862689
]
name: aten::empty
id: 6300
duration_micros: 16
attr: [name: "rf_id"
int64_val: 105
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862694
]
name: aten::resize_
id: 6301
duration_micros: 6
attr: [name: "rf_id"
int64_val: 106
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862716
]
name: void at::native::(anonymous namespace)::indexSelectLargeIndex<c10::Half, long, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<c10::Half, unsigned int>, at::cuda::detail::TensorInfo<c10::Half, unsigned int>, at::cuda::detail::TensorInfo<long, unsigned int>, int, int, unsigned int, unsigned int, long)
id: 6302
duration_micros: 410
attr: [name: "rf_id"
int64_val: 106
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122862744
]
name: aten::resize_
id: 6303
duration_micros: 6
attr: [name: "rf_id"
int64_val: 106
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862744
]
name: aten::view
id: 6305
duration_micros: 10
attr: [name: "rf_id"
int64_val: 107
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862756
]
name: aten::add
id: 6306
duration_micros: 15
attr: [name: "rf_id"
int64_val: 108
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862784
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<c10::Half>, at::detail::Array<char*, 3>)
id: 6307
duration_micros: 113
attr: [name: "rf_id"
int64_val: 108
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122862804
]
name: aten::add
id: 6308
duration_micros: 15
attr: [name: "rf_id"
int64_val: 108
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862804
]
name: aten::transpose
id: 6310
duration_micros: 18
attr: [name: "rf_id"
int64_val: 109
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862822
]
name: aten::as_strided
id: 6311
duration_micros: 37
attr: [name: "rf_id"
int64_val: 110
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862829
]
name: aten::contiguous
id: 6312
duration_micros: 8
attr: [name: "rf_id"
int64_val: 111
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862886
]
name: aten::clone
id: 6313
duration_micros: 13
attr: [name: "rf_id"
int64_val: 112
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862888
]
name: aten::empty_like
id: 6314
duration_micros: 12
attr: [name: "rf_id"
int64_val: 113
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862892
]
name: aten::empty
id: 6315
duration_micros: 16
attr: [name: "rf_id"
int64_val: 114
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862897
]
name: aten::copy_
id: 6316
duration_micros: 14
attr: [name: "rf_id"
int64_val: 115
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862923
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 6317
duration_micros: 149
attr: [name: "rf_id"
int64_val: 115
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122862941
]
name: aten::copy_
id: 6318
duration_micros: 14
attr: [name: "rf_id"
int64_val: 115
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862941
]
name: aten::dropout
id: 6320
duration_micros: 7
attr: [name: "rf_id"
int64_val: 116
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122862998
]
name: FusedLayerNormAffineFunction
id: 6321
duration_micros: 55
attr: [name: "rf_id"
int64_val: 117
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1662
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863117
]
name: aten::empty_like
id: 6322
duration_micros: 15
attr: [name: "rf_id"
int64_val: 118
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863132
]
name: aten::empty_strided
id: 6323
duration_micros: 24
attr: [name: "rf_id"
int64_val: 119
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863139
]
name: aten::empty
id: 6324
duration_micros: 13
attr: [name: "rf_id"
int64_val: 120
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863174
]
name: aten::empty_like
id: 6325
duration_micros: 87
attr: [name: "rf_id"
int64_val: 121
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863190
]
name: aten::empty_strided
id: 6326
duration_micros: 5
attr: [name: "rf_id"
int64_val: 122
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863194
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 6327
duration_micros: 140
attr: [name: "rf_id"
int64_val: 122
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122863305
]
name: aten::empty_strided
id: 6328
duration_micros: 5
attr: [name: "rf_id"
int64_val: 122
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863305
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6330
duration_micros: 41
attr: [name: "rf_id"
int64_val: 123
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1663
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863387
]
name: aten::t
id: 6331
duration_micros: 13
attr: [name: "rf_id"
int64_val: 124
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863399
]
name: aten::transpose
id: 6332
duration_micros: 67
attr: [name: "rf_id"
int64_val: 125
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863403
]
name: aten::as_strided
id: 6333
duration_micros: 11
attr: [name: "rf_id"
int64_val: 126
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863409
]
name: aten::matmul
id: 6334
duration_micros: 21
attr: [name: "rf_id"
int64_val: 127
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863498
]
name: aten::reshape
id: 6335
duration_micros: 9
attr: [name: "rf_id"
int64_val: 128
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863504
]
name: aten::view
id: 6336
duration_micros: 9
attr: [name: "rf_id"
int64_val: 129
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863507
]
name: aten::mm
id: 6337
duration_micros: 37
attr: [name: "rf_id"
int64_val: 130
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863525
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 6338
duration_micros: 400
attr: [name: "rf_id"
int64_val: 130
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122863587
]
name: aten::mm
id: 6339
duration_micros: 37
attr: [name: "rf_id"
int64_val: 130
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863587
]
name: aten::_unsafe_view
id: 6341
duration_micros: 7
attr: [name: "rf_id"
int64_val: 131
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863606
]
name: aten::add
id: 6342
duration_micros: 16
attr: [name: "rf_id"
int64_val: 132
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863629
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 6343
duration_micros: 54
attr: [name: "rf_id"
int64_val: 132
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122863651
]
name: aten::add
id: 6344
duration_micros: 16
attr: [name: "rf_id"
int64_val: 132
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863651
]
name: aten::view
id: 6346
duration_micros: 10
attr: [name: "rf_id"
int64_val: 133
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863690
]
name: aten::split_with_sizes
id: 6347
duration_micros: 35
attr: [name: "rf_id"
int64_val: 134
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863719
]
name: aten::as_strided
id: 6348
duration_micros: 9
attr: [name: "rf_id"
int64_val: 135
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863727
]
name: aten::as_strided
id: 6349
duration_micros: 9
attr: [name: "rf_id"
int64_val: 136
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863727
]
name: aten::as_strided
id: 6350
duration_micros: 7
attr: [name: "rf_id"
int64_val: 137
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863741
]
name: aten::view
id: 6351
duration_micros: 7
attr: [name: "rf_id"
int64_val: 138
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863785
]
name: aten::reshape
id: 6352
duration_micros: 20
attr: [name: "rf_id"
int64_val: 139
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863811
]
name: aten::_reshape_alias
id: 6353
duration_micros: 42
attr: [name: "rf_id"
int64_val: 140
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863822
]
name: aten::view
id: 6354
duration_micros: 8
attr: [name: "rf_id"
int64_val: 141
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863882
]
name: aten::slice
id: 6355
duration_micros: 16
attr: [name: "rf_id"
int64_val: 142
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863925
]
name: aten::as_strided
id: 6356
duration_micros: 10
attr: [name: "rf_id"
int64_val: 143
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863931
]
name: aten::view
id: 6357
duration_micros: 7
attr: [name: "rf_id"
int64_val: 144
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863960
]
name: aten::transpose
id: 6358
duration_micros: 13
attr: [name: "rf_id"
int64_val: 145
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863974
]
name: aten::as_strided
id: 6359
duration_micros: 7
attr: [name: "rf_id"
int64_val: 146
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863980
]
name: aten::transpose
id: 6360
duration_micros: 10
attr: [name: "rf_id"
int64_val: 147
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122863998
]
name: aten::as_strided
id: 6361
duration_micros: 7
attr: [name: "rf_id"
int64_val: 148
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864002
]
name: aten::transpose
id: 6362
duration_micros: 10
attr: [name: "rf_id"
int64_val: 149
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864018
]
name: aten::as_strided
id: 6363
duration_micros: 7
attr: [name: "rf_id"
int64_val: 150
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864023
]
name: aten::baddbmm
id: 6364
duration_micros: 34
attr: [name: "rf_id"
int64_val: 151
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864049
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 6365
duration_micros: 294
attr: [name: "rf_id"
int64_val: 151
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122864103
]
name: aten::baddbmm
id: 6366
duration_micros: 34
attr: [name: "rf_id"
int64_val: 151
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864103
]
name: aten::view
id: 6368
duration_micros: 9
attr: [name: "rf_id"
int64_val: 152
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864129
]
name: aten::view
id: 6369
duration_micros: 9
attr: [name: "rf_id"
int64_val: 153
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864129
]
name: ScaledUpperTriangMaskedSoftmax
id: 6370
duration_micros: 77
attr: [name: "rf_id"
int64_val: 154
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1664
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864190
]
name: aten::empty
id: 6371
duration_micros: 43
attr: [name: "rf_id"
int64_val: 155
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864205
]
name: aten::to
id: 6372
duration_micros: 9
attr: [name: "rf_id"
int64_val: 156
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864256
]
name: aten::lift_fresh
id: 6373
duration_micros: 5
attr: [name: "rf_id"
int64_val: 157
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864268
]
name: aten::detach_
id: 6374
duration_micros: 7
attr: [name: "rf_id"
int64_val: 158
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864276
]
name: detach_
id: 6375
duration_micros: 2
attr: [name: "rf_id"
int64_val: 159
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864278
]
name: aten::select
id: 6376
duration_micros: 15
attr: [name: "rf_id"
int64_val: 160
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864291
]
name: aten::as_strided
id: 6377
duration_micros: 11
attr: [name: "rf_id"
int64_val: 161
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864298
]
name: aten::item
id: 6378
duration_micros: 7
attr: [name: "rf_id"
int64_val: 162
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864323
]
name: aten::_local_scalar_dense
id: 6379
duration_micros: 7
attr: [name: "rf_id"
int64_val: 163
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864326
]
name: aten::empty
id: 6380
duration_micros: 9
attr: [name: "rf_id"
int64_val: 164
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864342
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 6381
duration_micros: 426
attr: [name: "rf_id"
int64_val: 164
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122864378
]
name: aten::empty
id: 6382
duration_micros: 9
attr: [name: "rf_id"
int64_val: 164
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864378
]
name: aten::view
id: 6384
duration_micros: 10
attr: [name: "rf_id"
int64_val: 165
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864402
]
name: aten::dropout
id: 6385
duration_micros: 7
attr: [name: "rf_id"
int64_val: 166
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864477
]
name: aten::view
id: 6386
duration_micros: 10
attr: [name: "rf_id"
int64_val: 167
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864518
]
name: aten::view
id: 6387
duration_micros: 10
attr: [name: "rf_id"
int64_val: 168
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864518
]
name: aten::transpose
id: 6388
duration_micros: 13
attr: [name: "rf_id"
int64_val: 169
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864545
]
name: aten::as_strided
id: 6389
duration_micros: 8
attr: [name: "rf_id"
int64_val: 170
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864551
]
name: aten::bmm
id: 6390
duration_micros: 36
attr: [name: "rf_id"
int64_val: 171
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864571
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 6391
duration_micros: 184
attr: [name: "rf_id"
int64_val: 171
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122864605
]
name: aten::bmm
id: 6392
duration_micros: 36
attr: [name: "rf_id"
int64_val: 171
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864605
]
name: aten::view
id: 6394
duration_micros: 11
attr: [name: "rf_id"
int64_val: 172
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864659
]
name: aten::permute
id: 6395
duration_micros: 14
attr: [name: "rf_id"
int64_val: 173
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864678
]
name: aten::as_strided
id: 6396
duration_micros: 8
attr: [name: "rf_id"
int64_val: 174
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864685
]
name: aten::contiguous
id: 6397
duration_micros: 8
attr: [name: "rf_id"
int64_val: 175
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864707
]
name: aten::clone
id: 6398
duration_micros: 13
attr: [name: "rf_id"
int64_val: 176
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864709
]
name: aten::empty_like
id: 6399
duration_micros: 12
attr: [name: "rf_id"
int64_val: 177
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864713
]
name: aten::empty
id: 6400
duration_micros: 16
attr: [name: "rf_id"
int64_val: 178
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864717
]
name: aten::copy_
id: 6401
duration_micros: 15
attr: [name: "rf_id"
int64_val: 179
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864744
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 6402
duration_micros: 20
attr: [name: "rf_id"
int64_val: 179
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122864763
]
name: aten::copy_
id: 6403
duration_micros: 15
attr: [name: "rf_id"
int64_val: 179
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864763
]
name: aten::view
id: 6405
duration_micros: 9
attr: [name: "rf_id"
int64_val: 180
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864802
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6406
duration_micros: 27
attr: [name: "rf_id"
int64_val: 181
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1665
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864855
]
name: aten::t
id: 6407
duration_micros: 9
attr: [name: "rf_id"
int64_val: 182
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864865
]
name: aten::transpose
id: 6408
duration_micros: 12
attr: [name: "rf_id"
int64_val: 183
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864868
]
name: aten::as_strided
id: 6409
duration_micros: 10
attr: [name: "rf_id"
int64_val: 184
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864874
]
name: aten::matmul
id: 6410
duration_micros: 21
attr: [name: "rf_id"
int64_val: 185
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864901
]
name: aten::reshape
id: 6411
duration_micros: 8
attr: [name: "rf_id"
int64_val: 186
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864905
]
name: aten::view
id: 6412
duration_micros: 7
attr: [name: "rf_id"
int64_val: 187
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864908
]
name: aten::mm
id: 6413
duration_micros: 27
attr: [name: "rf_id"
int64_val: 188
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864923
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 6414
duration_micros: 159
attr: [name: "rf_id"
int64_val: 188
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122864967
]
name: aten::mm
id: 6415
duration_micros: 27
attr: [name: "rf_id"
int64_val: 188
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864967
]
name: aten::_unsafe_view
id: 6417
duration_micros: 36
attr: [name: "rf_id"
int64_val: 189
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122864984
]
name: _ReduceFromModelParallelRegion
id: 6418
duration_micros: 68
attr: [name: "rf_id"
int64_val: 190
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1666
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865054
]
name: c10d::allreduce_
id: 6419
duration_micros: 28
attr: [name: "rf_id"
int64_val: 191
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865086
]
name: record_param_comms
id: 6420
duration_micros: 31
attr: [name: "rf_id"
int64_val: 192
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865098
]
name: nccl:all_reduce
id: 6421
duration_micros: 27
attr: [name: "rf_id"
int64_val: 193
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865116
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 6422
duration_micros: 4288
attr: [name: "rf_id"
int64_val: 193
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122865136
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 6423
duration_micros: 27
attr: [name: "rf_id"
int64_val: 193
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865136
]
name: record_param_comms
id: 6425
duration_micros: 6
attr: [name: "rf_id"
int64_val: 194
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865212
]
name: aten::view_as
id: 6426
duration_micros: 9
attr: [name: "rf_id"
int64_val: 195
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865235
]
name: aten::view
id: 6427
duration_micros: 11
attr: [name: "rf_id"
int64_val: 196
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865239
]
name: aten::expand_as
id: 6428
duration_micros: 10
attr: [name: "rf_id"
int64_val: 197
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865283
]
name: aten::expand
id: 6429
duration_micros: 15
attr: [name: "rf_id"
int64_val: 198
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865288
]
name: aten::as_strided
id: 6430
duration_micros: 9
attr: [name: "rf_id"
int64_val: 199
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865295
]
name: TorchDynamo Cache Lookup
id: 6431
duration_micros: 17
attr: [name: "rf_id"
int64_val: 200
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865353
]
name: Torch-Compiled Region
id: 6432
duration_micros: 104
attr: [name: "rf_id"
int64_val: 201
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865371
]
name: aten::empty
id: 6433
duration_micros: 19
attr: [name: "rf_id"
int64_val: 202
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865431
]
name: triton_poi_fused_add_0
id: 6434
duration_micros: 21
attr: [name: "rf_id"
int64_val: 203
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865472
]
name: triton__0d1d2d3d4de
id: 6435
duration_micros: 114
attr: [name: "rf_id"
int64_val: 203
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122865498
]
name: triton_poi_fused_add_0
id: 6436
duration_micros: 21
attr: [name: "rf_id"
int64_val: 203
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865498
]
name: FusedLayerNormAffineFunction
id: 6438
duration_micros: 50
attr: [name: "rf_id"
int64_val: 204
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1667
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865582
]
name: aten::empty_like
id: 6439
duration_micros: 17
attr: [name: "rf_id"
int64_val: 205
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865595
]
name: aten::empty_strided
id: 6440
duration_micros: 8107
attr: [name: "rf_id"
int64_val: 206
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122865601
]
name: aten::empty
id: 6441
duration_micros: 16
attr: [name: "rf_id"
int64_val: 207
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873724
]
name: aten::empty_like
id: 6442
duration_micros: 11
attr: [name: "rf_id"
int64_val: 208
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873744
]
name: aten::empty_strided
id: 6443
duration_micros: 6
attr: [name: "rf_id"
int64_val: 209
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873748
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 6444
duration_micros: 140
attr: [name: "rf_id"
int64_val: 209
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122873782
]
name: aten::empty_strided
id: 6445
duration_micros: 6
attr: [name: "rf_id"
int64_val: 209
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873782
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6447
duration_micros: 27
attr: [name: "rf_id"
int64_val: 210
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1668
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873851
]
name: aten::t
id: 6448
duration_micros: 9
attr: [name: "rf_id"
int64_val: 211
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873862
]
name: aten::transpose
id: 6449
duration_micros: 13
attr: [name: "rf_id"
int64_val: 212
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873865
]
name: aten::as_strided
id: 6450
duration_micros: 11
attr: [name: "rf_id"
int64_val: 213
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873872
]
name: aten::matmul
id: 6451
duration_micros: 20
attr: [name: "rf_id"
int64_val: 214
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873900
]
name: aten::reshape
id: 6452
duration_micros: 16
attr: [name: "rf_id"
int64_val: 215
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873904
]
name: aten::view
id: 6453
duration_micros: 8
attr: [name: "rf_id"
int64_val: 216
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873914
]
name: aten::mm
id: 6454
duration_micros: 39
attr: [name: "rf_id"
int64_val: 217
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873931
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 6455
duration_micros: 525
attr: [name: "rf_id"
int64_val: 217
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122873996
]
name: aten::mm
id: 6456
duration_micros: 39
attr: [name: "rf_id"
int64_val: 217
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122873996
]
name: aten::_unsafe_view
id: 6458
duration_micros: 8
attr: [name: "rf_id"
int64_val: 218
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874016
]
name: GeLUFunction
id: 6459
duration_micros: 42
attr: [name: "rf_id"
int64_val: 219
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1669
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874063
]
name: TorchDynamo Cache Lookup
id: 6460
duration_micros: 14
attr: [name: "rf_id"
int64_val: 220
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874094
]
name: Torch-Compiled Region
id: 6461
duration_micros: 93
attr: [name: "rf_id"
int64_val: 221
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874109
]
name: aten::empty
id: 6462
duration_micros: 51
attr: [name: "rf_id"
int64_val: 222
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874159
]
name: triton_poi_fused_add_mul_tanh_0
id: 6463
duration_micros: 20
attr: [name: "rf_id"
int64_val: 223
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874231
]
name: triton__0d1d2d3de
id: 6464
duration_micros: 43
attr: [name: "rf_id"
int64_val: 223
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122874255
]
name: triton_poi_fused_add_mul_tanh_0
id: 6465
duration_micros: 20
attr: [name: "rf_id"
int64_val: 223
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874255
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6467
duration_micros: 25
attr: [name: "rf_id"
int64_val: 224
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1670
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874344
]
name: aten::t
id: 6468
duration_micros: 9
attr: [name: "rf_id"
int64_val: 225
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874354
]
name: aten::transpose
id: 6469
duration_micros: 14
attr: [name: "rf_id"
int64_val: 226
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874357
]
name: aten::as_strided
id: 6470
duration_micros: 13
attr: [name: "rf_id"
int64_val: 227
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874364
]
name: aten::matmul
id: 6471
duration_micros: 19
attr: [name: "rf_id"
int64_val: 228
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874395
]
name: aten::reshape
id: 6472
duration_micros: 8
attr: [name: "rf_id"
int64_val: 229
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874399
]
name: aten::view
id: 6473
duration_micros: 9
attr: [name: "rf_id"
int64_val: 230
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874402
]
name: aten::mm
id: 6474
duration_micros: 33
attr: [name: "rf_id"
int64_val: 231
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874419
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 6475
duration_micros: 567
attr: [name: "rf_id"
int64_val: 231
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122874474
]
name: aten::mm
id: 6476
duration_micros: 33
attr: [name: "rf_id"
int64_val: 231
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874474
]
name: aten::_unsafe_view
id: 6478
duration_micros: 7
attr: [name: "rf_id"
int64_val: 232
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874492
]
name: _ReduceFromModelParallelRegion
id: 6479
duration_micros: 76
attr: [name: "rf_id"
int64_val: 233
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1671
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874528
]
name: c10d::allreduce_
id: 6480
duration_micros: 28
attr: [name: "rf_id"
int64_val: 234
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874563
]
name: record_param_comms
id: 6481
duration_micros: 31
attr: [name: "rf_id"
int64_val: 235
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874575
]
name: nccl:all_reduce
id: 6482
duration_micros: 27
attr: [name: "rf_id"
int64_val: 236
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874594
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 6483
duration_micros: 650
attr: [name: "rf_id"
int64_val: 236
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122874614
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 6484
duration_micros: 27
attr: [name: "rf_id"
int64_val: 236
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874614
]
name: record_param_comms
id: 6486
duration_micros: 6
attr: [name: "rf_id"
int64_val: 237
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874687
]
name: aten::view_as
id: 6487
duration_micros: 42
attr: [name: "rf_id"
int64_val: 238
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874714
]
name: aten::view
id: 6488
duration_micros: 12
attr: [name: "rf_id"
int64_val: 239
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874718
]
name: aten::expand_as
id: 6489
duration_micros: 10
attr: [name: "rf_id"
int64_val: 240
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874796
]
name: aten::expand
id: 6490
duration_micros: 15
attr: [name: "rf_id"
int64_val: 241
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874801
]
name: aten::as_strided
id: 6491
duration_micros: 10
attr: [name: "rf_id"
int64_val: 242
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874808
]
name: TorchDynamo Cache Lookup
id: 6492
duration_micros: 13
attr: [name: "rf_id"
int64_val: 243
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874856
]
name: Torch-Compiled Region
id: 6493
duration_micros: 75
attr: [name: "rf_id"
int64_val: 244
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874870
]
name: aten::empty
id: 6494
duration_micros: 18
attr: [name: "rf_id"
int64_val: 245
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874913
]
name: triton_poi_fused_add_0
id: 6495
duration_micros: 18
attr: [name: "rf_id"
int64_val: 246
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874944
]
name: triton__0d1d2d3d4de
id: 6496
duration_micros: 113
attr: [name: "rf_id"
int64_val: 246
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122874964
]
name: triton_poi_fused_add_0
id: 6497
duration_micros: 18
attr: [name: "rf_id"
int64_val: 246
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122874964
]
name: FusedLayerNormAffineFunction
id: 6499
duration_micros: 51
attr: [name: "rf_id"
int64_val: 247
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1672
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875080
]
name: aten::empty_like
id: 6500
duration_micros: 15
attr: [name: "rf_id"
int64_val: 248
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875093
]
name: aten::empty_strided
id: 6501
duration_micros: 20
attr: [name: "rf_id"
int64_val: 249
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875100
]
name: aten::empty
id: 6502
duration_micros: 13
attr: [name: "rf_id"
int64_val: 250
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875133
]
name: aten::empty_like
id: 6503
duration_micros: 11
attr: [name: "rf_id"
int64_val: 251
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875149
]
name: aten::empty_strided
id: 6504
duration_micros: 6
attr: [name: "rf_id"
int64_val: 252
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875153
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 6505
duration_micros: 137
attr: [name: "rf_id"
int64_val: 252
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122875187
]
name: aten::empty_strided
id: 6506
duration_micros: 6
attr: [name: "rf_id"
int64_val: 252
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875187
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6508
duration_micros: 36
attr: [name: "rf_id"
int64_val: 253
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1673
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875254
]
name: aten::t
id: 6509
duration_micros: 13
attr: [name: "rf_id"
int64_val: 254
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875263
]
name: aten::transpose
id: 6510
duration_micros: 46
attr: [name: "rf_id"
int64_val: 255
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875266
]
name: aten::as_strided
id: 6511
duration_micros: 10
attr: [name: "rf_id"
int64_val: 256
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875273
]
name: aten::matmul
id: 6512
duration_micros: 20
attr: [name: "rf_id"
int64_val: 257
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875338
]
name: aten::reshape
id: 6513
duration_micros: 9
attr: [name: "rf_id"
int64_val: 258
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875343
]
name: aten::view
id: 6514
duration_micros: 9
attr: [name: "rf_id"
int64_val: 259
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875347
]
name: aten::mm
id: 6515
duration_micros: 31
attr: [name: "rf_id"
int64_val: 260
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875364
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 6516
duration_micros: 400
attr: [name: "rf_id"
int64_val: 260
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122875414
]
name: aten::mm
id: 6517
duration_micros: 31
attr: [name: "rf_id"
int64_val: 260
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875414
]
name: aten::_unsafe_view
id: 6519
duration_micros: 7
attr: [name: "rf_id"
int64_val: 261
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875433
]
name: aten::add
id: 6520
duration_micros: 17
attr: [name: "rf_id"
int64_val: 262
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875454
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 6521
duration_micros: 54
attr: [name: "rf_id"
int64_val: 262
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122875477
]
name: aten::add
id: 6522
duration_micros: 17
attr: [name: "rf_id"
int64_val: 262
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875477
]
name: aten::view
id: 6524
duration_micros: 10
attr: [name: "rf_id"
int64_val: 263
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875515
]
name: aten::split_with_sizes
id: 6525
duration_micros: 31
attr: [name: "rf_id"
int64_val: 264
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875543
]
name: aten::as_strided
id: 6526
duration_micros: 9
attr: [name: "rf_id"
int64_val: 265
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875550
]
name: aten::as_strided
id: 6527
duration_micros: 9
attr: [name: "rf_id"
int64_val: 266
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875550
]
name: aten::as_strided
id: 6528
duration_micros: 8
attr: [name: "rf_id"
int64_val: 267
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875567
]
name: aten::view
id: 6529
duration_micros: 8
attr: [name: "rf_id"
int64_val: 268
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875606
]
name: aten::reshape
id: 6530
duration_micros: 16
attr: [name: "rf_id"
int64_val: 269
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875631
]
name: aten::_reshape_alias
id: 6531
duration_micros: 39
attr: [name: "rf_id"
int64_val: 270
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875639
]
name: aten::view
id: 6532
duration_micros: 8
attr: [name: "rf_id"
int64_val: 271
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875695
]
name: aten::slice
id: 6533
duration_micros: 8331
attr: [name: "rf_id"
int64_val: 272
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122875719
]
name: aten::as_strided
id: 6534
duration_micros: 13
attr: [name: "rf_id"
int64_val: 273
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884039
]
name: aten::view
id: 6535
duration_micros: 9
attr: [name: "rf_id"
int64_val: 274
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884075
]
name: aten::transpose
id: 6536
duration_micros: 13
attr: [name: "rf_id"
int64_val: 275
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884091
]
name: aten::as_strided
id: 6537
duration_micros: 11
attr: [name: "rf_id"
int64_val: 276
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884097
]
name: aten::transpose
id: 6538
duration_micros: 11
attr: [name: "rf_id"
int64_val: 277
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884119
]
name: aten::as_strided
id: 6539
duration_micros: 7
attr: [name: "rf_id"
int64_val: 278
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884124
]
name: aten::transpose
id: 6540
duration_micros: 9
attr: [name: "rf_id"
int64_val: 279
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884140
]
name: aten::as_strided
id: 6541
duration_micros: 7
attr: [name: "rf_id"
int64_val: 280
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884144
]
name: aten::baddbmm
id: 6542
duration_micros: 36
attr: [name: "rf_id"
int64_val: 281
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884169
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 6543
duration_micros: 295
attr: [name: "rf_id"
int64_val: 281
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122884228
]
name: aten::baddbmm
id: 6544
duration_micros: 36
attr: [name: "rf_id"
int64_val: 281
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884228
]
name: aten::view
id: 6546
duration_micros: 9
attr: [name: "rf_id"
int64_val: 282
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884254
]
name: aten::view
id: 6547
duration_micros: 9
attr: [name: "rf_id"
int64_val: 283
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884254
]
name: ScaledUpperTriangMaskedSoftmax
id: 6548
duration_micros: 73
attr: [name: "rf_id"
int64_val: 284
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1674
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884312
]
name: aten::empty
id: 6549
duration_micros: 44
attr: [name: "rf_id"
int64_val: 285
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884326
]
name: aten::to
id: 6550
duration_micros: 10
attr: [name: "rf_id"
int64_val: 286
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884378
]
name: aten::lift_fresh
id: 6551
duration_micros: 6
attr: [name: "rf_id"
int64_val: 287
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884390
]
name: aten::detach_
id: 6552
duration_micros: 8
attr: [name: "rf_id"
int64_val: 288
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884398
]
name: detach_
id: 6553
duration_micros: 4
attr: [name: "rf_id"
int64_val: 289
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884400
]
name: aten::select
id: 6554
duration_micros: 13
attr: [name: "rf_id"
int64_val: 290
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884416
]
name: aten::as_strided
id: 6555
duration_micros: 9
attr: [name: "rf_id"
int64_val: 291
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884422
]
name: aten::item
id: 6556
duration_micros: 6
attr: [name: "rf_id"
int64_val: 292
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884443
]
name: aten::_local_scalar_dense
id: 6557
duration_micros: 8
attr: [name: "rf_id"
int64_val: 293
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884445
]
name: aten::empty
id: 6558
duration_micros: 9
attr: [name: "rf_id"
int64_val: 294
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884462
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 6559
duration_micros: 426
attr: [name: "rf_id"
int64_val: 294
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122884498
]
name: aten::empty
id: 6560
duration_micros: 9
attr: [name: "rf_id"
int64_val: 294
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884498
]
name: aten::view
id: 6562
duration_micros: 10
attr: [name: "rf_id"
int64_val: 295
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884521
]
name: aten::dropout
id: 6563
duration_micros: 8
attr: [name: "rf_id"
int64_val: 296
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884585
]
name: aten::view
id: 6564
duration_micros: 10
attr: [name: "rf_id"
int64_val: 297
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884624
]
name: aten::view
id: 6565
duration_micros: 10
attr: [name: "rf_id"
int64_val: 298
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884624
]
name: aten::transpose
id: 6566
duration_micros: 13
attr: [name: "rf_id"
int64_val: 299
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884651
]
name: aten::as_strided
id: 6567
duration_micros: 7
attr: [name: "rf_id"
int64_val: 300
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884657
]
name: aten::bmm
id: 6568
duration_micros: 36
attr: [name: "rf_id"
int64_val: 301
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884676
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 6569
duration_micros: 185
attr: [name: "rf_id"
int64_val: 301
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122884710
]
name: aten::bmm
id: 6570
duration_micros: 36
attr: [name: "rf_id"
int64_val: 301
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884710
]
name: aten::view
id: 6572
duration_micros: 10
attr: [name: "rf_id"
int64_val: 302
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884764
]
name: aten::permute
id: 6573
duration_micros: 14
attr: [name: "rf_id"
int64_val: 303
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884784
]
name: aten::as_strided
id: 6574
duration_micros: 8
attr: [name: "rf_id"
int64_val: 304
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884791
]
name: aten::contiguous
id: 6575
duration_micros: 8
attr: [name: "rf_id"
int64_val: 305
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884813
]
name: aten::clone
id: 6576
duration_micros: 14
attr: [name: "rf_id"
int64_val: 306
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884815
]
name: aten::empty_like
id: 6577
duration_micros: 11
attr: [name: "rf_id"
int64_val: 307
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884819
]
name: aten::empty
id: 6578
duration_micros: 16
attr: [name: "rf_id"
int64_val: 308
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884823
]
name: aten::copy_
id: 6579
duration_micros: 15
attr: [name: "rf_id"
int64_val: 309
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884850
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 6580
duration_micros: 21
attr: [name: "rf_id"
int64_val: 309
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122884870
]
name: aten::copy_
id: 6581
duration_micros: 15
attr: [name: "rf_id"
int64_val: 309
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884870
]
name: aten::view
id: 6583
duration_micros: 9
attr: [name: "rf_id"
int64_val: 310
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884908
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6584
duration_micros: 25
attr: [name: "rf_id"
int64_val: 311
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1675
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884958
]
name: aten::t
id: 6585
duration_micros: 9
attr: [name: "rf_id"
int64_val: 312
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884967
]
name: aten::transpose
id: 6586
duration_micros: 12
attr: [name: "rf_id"
int64_val: 313
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884970
]
name: aten::as_strided
id: 6587
duration_micros: 10
attr: [name: "rf_id"
int64_val: 314
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122884976
]
name: aten::matmul
id: 6588
duration_micros: 21
attr: [name: "rf_id"
int64_val: 315
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885002
]
name: aten::reshape
id: 6589
duration_micros: 8
attr: [name: "rf_id"
int64_val: 316
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885006
]
name: aten::view
id: 6590
duration_micros: 10
attr: [name: "rf_id"
int64_val: 317
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885009
]
name: aten::mm
id: 6591
duration_micros: 26
attr: [name: "rf_id"
int64_val: 318
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885027
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 6592
duration_micros: 161
attr: [name: "rf_id"
int64_val: 318
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122885069
]
name: aten::mm
id: 6593
duration_micros: 26
attr: [name: "rf_id"
int64_val: 318
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885069
]
name: aten::_unsafe_view
id: 6595
duration_micros: 37
attr: [name: "rf_id"
int64_val: 319
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885086
]
name: _ReduceFromModelParallelRegion
id: 6596
duration_micros: 64
attr: [name: "rf_id"
int64_val: 320
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1676
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885158
]
name: c10d::allreduce_
id: 6597
duration_micros: 32
attr: [name: "rf_id"
int64_val: 321
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885187
]
name: record_param_comms
id: 6598
duration_micros: 25
attr: [name: "rf_id"
int64_val: 322
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885199
]
name: nccl:all_reduce
id: 6599
duration_micros: 26
attr: [name: "rf_id"
int64_val: 323
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885215
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 6600
duration_micros: 603
attr: [name: "rf_id"
int64_val: 323
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122885234
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 6601
duration_micros: 26
attr: [name: "rf_id"
int64_val: 323
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885234
]
name: record_param_comms
id: 6603
duration_micros: 6
attr: [name: "rf_id"
int64_val: 324
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885307
]
name: aten::view_as
id: 6604
duration_micros: 9
attr: [name: "rf_id"
int64_val: 325
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885330
]
name: aten::view
id: 6605
duration_micros: 11
attr: [name: "rf_id"
int64_val: 326
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885334
]
name: aten::expand_as
id: 6606
duration_micros: 9
attr: [name: "rf_id"
int64_val: 327
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885378
]
name: aten::expand
id: 6607
duration_micros: 13
attr: [name: "rf_id"
int64_val: 328
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885382
]
name: aten::as_strided
id: 6608
duration_micros: 10
attr: [name: "rf_id"
int64_val: 329
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885388
]
name: TorchDynamo Cache Lookup
id: 6609
duration_micros: 12
attr: [name: "rf_id"
int64_val: 330
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885433
]
name: Torch-Compiled Region
id: 6610
duration_micros: 74
attr: [name: "rf_id"
int64_val: 331
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885447
]
name: aten::empty
id: 6611
duration_micros: 18
attr: [name: "rf_id"
int64_val: 332
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885487
]
name: triton_poi_fused_add_0
id: 6612
duration_micros: 17
attr: [name: "rf_id"
int64_val: 333
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885519
]
name: triton__0d1d2d3d4de
id: 6613
duration_micros: 114
attr: [name: "rf_id"
int64_val: 333
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122885539
]
name: triton_poi_fused_add_0
id: 6614
duration_micros: 17
attr: [name: "rf_id"
int64_val: 333
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885539
]
name: FusedLayerNormAffineFunction
id: 6616
duration_micros: 53
attr: [name: "rf_id"
int64_val: 334
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1677
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885617
]
name: aten::empty_like
id: 6617
duration_micros: 24
attr: [name: "rf_id"
int64_val: 335
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885629
]
name: aten::empty_strided
id: 6618
duration_micros: 53
attr: [name: "rf_id"
int64_val: 336
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885636
]
name: aten::empty
id: 6619
duration_micros: 16
attr: [name: "rf_id"
int64_val: 337
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885712
]
name: aten::empty_like
id: 6620
duration_micros: 13
attr: [name: "rf_id"
int64_val: 338
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885731
]
name: aten::empty_strided
id: 6621
duration_micros: 5
attr: [name: "rf_id"
int64_val: 339
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885736
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 6622
duration_micros: 137
attr: [name: "rf_id"
int64_val: 339
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122885770
]
name: aten::empty_strided
id: 6623
duration_micros: 5
attr: [name: "rf_id"
int64_val: 339
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122885770
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6625
duration_micros: 25
attr: [name: "rf_id"
int64_val: 340
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1678
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893758
]
name: aten::t
id: 6626
duration_micros: 9
attr: [name: "rf_id"
int64_val: 341
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893767
]
name: aten::transpose
id: 6627
duration_micros: 12
attr: [name: "rf_id"
int64_val: 342
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893771
]
name: aten::as_strided
id: 6628
duration_micros: 10
attr: [name: "rf_id"
int64_val: 343
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893776
]
name: aten::matmul
id: 6629
duration_micros: 17
attr: [name: "rf_id"
int64_val: 344
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893803
]
name: aten::reshape
id: 6630
duration_micros: 8
attr: [name: "rf_id"
int64_val: 345
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893807
]
name: aten::view
id: 6631
duration_micros: 8
attr: [name: "rf_id"
int64_val: 346
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893810
]
name: aten::mm
id: 6632
duration_micros: 30
attr: [name: "rf_id"
int64_val: 347
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893825
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 6633
duration_micros: 523
attr: [name: "rf_id"
int64_val: 347
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122893873
]
name: aten::mm
id: 6634
duration_micros: 30
attr: [name: "rf_id"
int64_val: 347
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893873
]
name: aten::_unsafe_view
id: 6636
duration_micros: 7
attr: [name: "rf_id"
int64_val: 348
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893891
]
name: GeLUFunction
id: 6637
duration_micros: 36
attr: [name: "rf_id"
int64_val: 349
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1679
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893934
]
name: TorchDynamo Cache Lookup
id: 6638
duration_micros: 10
attr: [name: "rf_id"
int64_val: 350
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893957
]
name: Torch-Compiled Region
id: 6639
duration_micros: 96
attr: [name: "rf_id"
int64_val: 351
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122893969
]
name: aten::empty
id: 6640
duration_micros: 50
attr: [name: "rf_id"
int64_val: 352
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894010
]
name: triton_poi_fused_add_mul_tanh_0
id: 6641
duration_micros: 18
attr: [name: "rf_id"
int64_val: 353
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894094
]
name: triton__0d1d2d3de
id: 6642
duration_micros: 43
attr: [name: "rf_id"
int64_val: 353
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122894114
]
name: triton_poi_fused_add_mul_tanh_0
id: 6643
duration_micros: 18
attr: [name: "rf_id"
int64_val: 353
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894114
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6645
duration_micros: 24
attr: [name: "rf_id"
int64_val: 354
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1680
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894200
]
name: aten::t
id: 6646
duration_micros: 10
attr: [name: "rf_id"
int64_val: 355
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894209
]
name: aten::transpose
id: 6647
duration_micros: 16
attr: [name: "rf_id"
int64_val: 356
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894213
]
name: aten::as_strided
id: 6648
duration_micros: 13
attr: [name: "rf_id"
int64_val: 357
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894223
]
name: aten::matmul
id: 6649
duration_micros: 18
attr: [name: "rf_id"
int64_val: 358
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894253
]
name: aten::reshape
id: 6650
duration_micros: 9
attr: [name: "rf_id"
int64_val: 359
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894257
]
name: aten::view
id: 6651
duration_micros: 8
attr: [name: "rf_id"
int64_val: 360
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894260
]
name: aten::mm
id: 6652
duration_micros: 31
attr: [name: "rf_id"
int64_val: 361
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894276
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 6653
duration_micros: 566
attr: [name: "rf_id"
int64_val: 361
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122894328
]
name: aten::mm
id: 6654
duration_micros: 31
attr: [name: "rf_id"
int64_val: 361
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894328
]
name: aten::_unsafe_view
id: 6656
duration_micros: 7
attr: [name: "rf_id"
int64_val: 362
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894345
]
name: _ReduceFromModelParallelRegion
id: 6657
duration_micros: 73
attr: [name: "rf_id"
int64_val: 363
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1681
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894380
]
name: c10d::allreduce_
id: 6658
duration_micros: 30
attr: [name: "rf_id"
int64_val: 364
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894415
]
name: record_param_comms
id: 6659
duration_micros: 24
attr: [name: "rf_id"
int64_val: 365
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894426
]
name: nccl:all_reduce
id: 6660
duration_micros: 26
attr: [name: "rf_id"
int64_val: 366
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894441
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 6661
duration_micros: 611
attr: [name: "rf_id"
int64_val: 366
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122894459
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 6662
duration_micros: 26
attr: [name: "rf_id"
int64_val: 366
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894459
]
name: record_param_comms
id: 6664
duration_micros: 6
attr: [name: "rf_id"
int64_val: 367
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894533
]
name: aten::view_as
id: 6665
duration_micros: 41
attr: [name: "rf_id"
int64_val: 368
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894556
]
name: aten::view
id: 6666
duration_micros: 11
attr: [name: "rf_id"
int64_val: 369
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894561
]
name: aten::expand_as
id: 6667
duration_micros: 11
attr: [name: "rf_id"
int64_val: 370
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894636
]
name: aten::expand
id: 6668
duration_micros: 14
attr: [name: "rf_id"
int64_val: 371
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894641
]
name: aten::as_strided
id: 6669
duration_micros: 10
attr: [name: "rf_id"
int64_val: 372
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894647
]
name: TorchDynamo Cache Lookup
id: 6670
duration_micros: 13
attr: [name: "rf_id"
int64_val: 373
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894693
]
name: Torch-Compiled Region
id: 6671
duration_micros: 71
attr: [name: "rf_id"
int64_val: 374
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894707
]
name: aten::empty
id: 6672
duration_micros: 18
attr: [name: "rf_id"
int64_val: 375
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894748
]
name: triton_poi_fused_add_0
id: 6673
duration_micros: 17
attr: [name: "rf_id"
int64_val: 376
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894778
]
name: triton__0d1d2d3d4de
id: 6674
duration_micros: 113
attr: [name: "rf_id"
int64_val: 376
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122894796
]
name: triton_poi_fused_add_0
id: 6675
duration_micros: 17
attr: [name: "rf_id"
int64_val: 376
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894796
]
name: FusedLayerNormAffineFunction
id: 6677
duration_micros: 50
attr: [name: "rf_id"
int64_val: 377
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1682
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894907
]
name: aten::empty_like
id: 6678
duration_micros: 14
attr: [name: "rf_id"
int64_val: 378
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894919
]
name: aten::empty_strided
id: 6679
duration_micros: 22
attr: [name: "rf_id"
int64_val: 379
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894925
]
name: aten::empty
id: 6680
duration_micros: 13
attr: [name: "rf_id"
int64_val: 380
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894959
]
name: aten::empty_like
id: 6681
duration_micros: 10
attr: [name: "rf_id"
int64_val: 381
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894976
]
name: aten::empty_strided
id: 6682
duration_micros: 6
attr: [name: "rf_id"
int64_val: 382
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122894979
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 6683
duration_micros: 138
attr: [name: "rf_id"
int64_val: 382
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122895013
]
name: aten::empty_strided
id: 6684
duration_micros: 6
attr: [name: "rf_id"
int64_val: 382
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895013
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6686
duration_micros: 38
attr: [name: "rf_id"
int64_val: 383
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1683
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895079
]
name: aten::t
id: 6687
duration_micros: 12
attr: [name: "rf_id"
int64_val: 384
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895088
]
name: aten::transpose
id: 6688
duration_micros: 44
attr: [name: "rf_id"
int64_val: 385
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895091
]
name: aten::as_strided
id: 6689
duration_micros: 10
attr: [name: "rf_id"
int64_val: 386
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895098
]
name: aten::matmul
id: 6690
duration_micros: 19
attr: [name: "rf_id"
int64_val: 387
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895161
]
name: aten::reshape
id: 6691
duration_micros: 8
attr: [name: "rf_id"
int64_val: 388
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895166
]
name: aten::view
id: 6692
duration_micros: 8
attr: [name: "rf_id"
int64_val: 389
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895169
]
name: aten::mm
id: 6693
duration_micros: 31
attr: [name: "rf_id"
int64_val: 390
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895185
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 6694
duration_micros: 400
attr: [name: "rf_id"
int64_val: 390
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122895235
]
name: aten::mm
id: 6695
duration_micros: 31
attr: [name: "rf_id"
int64_val: 390
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895235
]
name: aten::_unsafe_view
id: 6697
duration_micros: 8
attr: [name: "rf_id"
int64_val: 391
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895253
]
name: aten::add
id: 6698
duration_micros: 16
attr: [name: "rf_id"
int64_val: 392
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895276
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 6699
duration_micros: 54
attr: [name: "rf_id"
int64_val: 392
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122895298
]
name: aten::add
id: 6700
duration_micros: 16
attr: [name: "rf_id"
int64_val: 392
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895298
]
name: aten::view
id: 6702
duration_micros: 9
attr: [name: "rf_id"
int64_val: 393
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895337
]
name: aten::split_with_sizes
id: 6703
duration_micros: 31
attr: [name: "rf_id"
int64_val: 394
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895363
]
name: aten::as_strided
id: 6704
duration_micros: 9
attr: [name: "rf_id"
int64_val: 395
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895370
]
name: aten::as_strided
id: 6705
duration_micros: 9
attr: [name: "rf_id"
int64_val: 396
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895370
]
name: aten::as_strided
id: 6706
duration_micros: 7
attr: [name: "rf_id"
int64_val: 397
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895388
]
name: aten::view
id: 6707
duration_micros: 7
attr: [name: "rf_id"
int64_val: 398
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895426
]
name: aten::reshape
id: 6708
duration_micros: 16
attr: [name: "rf_id"
int64_val: 399
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895450
]
name: aten::_reshape_alias
id: 6709
duration_micros: 38
attr: [name: "rf_id"
int64_val: 400
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895458
]
name: aten::view
id: 6710
duration_micros: 8
attr: [name: "rf_id"
int64_val: 401
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895513
]
name: aten::slice
id: 6711
duration_micros: 15
attr: [name: "rf_id"
int64_val: 402
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895537
]
name: aten::as_strided
id: 6712
duration_micros: 8
attr: [name: "rf_id"
int64_val: 403
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895543
]
name: aten::view
id: 6713
duration_micros: 7
attr: [name: "rf_id"
int64_val: 404
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895568
]
name: aten::transpose
id: 6714
duration_micros: 11
attr: [name: "rf_id"
int64_val: 405
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895582
]
name: aten::as_strided
id: 6715
duration_micros: 11
attr: [name: "rf_id"
int64_val: 406
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895587
]
name: aten::transpose
id: 6716
duration_micros: 11
attr: [name: "rf_id"
int64_val: 407
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895608
]
name: aten::as_strided
id: 6717
duration_micros: 6
attr: [name: "rf_id"
int64_val: 408
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895613
]
name: aten::transpose
id: 6718
duration_micros: 9
attr: [name: "rf_id"
int64_val: 409
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895628
]
name: aten::as_strided
id: 6719
duration_micros: 7
attr: [name: "rf_id"
int64_val: 410
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895632
]
name: aten::baddbmm
id: 6720
duration_micros: 35
attr: [name: "rf_id"
int64_val: 411
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895657
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 6721
duration_micros: 295
attr: [name: "rf_id"
int64_val: 411
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122895715
]
name: aten::baddbmm
id: 6722
duration_micros: 35
attr: [name: "rf_id"
int64_val: 411
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895715
]
name: aten::view
id: 6724
duration_micros: 9
attr: [name: "rf_id"
int64_val: 412
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895740
]
name: aten::view
id: 6725
duration_micros: 9
attr: [name: "rf_id"
int64_val: 413
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895740
]
name: ScaledUpperTriangMaskedSoftmax
id: 6726
duration_micros: 77
attr: [name: "rf_id"
int64_val: 414
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1684
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895804
]
name: aten::empty
id: 6727
duration_micros: 86
attr: [name: "rf_id"
int64_val: 415
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895818
]
name: aten::to
id: 6728
duration_micros: 11
attr: [name: "rf_id"
int64_val: 416
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895914
]
name: aten::lift_fresh
id: 6729
duration_micros: 5
attr: [name: "rf_id"
int64_val: 417
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895928
]
name: aten::detach_
id: 6730
duration_micros: 7
attr: [name: "rf_id"
int64_val: 418
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895935
]
name: detach_
id: 6731
duration_micros: 3
attr: [name: "rf_id"
int64_val: 419
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895937
]
name: aten::select
id: 6732
duration_micros: 16
attr: [name: "rf_id"
int64_val: 420
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895952
]
name: aten::as_strided
id: 6733
duration_micros: 9
attr: [name: "rf_id"
int64_val: 421
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895961
]
name: aten::item
id: 6734
duration_micros: 6
attr: [name: "rf_id"
int64_val: 422
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895983
]
name: aten::_local_scalar_dense
id: 6735
duration_micros: 8
attr: [name: "rf_id"
int64_val: 423
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122895985
]
name: aten::empty
id: 6736
duration_micros: 10
attr: [name: "rf_id"
int64_val: 424
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896002
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 6737
duration_micros: 426
attr: [name: "rf_id"
int64_val: 424
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122896038
]
name: aten::empty
id: 6738
duration_micros: 10
attr: [name: "rf_id"
int64_val: 424
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896038
]
name: aten::view
id: 6740
duration_micros: 10
attr: [name: "rf_id"
int64_val: 425
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896062
]
name: aten::dropout
id: 6741
duration_micros: 8
attr: [name: "rf_id"
int64_val: 426
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896128
]
name: aten::view
id: 6742
duration_micros: 9
attr: [name: "rf_id"
int64_val: 427
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896169
]
name: aten::view
id: 6743
duration_micros: 9
attr: [name: "rf_id"
int64_val: 428
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896169
]
name: aten::transpose
id: 6744
duration_micros: 13
attr: [name: "rf_id"
int64_val: 429
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896195
]
name: aten::as_strided
id: 6745
duration_micros: 8
attr: [name: "rf_id"
int64_val: 430
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896201
]
name: aten::bmm
id: 6746
duration_micros: 37
attr: [name: "rf_id"
int64_val: 431
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896220
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 6747
duration_micros: 183
attr: [name: "rf_id"
int64_val: 431
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122896254
]
name: aten::bmm
id: 6748
duration_micros: 37
attr: [name: "rf_id"
int64_val: 431
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896254
]
name: aten::view
id: 6750
duration_micros: 11
attr: [name: "rf_id"
int64_val: 432
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896309
]
name: aten::permute
id: 6751
duration_micros: 17
attr: [name: "rf_id"
int64_val: 433
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896327
]
name: aten::as_strided
id: 6752
duration_micros: 8
attr: [name: "rf_id"
int64_val: 434
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896337
]
name: aten::contiguous
id: 6753
duration_micros: 8
attr: [name: "rf_id"
int64_val: 435
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896359
]
name: aten::clone
id: 6754
duration_micros: 13
attr: [name: "rf_id"
int64_val: 436
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896361
]
name: aten::empty_like
id: 6755
duration_micros: 12
attr: [name: "rf_id"
int64_val: 437
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896365
]
name: aten::empty
id: 6756
duration_micros: 16
attr: [name: "rf_id"
int64_val: 438
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896369
]
name: aten::copy_
id: 6757
duration_micros: 15
attr: [name: "rf_id"
int64_val: 439
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896396
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 6758
duration_micros: 21
attr: [name: "rf_id"
int64_val: 439
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122896415
]
name: aten::copy_
id: 6759
duration_micros: 15
attr: [name: "rf_id"
int64_val: 439
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896415
]
name: aten::view
id: 6761
duration_micros: 9
attr: [name: "rf_id"
int64_val: 440
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896454
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6762
duration_micros: 24
attr: [name: "rf_id"
int64_val: 441
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1685
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896505
]
name: aten::t
id: 6763
duration_micros: 9
attr: [name: "rf_id"
int64_val: 442
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896513
]
name: aten::transpose
id: 6764
duration_micros: 12
attr: [name: "rf_id"
int64_val: 443
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896517
]
name: aten::as_strided
id: 6765
duration_micros: 10
attr: [name: "rf_id"
int64_val: 444
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896522
]
name: aten::matmul
id: 6766
duration_micros: 22
attr: [name: "rf_id"
int64_val: 445
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896549
]
name: aten::reshape
id: 6767
duration_micros: 8
attr: [name: "rf_id"
int64_val: 446
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896553
]
name: aten::view
id: 6768
duration_micros: 8
attr: [name: "rf_id"
int64_val: 447
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896556
]
name: aten::mm
id: 6769
duration_micros: 27
attr: [name: "rf_id"
int64_val: 448
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896572
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 6770
duration_micros: 161
attr: [name: "rf_id"
int64_val: 448
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122896614
]
name: aten::mm
id: 6771
duration_micros: 27
attr: [name: "rf_id"
int64_val: 448
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896614
]
name: aten::_unsafe_view
id: 6773
duration_micros: 35
attr: [name: "rf_id"
int64_val: 449
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896634
]
name: _ReduceFromModelParallelRegion
id: 6774
duration_micros: 61
attr: [name: "rf_id"
int64_val: 450
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1686
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896702
]
name: c10d::allreduce_
id: 6775
duration_micros: 28
attr: [name: "rf_id"
int64_val: 451
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896730
]
name: record_param_comms
id: 6776
duration_micros: 27
attr: [name: "rf_id"
int64_val: 452
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896741
]
name: nccl:all_reduce
id: 6777
duration_micros: 25
attr: [name: "rf_id"
int64_val: 453
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896758
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 6778
duration_micros: 612
attr: [name: "rf_id"
int64_val: 453
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122896776
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 6779
duration_micros: 25
attr: [name: "rf_id"
int64_val: 453
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896776
]
name: record_param_comms
id: 6781
duration_micros: 6
attr: [name: "rf_id"
int64_val: 454
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896847
]
name: aten::view_as
id: 6782
duration_micros: 10
attr: [name: "rf_id"
int64_val: 455
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896869
]
name: aten::view
id: 6783
duration_micros: 11
attr: [name: "rf_id"
int64_val: 456
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896873
]
name: aten::expand_as
id: 6784
duration_micros: 10
attr: [name: "rf_id"
int64_val: 457
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896916
]
name: aten::expand
id: 6785
duration_micros: 14
attr: [name: "rf_id"
int64_val: 458
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896921
]
name: aten::as_strided
id: 6786
duration_micros: 9
attr: [name: "rf_id"
int64_val: 459
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896927
]
name: TorchDynamo Cache Lookup
id: 6787
duration_micros: 11
attr: [name: "rf_id"
int64_val: 460
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896971
]
name: Torch-Compiled Region
id: 6788
duration_micros: 68
attr: [name: "rf_id"
int64_val: 461
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122896983
]
name: aten::empty
id: 6789
duration_micros: 18
attr: [name: "rf_id"
int64_val: 462
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897021
]
name: triton_poi_fused_add_0
id: 6790
duration_micros: 16
attr: [name: "rf_id"
int64_val: 463
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897051
]
name: triton__0d1d2d3d4de
id: 6791
duration_micros: 114
attr: [name: "rf_id"
int64_val: 463
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122897069
]
name: triton_poi_fused_add_0
id: 6792
duration_micros: 16
attr: [name: "rf_id"
int64_val: 463
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897069
]
name: FusedLayerNormAffineFunction
id: 6794
duration_micros: 53
attr: [name: "rf_id"
int64_val: 464
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1687
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897144
]
name: aten::empty_like
id: 6795
duration_micros: 18
attr: [name: "rf_id"
int64_val: 465
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897156
]
name: aten::empty_strided
id: 6796
duration_micros: 49
attr: [name: "rf_id"
int64_val: 466
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897163
]
name: aten::empty
id: 6797
duration_micros: 15
attr: [name: "rf_id"
int64_val: 467
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897228
]
name: aten::empty_like
id: 6798
duration_micros: 12
attr: [name: "rf_id"
int64_val: 468
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897247
]
name: aten::empty_strided
id: 6799
duration_micros: 7
attr: [name: "rf_id"
int64_val: 469
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897251
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 6800
duration_micros: 136
attr: [name: "rf_id"
int64_val: 469
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122897288
]
name: aten::empty_strided
id: 6801
duration_micros: 7
attr: [name: "rf_id"
int64_val: 469
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897288
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6803
duration_micros: 22
attr: [name: "rf_id"
int64_val: 470
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1688
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897353
]
name: aten::t
id: 6804
duration_micros: 9
attr: [name: "rf_id"
int64_val: 471
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897362
]
name: aten::transpose
id: 6805
duration_micros: 14
attr: [name: "rf_id"
int64_val: 472
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897365
]
name: aten::as_strided
id: 6806
duration_micros: 10
attr: [name: "rf_id"
int64_val: 473
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897372
]
name: aten::matmul
id: 6807
duration_micros: 19
attr: [name: "rf_id"
int64_val: 474
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897399
]
name: aten::reshape
id: 6808
duration_micros: 8
attr: [name: "rf_id"
int64_val: 475
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897404
]
name: aten::view
id: 6809
duration_micros: 8
attr: [name: "rf_id"
int64_val: 476
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897407
]
name: aten::mm
id: 6810
duration_micros: 28
attr: [name: "rf_id"
int64_val: 477
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897422
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 6811
duration_micros: 525
attr: [name: "rf_id"
int64_val: 477
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122897467
]
name: aten::mm
id: 6812
duration_micros: 28
attr: [name: "rf_id"
int64_val: 477
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897467
]
name: aten::_unsafe_view
id: 6814
duration_micros: 7
attr: [name: "rf_id"
int64_val: 478
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897484
]
name: GeLUFunction
id: 6815
duration_micros: 32
attr: [name: "rf_id"
int64_val: 479
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1689
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897531
]
name: TorchDynamo Cache Lookup
id: 6816
duration_micros: 9
attr: [name: "rf_id"
int64_val: 480
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897551
]
name: Torch-Compiled Region
id: 6817
duration_micros: 75
attr: [name: "rf_id"
int64_val: 481
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897561
]
name: aten::empty
id: 6818
duration_micros: 48
attr: [name: "rf_id"
int64_val: 482
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897600
]
name: triton_poi_fused_add_mul_tanh_0
id: 6819
duration_micros: 20
attr: [name: "rf_id"
int64_val: 483
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897663
]
name: triton__0d1d2d3de
id: 6820
duration_micros: 43
attr: [name: "rf_id"
int64_val: 483
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122897681
]
name: triton_poi_fused_add_mul_tanh_0
id: 6821
duration_micros: 20
attr: [name: "rf_id"
int64_val: 483
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897681
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6823
duration_micros: 23
attr: [name: "rf_id"
int64_val: 484
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1690
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897774
]
name: aten::t
id: 6824
duration_micros: 10
attr: [name: "rf_id"
int64_val: 485
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897783
]
name: aten::transpose
id: 6825
duration_micros: 13
attr: [name: "rf_id"
int64_val: 486
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897786
]
name: aten::as_strided
id: 6826
duration_micros: 12
attr: [name: "rf_id"
int64_val: 487
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897793
]
name: aten::matmul
id: 6827
duration_micros: 17
attr: [name: "rf_id"
int64_val: 488
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897822
]
name: aten::reshape
id: 6828
duration_micros: 9
attr: [name: "rf_id"
int64_val: 489
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897826
]
name: aten::view
id: 6829
duration_micros: 11
attr: [name: "rf_id"
int64_val: 490
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897829
]
name: aten::mm
id: 6830
duration_micros: 31
attr: [name: "rf_id"
int64_val: 491
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897848
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 6831
duration_micros: 566
attr: [name: "rf_id"
int64_val: 491
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122897898
]
name: aten::mm
id: 6832
duration_micros: 31
attr: [name: "rf_id"
int64_val: 491
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897898
]
name: aten::_unsafe_view
id: 6834
duration_micros: 7
attr: [name: "rf_id"
int64_val: 492
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897916
]
name: _ReduceFromModelParallelRegion
id: 6835
duration_micros: 64
attr: [name: "rf_id"
int64_val: 493
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1691
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897961
]
name: c10d::allreduce_
id: 6836
duration_micros: 26
attr: [name: "rf_id"
int64_val: 494
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122897989
]
name: record_param_comms
id: 6837
duration_micros: 26
attr: [name: "rf_id"
int64_val: 495
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898000
]
name: nccl:all_reduce
id: 6838
duration_micros: 24
attr: [name: "rf_id"
int64_val: 496
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898016
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 6839
duration_micros: 638
attr: [name: "rf_id"
int64_val: 496
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122898033
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 6840
duration_micros: 24
attr: [name: "rf_id"
int64_val: 496
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898033
]
name: record_param_comms
id: 6842
duration_micros: 6
attr: [name: "rf_id"
int64_val: 497
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898101
]
name: aten::view_as
id: 6843
duration_micros: 46
attr: [name: "rf_id"
int64_val: 498
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898123
]
name: aten::view
id: 6844
duration_micros: 11
attr: [name: "rf_id"
int64_val: 499
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898127
]
name: aten::expand_as
id: 6845
duration_micros: 10
attr: [name: "rf_id"
int64_val: 500
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898207
]
name: aten::expand
id: 6846
duration_micros: 14
attr: [name: "rf_id"
int64_val: 501
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898212
]
name: aten::as_strided
id: 6847
duration_micros: 10
attr: [name: "rf_id"
int64_val: 502
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898218
]
name: TorchDynamo Cache Lookup
id: 6848
duration_micros: 10
attr: [name: "rf_id"
int64_val: 503
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898263
]
name: Torch-Compiled Region
id: 6849
duration_micros: 67
attr: [name: "rf_id"
int64_val: 504
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898275
]
name: aten::empty
id: 6850
duration_micros: 18
attr: [name: "rf_id"
int64_val: 505
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898313
]
name: triton_poi_fused_add_0
id: 6851
duration_micros: 16
attr: [name: "rf_id"
int64_val: 506
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898343
]
name: triton__0d1d2d3d4de
id: 6852
duration_micros: 113
attr: [name: "rf_id"
int64_val: 506
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122898360
]
name: triton_poi_fused_add_0
id: 6853
duration_micros: 16
attr: [name: "rf_id"
int64_val: 506
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898360
]
name: FusedLayerNormAffineFunction
id: 6855
duration_micros: 73
attr: [name: "rf_id"
int64_val: 507
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1692
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898467
]
name: aten::empty_like
id: 6856
duration_micros: 15
attr: [name: "rf_id"
int64_val: 508
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898479
]
name: aten::empty_strided
id: 6857
duration_micros: 21
attr: [name: "rf_id"
int64_val: 509
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898486
]
name: aten::empty
id: 6858
duration_micros: 14
attr: [name: "rf_id"
int64_val: 510
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898519
]
name: aten::empty_like
id: 6859
duration_micros: 11
attr: [name: "rf_id"
int64_val: 511
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898560
]
name: aten::empty_strided
id: 6860
duration_micros: 6
attr: [name: "rf_id"
int64_val: 512
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898564
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 6861
duration_micros: 134
attr: [name: "rf_id"
int64_val: 512
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122898599
]
name: aten::empty_strided
id: 6862
duration_micros: 6
attr: [name: "rf_id"
int64_val: 512
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898599
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6864
duration_micros: 35
attr: [name: "rf_id"
int64_val: 513
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1693
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898664
]
name: aten::t
id: 6865
duration_micros: 15
attr: [name: "rf_id"
int64_val: 514
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898673
]
name: aten::transpose
id: 6866
duration_micros: 45
attr: [name: "rf_id"
int64_val: 515
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898679
]
name: aten::as_strided
id: 6867
duration_micros: 11
attr: [name: "rf_id"
int64_val: 516
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898685
]
name: aten::matmul
id: 6868
duration_micros: 20
attr: [name: "rf_id"
int64_val: 517
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898751
]
name: aten::reshape
id: 6869
duration_micros: 8
attr: [name: "rf_id"
int64_val: 518
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898756
]
name: aten::view
id: 6870
duration_micros: 8
attr: [name: "rf_id"
int64_val: 519
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898759
]
name: aten::mm
id: 6871
duration_micros: 30
attr: [name: "rf_id"
int64_val: 520
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898775
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 6872
duration_micros: 400
attr: [name: "rf_id"
int64_val: 520
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122898825
]
name: aten::mm
id: 6873
duration_micros: 30
attr: [name: "rf_id"
int64_val: 520
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898825
]
name: aten::_unsafe_view
id: 6875
duration_micros: 7
attr: [name: "rf_id"
int64_val: 521
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898842
]
name: aten::add
id: 6876
duration_micros: 17
attr: [name: "rf_id"
int64_val: 522
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898863
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 6877
duration_micros: 54
attr: [name: "rf_id"
int64_val: 522
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122898885
]
name: aten::add
id: 6878
duration_micros: 17
attr: [name: "rf_id"
int64_val: 522
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898885
]
name: aten::view
id: 6880
duration_micros: 9
attr: [name: "rf_id"
int64_val: 523
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898925
]
name: aten::split_with_sizes
id: 6881
duration_micros: 31
attr: [name: "rf_id"
int64_val: 524
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898950
]
name: aten::as_strided
id: 6882
duration_micros: 9
attr: [name: "rf_id"
int64_val: 525
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898956
]
name: aten::as_strided
id: 6883
duration_micros: 9
attr: [name: "rf_id"
int64_val: 526
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898956
]
name: aten::as_strided
id: 6884
duration_micros: 6
attr: [name: "rf_id"
int64_val: 527
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122898971
]
name: aten::view
id: 6885
duration_micros: 7
attr: [name: "rf_id"
int64_val: 528
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899012
]
name: aten::reshape
id: 6886
duration_micros: 15
attr: [name: "rf_id"
int64_val: 529
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899036
]
name: aten::_reshape_alias
id: 6887
duration_micros: 39
attr: [name: "rf_id"
int64_val: 530
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899043
]
name: aten::view
id: 6888
duration_micros: 9
attr: [name: "rf_id"
int64_val: 531
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899099
]
name: aten::slice
id: 6889
duration_micros: 15
attr: [name: "rf_id"
int64_val: 532
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899123
]
name: aten::as_strided
id: 6890
duration_micros: 8
attr: [name: "rf_id"
int64_val: 533
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899129
]
name: aten::view
id: 6891
duration_micros: 7
attr: [name: "rf_id"
int64_val: 534
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899154
]
name: aten::transpose
id: 6892
duration_micros: 12
attr: [name: "rf_id"
int64_val: 535
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899168
]
name: aten::as_strided
id: 6893
duration_micros: 7
attr: [name: "rf_id"
int64_val: 536
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899173
]
name: aten::transpose
id: 6894
duration_micros: 11
attr: [name: "rf_id"
int64_val: 537
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899190
]
name: aten::as_strided
id: 6895
duration_micros: 10
attr: [name: "rf_id"
int64_val: 538
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899195
]
name: aten::transpose
id: 6896
duration_micros: 9
attr: [name: "rf_id"
int64_val: 539
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899214
]
name: aten::as_strided
id: 6897
duration_micros: 7
attr: [name: "rf_id"
int64_val: 540
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899218
]
name: aten::baddbmm
id: 6898
duration_micros: 33
attr: [name: "rf_id"
int64_val: 541
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899243
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 6899
duration_micros: 293
attr: [name: "rf_id"
int64_val: 541
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122899296
]
name: aten::baddbmm
id: 6900
duration_micros: 33
attr: [name: "rf_id"
int64_val: 541
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899296
]
name: aten::view
id: 6902
duration_micros: 9
attr: [name: "rf_id"
int64_val: 542
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899321
]
name: aten::view
id: 6903
duration_micros: 9
attr: [name: "rf_id"
int64_val: 543
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899321
]
name: ScaledUpperTriangMaskedSoftmax
id: 6904
duration_micros: 70
attr: [name: "rf_id"
int64_val: 544
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1694
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899374
]
name: aten::empty
id: 6905
duration_micros: 42
attr: [name: "rf_id"
int64_val: 545
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899388
]
name: aten::to
id: 6906
duration_micros: 10
attr: [name: "rf_id"
int64_val: 546
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899437
]
name: aten::lift_fresh
id: 6907
duration_micros: 5
attr: [name: "rf_id"
int64_val: 547
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899450
]
name: aten::detach_
id: 6908
duration_micros: 7
attr: [name: "rf_id"
int64_val: 548
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899457
]
name: detach_
id: 6909
duration_micros: 2
attr: [name: "rf_id"
int64_val: 549
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899459
]
name: aten::select
id: 6910
duration_micros: 13
attr: [name: "rf_id"
int64_val: 550
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899472
]
name: aten::as_strided
id: 6911
duration_micros: 11
attr: [name: "rf_id"
int64_val: 551
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899478
]
name: aten::item
id: 6912
duration_micros: 6
attr: [name: "rf_id"
int64_val: 552
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899501
]
name: aten::_local_scalar_dense
id: 6913
duration_micros: 8
attr: [name: "rf_id"
int64_val: 553
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899503
]
name: aten::empty
id: 6914
duration_micros: 10
attr: [name: "rf_id"
int64_val: 554
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899520
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 6915
duration_micros: 426
attr: [name: "rf_id"
int64_val: 554
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122899556
]
name: aten::empty
id: 6916
duration_micros: 10
attr: [name: "rf_id"
int64_val: 554
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899556
]
name: aten::view
id: 6918
duration_micros: 10
attr: [name: "rf_id"
int64_val: 555
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899579
]
name: aten::dropout
id: 6919
duration_micros: 7
attr: [name: "rf_id"
int64_val: 556
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899642
]
name: aten::view
id: 6920
duration_micros: 10
attr: [name: "rf_id"
int64_val: 557
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899681
]
name: aten::view
id: 6921
duration_micros: 10
attr: [name: "rf_id"
int64_val: 558
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899681
]
name: aten::transpose
id: 6922
duration_micros: 13
attr: [name: "rf_id"
int64_val: 559
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899707
]
name: aten::as_strided
id: 6923
duration_micros: 7
attr: [name: "rf_id"
int64_val: 560
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899713
]
name: aten::bmm
id: 6924
duration_micros: 36
attr: [name: "rf_id"
int64_val: 561
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899732
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 6925
duration_micros: 184
attr: [name: "rf_id"
int64_val: 561
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122899766
]
name: aten::bmm
id: 6926
duration_micros: 36
attr: [name: "rf_id"
int64_val: 561
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899766
]
name: aten::view
id: 6928
duration_micros: 10
attr: [name: "rf_id"
int64_val: 562
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899820
]
name: aten::permute
id: 6929
duration_micros: 13
attr: [name: "rf_id"
int64_val: 563
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899837
]
name: aten::as_strided
id: 6930
duration_micros: 11
attr: [name: "rf_id"
int64_val: 564
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899843
]
name: aten::contiguous
id: 6931
duration_micros: 8
attr: [name: "rf_id"
int64_val: 565
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899868
]
name: aten::clone
id: 6932
duration_micros: 12
attr: [name: "rf_id"
int64_val: 566
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899870
]
name: aten::empty_like
id: 6933
duration_micros: 12
attr: [name: "rf_id"
int64_val: 567
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899874
]
name: aten::empty
id: 6934
duration_micros: 18
attr: [name: "rf_id"
int64_val: 568
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899878
]
name: aten::copy_
id: 6935
duration_micros: 15
attr: [name: "rf_id"
int64_val: 569
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899907
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 6936
duration_micros: 20
attr: [name: "rf_id"
int64_val: 569
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122899926
]
name: aten::copy_
id: 6937
duration_micros: 15
attr: [name: "rf_id"
int64_val: 569
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899926
]
name: aten::view
id: 6939
duration_micros: 9
attr: [name: "rf_id"
int64_val: 570
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122899964
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6940
duration_micros: 24
attr: [name: "rf_id"
int64_val: 571
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1695
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900015
]
name: aten::t
id: 6941
duration_micros: 9
attr: [name: "rf_id"
int64_val: 572
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900024
]
name: aten::transpose
id: 6942
duration_micros: 11
attr: [name: "rf_id"
int64_val: 573
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900027
]
name: aten::as_strided
id: 6943
duration_micros: 10
attr: [name: "rf_id"
int64_val: 574
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900032
]
name: aten::matmul
id: 6944
duration_micros: 21
attr: [name: "rf_id"
int64_val: 575
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900058
]
name: aten::reshape
id: 6945
duration_micros: 8
attr: [name: "rf_id"
int64_val: 576
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900062
]
name: aten::view
id: 6946
duration_micros: 7
attr: [name: "rf_id"
int64_val: 577
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900065
]
name: aten::mm
id: 6947
duration_micros: 26
attr: [name: "rf_id"
int64_val: 578
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900080
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 6948
duration_micros: 158
attr: [name: "rf_id"
int64_val: 578
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122900122
]
name: aten::mm
id: 6949
duration_micros: 26
attr: [name: "rf_id"
int64_val: 578
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900122
]
name: aten::_unsafe_view
id: 6951
duration_micros: 39
attr: [name: "rf_id"
int64_val: 579
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900138
]
name: _ReduceFromModelParallelRegion
id: 6952
duration_micros: 60
attr: [name: "rf_id"
int64_val: 580
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1696
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900211
]
name: c10d::allreduce_
id: 6953
duration_micros: 29
attr: [name: "rf_id"
int64_val: 581
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900239
]
name: record_param_comms
id: 6954
duration_micros: 25
attr: [name: "rf_id"
int64_val: 582
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900251
]
name: nccl:all_reduce
id: 6955
duration_micros: 25
attr: [name: "rf_id"
int64_val: 583
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900267
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 6956
duration_micros: 629
attr: [name: "rf_id"
int64_val: 583
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122900284
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 6957
duration_micros: 25
attr: [name: "rf_id"
int64_val: 583
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900284
]
name: record_param_comms
id: 6959
duration_micros: 7
attr: [name: "rf_id"
int64_val: 584
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900354
]
name: aten::view_as
id: 6960
duration_micros: 10
attr: [name: "rf_id"
int64_val: 585
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900377
]
name: aten::view
id: 6961
duration_micros: 11
attr: [name: "rf_id"
int64_val: 586
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900381
]
name: aten::expand_as
id: 6962
duration_micros: 9
attr: [name: "rf_id"
int64_val: 587
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900424
]
name: aten::expand
id: 6963
duration_micros: 14
attr: [name: "rf_id"
int64_val: 588
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900428
]
name: aten::as_strided
id: 6964
duration_micros: 9
attr: [name: "rf_id"
int64_val: 589
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900434
]
name: TorchDynamo Cache Lookup
id: 6965
duration_micros: 11
attr: [name: "rf_id"
int64_val: 590
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900477
]
name: Torch-Compiled Region
id: 6966
duration_micros: 68
attr: [name: "rf_id"
int64_val: 591
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900489
]
name: aten::empty
id: 6967
duration_micros: 26
attr: [name: "rf_id"
int64_val: 592
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900527
]
name: triton_poi_fused_add_0
id: 6968
duration_micros: 16
attr: [name: "rf_id"
int64_val: 593
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900565
]
name: triton__0d1d2d3d4de
id: 6969
duration_micros: 113
attr: [name: "rf_id"
int64_val: 593
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122900582
]
name: triton_poi_fused_add_0
id: 6970
duration_micros: 16
attr: [name: "rf_id"
int64_val: 593
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900582
]
name: FusedLayerNormAffineFunction
id: 6972
duration_micros: 52
attr: [name: "rf_id"
int64_val: 594
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1697
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900656
]
name: aten::empty_like
id: 6973
duration_micros: 17
attr: [name: "rf_id"
int64_val: 595
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900668
]
name: aten::empty_strided
id: 6974
duration_micros: 50
attr: [name: "rf_id"
int64_val: 596
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900674
]
name: aten::empty
id: 6975
duration_micros: 15
attr: [name: "rf_id"
int64_val: 597
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900740
]
name: aten::empty_like
id: 6976
duration_micros: 12
attr: [name: "rf_id"
int64_val: 598
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900758
]
name: aten::empty_strided
id: 6977
duration_micros: 5
attr: [name: "rf_id"
int64_val: 599
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900762
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 6978
duration_micros: 135
attr: [name: "rf_id"
int64_val: 599
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122900796
]
name: aten::empty_strided
id: 6979
duration_micros: 5
attr: [name: "rf_id"
int64_val: 599
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900796
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 6981
duration_micros: 24
attr: [name: "rf_id"
int64_val: 600
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1698
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900862
]
name: aten::t
id: 6982
duration_micros: 9
attr: [name: "rf_id"
int64_val: 601
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900871
]
name: aten::transpose
id: 6983
duration_micros: 16
attr: [name: "rf_id"
int64_val: 602
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900874
]
name: aten::as_strided
id: 6984
duration_micros: 11
attr: [name: "rf_id"
int64_val: 603
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900884
]
name: aten::matmul
id: 6985
duration_micros: 18
attr: [name: "rf_id"
int64_val: 604
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900912
]
name: aten::reshape
id: 6986
duration_micros: 8
attr: [name: "rf_id"
int64_val: 605
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900916
]
name: aten::view
id: 6987
duration_micros: 8
attr: [name: "rf_id"
int64_val: 606
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900919
]
name: aten::mm
id: 6988
duration_micros: 28
attr: [name: "rf_id"
int64_val: 607
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900935
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 6989
duration_micros: 522
attr: [name: "rf_id"
int64_val: 607
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122900980
]
name: aten::mm
id: 6990
duration_micros: 28
attr: [name: "rf_id"
int64_val: 607
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900980
]
name: aten::_unsafe_view
id: 6992
duration_micros: 8
attr: [name: "rf_id"
int64_val: 608
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122900997
]
name: GeLUFunction
id: 6993
duration_micros: 33
attr: [name: "rf_id"
int64_val: 609
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1699
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901040
]
name: TorchDynamo Cache Lookup
id: 6994
duration_micros: 9
attr: [name: "rf_id"
int64_val: 610
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901061
]
name: Torch-Compiled Region
id: 6995
duration_micros: 72
attr: [name: "rf_id"
int64_val: 611
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901071
]
name: aten::empty
id: 6996
duration_micros: 49
attr: [name: "rf_id"
int64_val: 612
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901109
]
name: triton_poi_fused_add_mul_tanh_0
id: 6997
duration_micros: 16
attr: [name: "rf_id"
int64_val: 613
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901173
]
name: triton__0d1d2d3de
id: 6998
duration_micros: 43
attr: [name: "rf_id"
int64_val: 613
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122901190
]
name: triton_poi_fused_add_mul_tanh_0
id: 6999
duration_micros: 16
attr: [name: "rf_id"
int64_val: 613
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901190
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7001
duration_micros: 27
attr: [name: "rf_id"
int64_val: 614
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1700
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901274
]
name: aten::t
id: 7002
duration_micros: 10
attr: [name: "rf_id"
int64_val: 615
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901287
]
name: aten::transpose
id: 7003
duration_micros: 12
attr: [name: "rf_id"
int64_val: 616
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901291
]
name: aten::as_strided
id: 7004
duration_micros: 12
attr: [name: "rf_id"
int64_val: 617
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901297
]
name: aten::matmul
id: 7005
duration_micros: 19
attr: [name: "rf_id"
int64_val: 618
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901326
]
name: aten::reshape
id: 7006
duration_micros: 8
attr: [name: "rf_id"
int64_val: 619
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901330
]
name: aten::view
id: 7007
duration_micros: 8
attr: [name: "rf_id"
int64_val: 620
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901333
]
name: aten::mm
id: 7008
duration_micros: 30
attr: [name: "rf_id"
int64_val: 621
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901349
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 7009
duration_micros: 565
attr: [name: "rf_id"
int64_val: 621
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122901398
]
name: aten::mm
id: 7010
duration_micros: 30
attr: [name: "rf_id"
int64_val: 621
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901398
]
name: aten::_unsafe_view
id: 7012
duration_micros: 7
attr: [name: "rf_id"
int64_val: 622
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901415
]
name: _ReduceFromModelParallelRegion
id: 7013
duration_micros: 60
attr: [name: "rf_id"
int64_val: 623
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1701
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901450
]
name: c10d::allreduce_
id: 7014
duration_micros: 28
attr: [name: "rf_id"
int64_val: 624
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901475
]
name: record_param_comms
id: 7015
duration_micros: 24
attr: [name: "rf_id"
int64_val: 625
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901487
]
name: nccl:all_reduce
id: 7016
duration_micros: 27
attr: [name: "rf_id"
int64_val: 626
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901502
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 7017
duration_micros: 2488
attr: [name: "rf_id"
int64_val: 626
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122901523
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 7018
duration_micros: 27
attr: [name: "rf_id"
int64_val: 626
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901523
]
name: record_param_comms
id: 7020
duration_micros: 6
attr: [name: "rf_id"
int64_val: 627
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901592
]
name: aten::view_as
id: 7021
duration_micros: 12
attr: [name: "rf_id"
int64_val: 628
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901614
]
name: aten::view
id: 7022
duration_micros: 42
attr: [name: "rf_id"
int64_val: 629
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901618
]
name: aten::expand_as
id: 7023
duration_micros: 18
attr: [name: "rf_id"
int64_val: 630
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901693
]
name: aten::expand
id: 7024
duration_micros: 14
attr: [name: "rf_id"
int64_val: 631
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901705
]
name: aten::as_strided
id: 7025
duration_micros: 10
attr: [name: "rf_id"
int64_val: 632
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901712
]
name: TorchDynamo Cache Lookup
id: 7026
duration_micros: 10
attr: [name: "rf_id"
int64_val: 633
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901757
]
name: Torch-Compiled Region
id: 7027
duration_micros: 67
attr: [name: "rf_id"
int64_val: 634
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901768
]
name: aten::empty
id: 7028
duration_micros: 19
attr: [name: "rf_id"
int64_val: 635
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901806
]
name: triton_poi_fused_add_0
id: 7029
duration_micros: 16
attr: [name: "rf_id"
int64_val: 636
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901836
]
name: triton__0d1d2d3d4de
id: 7030
duration_micros: 114
attr: [name: "rf_id"
int64_val: 636
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122901853
]
name: triton_poi_fused_add_0
id: 7031
duration_micros: 16
attr: [name: "rf_id"
int64_val: 636
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901853
]
name: FusedLayerNormAffineFunction
id: 7033
duration_micros: 48
attr: [name: "rf_id"
int64_val: 637
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1702
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901958
]
name: aten::empty_like
id: 7034
duration_micros: 14
attr: [name: "rf_id"
int64_val: 638
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901970
]
name: aten::empty_strided
id: 7035
duration_micros: 22
attr: [name: "rf_id"
int64_val: 639
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122901976
]
name: aten::empty
id: 7036
duration_micros: 14
attr: [name: "rf_id"
int64_val: 640
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902010
]
name: aten::empty_like
id: 7037
duration_micros: 12
attr: [name: "rf_id"
int64_val: 641
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902027
]
name: aten::empty_strided
id: 7038
duration_micros: 6
attr: [name: "rf_id"
int64_val: 642
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902031
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 7039
duration_micros: 140
attr: [name: "rf_id"
int64_val: 642
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122902064
]
name: aten::empty_strided
id: 7040
duration_micros: 6
attr: [name: "rf_id"
int64_val: 642
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902064
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7042
duration_micros: 36
attr: [name: "rf_id"
int64_val: 643
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1703
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902129
]
name: aten::t
id: 7043
duration_micros: 10
attr: [name: "rf_id"
int64_val: 644
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902138
]
name: aten::transpose
id: 7044
duration_micros: 19
attr: [name: "rf_id"
int64_val: 645
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902141
]
name: aten::as_strided
id: 7045
duration_micros: 40
attr: [name: "rf_id"
int64_val: 646
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902151
]
name: aten::matmul
id: 7046
duration_micros: 19
attr: [name: "rf_id"
int64_val: 647
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902213
]
name: aten::reshape
id: 7047
duration_micros: 8
attr: [name: "rf_id"
int64_val: 648
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902218
]
name: aten::view
id: 7048
duration_micros: 8
attr: [name: "rf_id"
int64_val: 649
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902221
]
name: aten::mm
id: 7049
duration_micros: 29
attr: [name: "rf_id"
int64_val: 650
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902236
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 7050
duration_micros: 400
attr: [name: "rf_id"
int64_val: 650
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122902284
]
name: aten::mm
id: 7051
duration_micros: 29
attr: [name: "rf_id"
int64_val: 650
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902284
]
name: aten::_unsafe_view
id: 7053
duration_micros: 7
attr: [name: "rf_id"
int64_val: 651
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902301
]
name: aten::add
id: 7054
duration_micros: 16
attr: [name: "rf_id"
int64_val: 652
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902323
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 7055
duration_micros: 54
attr: [name: "rf_id"
int64_val: 652
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122902345
]
name: aten::add
id: 7056
duration_micros: 16
attr: [name: "rf_id"
int64_val: 652
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902345
]
name: aten::view
id: 7058
duration_micros: 10
attr: [name: "rf_id"
int64_val: 653
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902383
]
name: aten::split_with_sizes
id: 7059
duration_micros: 27
attr: [name: "rf_id"
int64_val: 654
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902408
]
name: aten::as_strided
id: 7060
duration_micros: 9
attr: [name: "rf_id"
int64_val: 655
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902415
]
name: aten::as_strided
id: 7061
duration_micros: 9
attr: [name: "rf_id"
int64_val: 656
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902415
]
name: aten::as_strided
id: 7062
duration_micros: 7
attr: [name: "rf_id"
int64_val: 657
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902429
]
name: aten::view
id: 7063
duration_micros: 37
attr: [name: "rf_id"
int64_val: 658
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902466
]
name: aten::reshape
id: 7064
duration_micros: 14
attr: [name: "rf_id"
int64_val: 659
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902526
]
name: aten::_reshape_alias
id: 7065
duration_micros: 14
attr: [name: "rf_id"
int64_val: 660
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902534
]
name: aten::view
id: 7066
duration_micros: 7
attr: [name: "rf_id"
int64_val: 661
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902560
]
name: aten::slice
id: 7067
duration_micros: 14
attr: [name: "rf_id"
int64_val: 662
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902581
]
name: aten::as_strided
id: 7068
duration_micros: 8
attr: [name: "rf_id"
int64_val: 663
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902586
]
name: aten::view
id: 7069
duration_micros: 7
attr: [name: "rf_id"
int64_val: 664
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902611
]
name: aten::transpose
id: 7070
duration_micros: 11
attr: [name: "rf_id"
int64_val: 665
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902624
]
name: aten::as_strided
id: 7071
duration_micros: 8
attr: [name: "rf_id"
int64_val: 666
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902629
]
name: aten::transpose
id: 7072
duration_micros: 10
attr: [name: "rf_id"
int64_val: 667
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902647
]
name: aten::as_strided
id: 7073
duration_micros: 7
attr: [name: "rf_id"
int64_val: 668
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902651
]
name: aten::transpose
id: 7074
duration_micros: 9
attr: [name: "rf_id"
int64_val: 669
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902667
]
name: aten::as_strided
id: 7075
duration_micros: 7
attr: [name: "rf_id"
int64_val: 670
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902671
]
name: aten::baddbmm
id: 7076
duration_micros: 39
attr: [name: "rf_id"
int64_val: 671
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902695
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 7077
duration_micros: 293
attr: [name: "rf_id"
int64_val: 671
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122902759
]
name: aten::baddbmm
id: 7078
duration_micros: 39
attr: [name: "rf_id"
int64_val: 671
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902759
]
name: aten::view
id: 7080
duration_micros: 10
attr: [name: "rf_id"
int64_val: 672
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902786
]
name: aten::view
id: 7081
duration_micros: 10
attr: [name: "rf_id"
int64_val: 673
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902786
]
name: ScaledUpperTriangMaskedSoftmax
id: 7082
duration_micros: 73
attr: [name: "rf_id"
int64_val: 674
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1704
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902873
]
name: aten::empty
id: 7083
duration_micros: 23227
attr: [name: "rf_id"
int64_val: 675
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122902888
]
name: aten::to
id: 7084
duration_micros: 11
attr: [name: "rf_id"
int64_val: 676
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926124
]
name: aten::lift_fresh
id: 7085
duration_micros: 5
attr: [name: "rf_id"
int64_val: 677
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926137
]
name: aten::detach_
id: 7086
duration_micros: 7
attr: [name: "rf_id"
int64_val: 678
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926144
]
name: detach_
id: 7087
duration_micros: 3
attr: [name: "rf_id"
int64_val: 679
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926146
]
name: aten::select
id: 7088
duration_micros: 14
attr: [name: "rf_id"
int64_val: 680
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926160
]
name: aten::as_strided
id: 7089
duration_micros: 8
attr: [name: "rf_id"
int64_val: 681
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926166
]
name: aten::item
id: 7090
duration_micros: 7
attr: [name: "rf_id"
int64_val: 682
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926186
]
name: aten::_local_scalar_dense
id: 7091
duration_micros: 7
attr: [name: "rf_id"
int64_val: 683
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926189
]
name: aten::empty
id: 7092
duration_micros: 15
attr: [name: "rf_id"
int64_val: 684
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926205
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 7093
duration_micros: 427
attr: [name: "rf_id"
int64_val: 684
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122926251
]
name: aten::empty
id: 7094
duration_micros: 15
attr: [name: "rf_id"
int64_val: 684
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926251
]
name: aten::view
id: 7096
duration_micros: 11
attr: [name: "rf_id"
int64_val: 685
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926275
]
name: aten::dropout
id: 7097
duration_micros: 7
attr: [name: "rf_id"
int64_val: 686
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926343
]
name: aten::view
id: 7098
duration_micros: 10
attr: [name: "rf_id"
int64_val: 687
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926384
]
name: aten::view
id: 7099
duration_micros: 10
attr: [name: "rf_id"
int64_val: 688
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926384
]
name: aten::transpose
id: 7100
duration_micros: 43
attr: [name: "rf_id"
int64_val: 689
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926415
]
name: aten::as_strided
id: 7101
duration_micros: 8
attr: [name: "rf_id"
int64_val: 690
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926421
]
name: aten::bmm
id: 7102
duration_micros: 25
attr: [name: "rf_id"
int64_val: 691
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926473
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 7103
duration_micros: 184
attr: [name: "rf_id"
int64_val: 691
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122926511
]
name: aten::bmm
id: 7104
duration_micros: 25
attr: [name: "rf_id"
int64_val: 691
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926511
]
name: aten::view
id: 7106
duration_micros: 9
attr: [name: "rf_id"
int64_val: 692
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926534
]
name: aten::permute
id: 7107
duration_micros: 12
attr: [name: "rf_id"
int64_val: 693
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926550
]
name: aten::as_strided
id: 7108
duration_micros: 9
attr: [name: "rf_id"
int64_val: 694
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926556
]
name: aten::contiguous
id: 7109
duration_micros: 9
attr: [name: "rf_id"
int64_val: 695
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926576
]
name: aten::clone
id: 7110
duration_micros: 14
attr: [name: "rf_id"
int64_val: 696
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926579
]
name: aten::empty_like
id: 7111
duration_micros: 11
attr: [name: "rf_id"
int64_val: 697
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926583
]
name: aten::empty
id: 7112
duration_micros: 15
attr: [name: "rf_id"
int64_val: 698
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926587
]
name: aten::copy_
id: 7113
duration_micros: 14
attr: [name: "rf_id"
int64_val: 699
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926613
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 7114
duration_micros: 21
attr: [name: "rf_id"
int64_val: 699
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122926630
]
name: aten::copy_
id: 7115
duration_micros: 14
attr: [name: "rf_id"
int64_val: 699
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926630
]
name: aten::view
id: 7117
duration_micros: 9
attr: [name: "rf_id"
int64_val: 700
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926669
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7118
duration_micros: 25
attr: [name: "rf_id"
int64_val: 701
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1705
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926729
]
name: aten::t
id: 7119
duration_micros: 9
attr: [name: "rf_id"
int64_val: 702
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926739
]
name: aten::transpose
id: 7120
duration_micros: 13
attr: [name: "rf_id"
int64_val: 703
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926742
]
name: aten::as_strided
id: 7121
duration_micros: 10
attr: [name: "rf_id"
int64_val: 704
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926748
]
name: aten::matmul
id: 7122
duration_micros: 22
attr: [name: "rf_id"
int64_val: 705
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926775
]
name: aten::reshape
id: 7123
duration_micros: 37
attr: [name: "rf_id"
int64_val: 706
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926779
]
name: aten::view
id: 7124
duration_micros: 7
attr: [name: "rf_id"
int64_val: 707
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926782
]
name: aten::mm
id: 7125
duration_micros: 28
attr: [name: "rf_id"
int64_val: 708
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926828
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 7126
duration_micros: 159
attr: [name: "rf_id"
int64_val: 708
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122926871
]
name: aten::mm
id: 7127
duration_micros: 28
attr: [name: "rf_id"
int64_val: 708
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926871
]
name: aten::_unsafe_view
id: 7129
duration_micros: 7
attr: [name: "rf_id"
int64_val: 709
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926891
]
name: _ReduceFromModelParallelRegion
id: 7130
duration_micros: 70
attr: [name: "rf_id"
int64_val: 710
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1706
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926929
]
name: c10d::allreduce_
id: 7131
duration_micros: 37
attr: [name: "rf_id"
int64_val: 711
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926964
]
name: record_param_comms
id: 7132
duration_micros: 26
attr: [name: "rf_id"
int64_val: 712
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122926983
]
name: nccl:all_reduce
id: 7133
duration_micros: 25
attr: [name: "rf_id"
int64_val: 713
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927000
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 7134
duration_micros: 659
attr: [name: "rf_id"
int64_val: 713
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122927018
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 7135
duration_micros: 25
attr: [name: "rf_id"
int64_val: 713
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927018
]
name: record_param_comms
id: 7137
duration_micros: 7
attr: [name: "rf_id"
int64_val: 714
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927089
]
name: aten::view_as
id: 7138
duration_micros: 10
attr: [name: "rf_id"
int64_val: 715
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927113
]
name: aten::view
id: 7139
duration_micros: 11
attr: [name: "rf_id"
int64_val: 716
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927118
]
name: aten::expand_as
id: 7140
duration_micros: 10
attr: [name: "rf_id"
int64_val: 717
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927161
]
name: aten::expand
id: 7141
duration_micros: 13
attr: [name: "rf_id"
int64_val: 718
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927165
]
name: aten::as_strided
id: 7142
duration_micros: 10
attr: [name: "rf_id"
int64_val: 719
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927171
]
name: TorchDynamo Cache Lookup
id: 7143
duration_micros: 12
attr: [name: "rf_id"
int64_val: 720
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927217
]
name: Torch-Compiled Region
id: 7144
duration_micros: 78
attr: [name: "rf_id"
int64_val: 721
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927230
]
name: aten::empty
id: 7145
duration_micros: 49
attr: [name: "rf_id"
int64_val: 722
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927270
]
name: triton_poi_fused_add_0
id: 7146
duration_micros: 18
attr: [name: "rf_id"
int64_val: 723
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927336
]
name: triton__0d1d2d3d4de
id: 7147
duration_micros: 113
attr: [name: "rf_id"
int64_val: 723
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122927356
]
name: triton_poi_fused_add_0
id: 7148
duration_micros: 18
attr: [name: "rf_id"
int64_val: 723
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927356
]
name: FusedLayerNormAffineFunction
id: 7150
duration_micros: 50
attr: [name: "rf_id"
int64_val: 724
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1707
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927438
]
name: aten::empty_like
id: 7151
duration_micros: 15
attr: [name: "rf_id"
int64_val: 725
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927450
]
name: aten::empty_strided
id: 7152
duration_micros: 20
attr: [name: "rf_id"
int64_val: 726
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927457
]
name: aten::empty
id: 7153
duration_micros: 12
attr: [name: "rf_id"
int64_val: 727
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927489
]
name: aten::empty_like
id: 7154
duration_micros: 10
attr: [name: "rf_id"
int64_val: 728
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927505
]
name: aten::empty_strided
id: 7155
duration_micros: 6
attr: [name: "rf_id"
int64_val: 729
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927508
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 7156
duration_micros: 136
attr: [name: "rf_id"
int64_val: 729
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122927540
]
name: aten::empty_strided
id: 7157
duration_micros: 6
attr: [name: "rf_id"
int64_val: 729
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927540
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7159
duration_micros: 26
attr: [name: "rf_id"
int64_val: 730
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1708
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927604
]
name: aten::t
id: 7160
duration_micros: 9
attr: [name: "rf_id"
int64_val: 731
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927613
]
name: aten::transpose
id: 7161
duration_micros: 13
attr: [name: "rf_id"
int64_val: 732
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927616
]
name: aten::as_strided
id: 7162
duration_micros: 11
attr: [name: "rf_id"
int64_val: 733
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927622
]
name: aten::matmul
id: 7163
duration_micros: 50
attr: [name: "rf_id"
int64_val: 734
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927651
]
name: aten::reshape
id: 7164
duration_micros: 8
attr: [name: "rf_id"
int64_val: 735
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927655
]
name: aten::view
id: 7165
duration_micros: 8
attr: [name: "rf_id"
int64_val: 736
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927658
]
name: aten::mm
id: 7166
duration_micros: 29
attr: [name: "rf_id"
int64_val: 737
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927674
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 7167
duration_micros: 521
attr: [name: "rf_id"
int64_val: 737
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122927720
]
name: aten::mm
id: 7168
duration_micros: 29
attr: [name: "rf_id"
int64_val: 737
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927720
]
name: aten::_unsafe_view
id: 7170
duration_micros: 10
attr: [name: "rf_id"
int64_val: 738
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927738
]
name: GeLUFunction
id: 7171
duration_micros: 34
attr: [name: "rf_id"
int64_val: 739
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1709
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927819
]
name: TorchDynamo Cache Lookup
id: 7172
duration_micros: 8
attr: [name: "rf_id"
int64_val: 740
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927842
]
name: Torch-Compiled Region
id: 7173
duration_micros: 70
attr: [name: "rf_id"
int64_val: 741
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927852
]
name: aten::empty
id: 7174
duration_micros: 20
attr: [name: "rf_id"
int64_val: 742
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927892
]
name: triton_poi_fused_add_mul_tanh_0
id: 7175
duration_micros: 16
attr: [name: "rf_id"
int64_val: 743
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927924
]
name: triton__0d1d2d3de
id: 7176
duration_micros: 43
attr: [name: "rf_id"
int64_val: 743
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122927940
]
name: triton_poi_fused_add_mul_tanh_0
id: 7177
duration_micros: 16
attr: [name: "rf_id"
int64_val: 743
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122927940
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7179
duration_micros: 23
attr: [name: "rf_id"
int64_val: 744
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1710
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928019
]
name: aten::t
id: 7180
duration_micros: 14
attr: [name: "rf_id"
int64_val: 745
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928028
]
name: aten::transpose
id: 7181
duration_micros: 14
attr: [name: "rf_id"
int64_val: 746
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928036
]
name: aten::as_strided
id: 7182
duration_micros: 11
attr: [name: "rf_id"
int64_val: 747
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928043
]
name: aten::matmul
id: 7183
duration_micros: 19
attr: [name: "rf_id"
int64_val: 748
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928072
]
name: aten::reshape
id: 7184
duration_micros: 8
attr: [name: "rf_id"
int64_val: 749
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928076
]
name: aten::view
id: 7185
duration_micros: 8
attr: [name: "rf_id"
int64_val: 750
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928079
]
name: aten::mm
id: 7186
duration_micros: 31
attr: [name: "rf_id"
int64_val: 751
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928095
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 7187
duration_micros: 566
attr: [name: "rf_id"
int64_val: 751
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122928145
]
name: aten::mm
id: 7188
duration_micros: 31
attr: [name: "rf_id"
int64_val: 751
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928145
]
name: aten::_unsafe_view
id: 7190
duration_micros: 7
attr: [name: "rf_id"
int64_val: 752
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928163
]
name: _ReduceFromModelParallelRegion
id: 7191
duration_micros: 66
attr: [name: "rf_id"
int64_val: 753
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1711
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928198
]
name: c10d::allreduce_
id: 7192
duration_micros: 57
attr: [name: "rf_id"
int64_val: 754
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928224
]
name: record_param_comms
id: 7193
duration_micros: 26
attr: [name: "rf_id"
int64_val: 755
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928235
]
name: nccl:all_reduce
id: 7194
duration_micros: 26
attr: [name: "rf_id"
int64_val: 756
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928251
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 7195
duration_micros: 10877
attr: [name: "rf_id"
int64_val: 756
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122928268
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 7196
duration_micros: 26
attr: [name: "rf_id"
int64_val: 756
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928268
]
name: record_param_comms
id: 7198
duration_micros: 8
attr: [name: "rf_id"
int64_val: 757
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928373
]
name: aten::view_as
id: 7199
duration_micros: 9
attr: [name: "rf_id"
int64_val: 758
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928400
]
name: aten::view
id: 7200
duration_micros: 12
attr: [name: "rf_id"
int64_val: 759
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928404
]
name: aten::expand_as
id: 7201
duration_micros: 10
attr: [name: "rf_id"
int64_val: 760
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928444
]
name: aten::expand
id: 7202
duration_micros: 13
attr: [name: "rf_id"
int64_val: 761
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928448
]
name: aten::as_strided
id: 7203
duration_micros: 9
attr: [name: "rf_id"
int64_val: 762
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928454
]
name: TorchDynamo Cache Lookup
id: 7204
duration_micros: 10
attr: [name: "rf_id"
int64_val: 763
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928497
]
name: Torch-Compiled Region
id: 7205
duration_micros: 67
attr: [name: "rf_id"
int64_val: 764
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928508
]
name: aten::empty
id: 7206
duration_micros: 18
attr: [name: "rf_id"
int64_val: 765
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928545
]
name: triton_poi_fused_add_0
id: 7207
duration_micros: 16
attr: [name: "rf_id"
int64_val: 766
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928575
]
name: triton__0d1d2d3d4de
id: 7208
duration_micros: 113
attr: [name: "rf_id"
int64_val: 766
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122928592
]
name: triton_poi_fused_add_0
id: 7209
duration_micros: 16
attr: [name: "rf_id"
int64_val: 766
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928592
]
name: FusedLayerNormAffineFunction
id: 7211
duration_micros: 54
attr: [name: "rf_id"
int64_val: 767
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1712
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928698
]
name: aten::empty_like
id: 7212
duration_micros: 15
attr: [name: "rf_id"
int64_val: 768
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928710
]
name: aten::empty_strided
id: 7213
duration_micros: 21
attr: [name: "rf_id"
int64_val: 769
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928717
]
name: aten::empty
id: 7214
duration_micros: 14
attr: [name: "rf_id"
int64_val: 770
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928750
]
name: aten::empty_like
id: 7215
duration_micros: 43
attr: [name: "rf_id"
int64_val: 771
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928767
]
name: aten::empty_strided
id: 7216
duration_micros: 6
attr: [name: "rf_id"
int64_val: 772
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928771
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 7217
duration_micros: 135
attr: [name: "rf_id"
int64_val: 772
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122928839
]
name: aten::empty_strided
id: 7218
duration_micros: 6
attr: [name: "rf_id"
int64_val: 772
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928839
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7220
duration_micros: 35
attr: [name: "rf_id"
int64_val: 773
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1713
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928909
]
name: aten::t
id: 7221
duration_micros: 10
attr: [name: "rf_id"
int64_val: 774
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928918
]
name: aten::transpose
id: 7222
duration_micros: 14
attr: [name: "rf_id"
int64_val: 775
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928922
]
name: aten::as_strided
id: 7223
duration_micros: 11
attr: [name: "rf_id"
int64_val: 776
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928929
]
name: aten::matmul
id: 7224
duration_micros: 18
attr: [name: "rf_id"
int64_val: 777
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928958
]
name: aten::reshape
id: 7225
duration_micros: 8
attr: [name: "rf_id"
int64_val: 778
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928962
]
name: aten::view
id: 7226
duration_micros: 11
attr: [name: "rf_id"
int64_val: 779
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928965
]
name: aten::mm
id: 7227
duration_micros: 29
attr: [name: "rf_id"
int64_val: 780
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122928984
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 7228
duration_micros: 400
attr: [name: "rf_id"
int64_val: 780
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122929031
]
name: aten::mm
id: 7229
duration_micros: 29
attr: [name: "rf_id"
int64_val: 780
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929031
]
name: aten::_unsafe_view
id: 7231
duration_micros: 7
attr: [name: "rf_id"
int64_val: 781
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929049
]
name: aten::add
id: 7232
duration_micros: 16
attr: [name: "rf_id"
int64_val: 782
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929070
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 7233
duration_micros: 54
attr: [name: "rf_id"
int64_val: 782
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122929093
]
name: aten::add
id: 7234
duration_micros: 16
attr: [name: "rf_id"
int64_val: 782
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929093
]
name: aten::view
id: 7236
duration_micros: 9
attr: [name: "rf_id"
int64_val: 783
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929131
]
name: aten::split_with_sizes
id: 7237
duration_micros: 31
attr: [name: "rf_id"
int64_val: 784
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929155
]
name: aten::as_strided
id: 7238
duration_micros: 9
attr: [name: "rf_id"
int64_val: 785
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929162
]
name: aten::as_strided
id: 7239
duration_micros: 9
attr: [name: "rf_id"
int64_val: 786
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929162
]
name: aten::as_strided
id: 7240
duration_micros: 7
attr: [name: "rf_id"
int64_val: 787
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929177
]
name: aten::view
id: 7241
duration_micros: 9
attr: [name: "rf_id"
int64_val: 788
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929251
]
name: aten::reshape
id: 7242
duration_micros: 14
attr: [name: "rf_id"
int64_val: 789
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929278
]
name: aten::_reshape_alias
id: 7243
duration_micros: 8
attr: [name: "rf_id"
int64_val: 790
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929286
]
name: aten::view
id: 7244
duration_micros: 7
attr: [name: "rf_id"
int64_val: 791
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929305
]
name: aten::slice
id: 7245
duration_micros: 14
attr: [name: "rf_id"
int64_val: 792
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929327
]
name: aten::as_strided
id: 7246
duration_micros: 8
attr: [name: "rf_id"
int64_val: 793
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929332
]
name: aten::view
id: 7247
duration_micros: 11
attr: [name: "rf_id"
int64_val: 794
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929357
]
name: aten::transpose
id: 7248
duration_micros: 11
attr: [name: "rf_id"
int64_val: 795
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929374
]
name: aten::as_strided
id: 7249
duration_micros: 8
attr: [name: "rf_id"
int64_val: 796
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929379
]
name: aten::transpose
id: 7250
duration_micros: 11
attr: [name: "rf_id"
int64_val: 797
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929397
]
name: aten::as_strided
id: 7251
duration_micros: 6
attr: [name: "rf_id"
int64_val: 798
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929402
]
name: aten::transpose
id: 7252
duration_micros: 11
attr: [name: "rf_id"
int64_val: 799
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929417
]
name: aten::as_strided
id: 7253
duration_micros: 6
attr: [name: "rf_id"
int64_val: 800
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929422
]
name: aten::baddbmm
id: 7254
duration_micros: 47
attr: [name: "rf_id"
int64_val: 801
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929446
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 7255
duration_micros: 294
attr: [name: "rf_id"
int64_val: 801
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122929499
]
name: aten::baddbmm
id: 7256
duration_micros: 47
attr: [name: "rf_id"
int64_val: 801
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929499
]
name: aten::view
id: 7258
duration_micros: 11
attr: [name: "rf_id"
int64_val: 802
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929556
]
name: aten::view
id: 7259
duration_micros: 11
attr: [name: "rf_id"
int64_val: 803
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929556
]
name: ScaledUpperTriangMaskedSoftmax
id: 7260
duration_micros: 69
attr: [name: "rf_id"
int64_val: 804
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1714
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929612
]
name: aten::empty
id: 7261
duration_micros: 12
attr: [name: "rf_id"
int64_val: 805
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929628
]
name: aten::to
id: 7262
duration_micros: 8
attr: [name: "rf_id"
int64_val: 806
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929645
]
name: aten::lift_fresh
id: 7263
duration_micros: 5
attr: [name: "rf_id"
int64_val: 807
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929655
]
name: aten::detach_
id: 7264
duration_micros: 7
attr: [name: "rf_id"
int64_val: 808
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929662
]
name: detach_
id: 7265
duration_micros: 2
attr: [name: "rf_id"
int64_val: 809
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929664
]
name: aten::select
id: 7266
duration_micros: 20
attr: [name: "rf_id"
int64_val: 810
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929677
]
name: aten::as_strided
id: 7267
duration_micros: 7
attr: [name: "rf_id"
int64_val: 811
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929683
]
name: aten::item
id: 7268
duration_micros: 8
attr: [name: "rf_id"
int64_val: 812
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929709
]
name: aten::_local_scalar_dense
id: 7269
duration_micros: 7
attr: [name: "rf_id"
int64_val: 813
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929712
]
name: aten::empty
id: 7270
duration_micros: 10
attr: [name: "rf_id"
int64_val: 814
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929729
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 7271
duration_micros: 425
attr: [name: "rf_id"
int64_val: 814
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122929764
]
name: aten::empty
id: 7272
duration_micros: 10
attr: [name: "rf_id"
int64_val: 814
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929764
]
name: aten::view
id: 7274
duration_micros: 10
attr: [name: "rf_id"
int64_val: 815
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929787
]
name: aten::dropout
id: 7275
duration_micros: 8
attr: [name: "rf_id"
int64_val: 816
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929853
]
name: aten::view
id: 7276
duration_micros: 10
attr: [name: "rf_id"
int64_val: 817
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929896
]
name: aten::view
id: 7277
duration_micros: 10
attr: [name: "rf_id"
int64_val: 818
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929896
]
name: aten::transpose
id: 7278
duration_micros: 13
attr: [name: "rf_id"
int64_val: 819
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929957
]
name: aten::as_strided
id: 7279
duration_micros: 10
attr: [name: "rf_id"
int64_val: 820
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929963
]
name: aten::bmm
id: 7280
duration_micros: 25
attr: [name: "rf_id"
int64_val: 821
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122929985
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 7281
duration_micros: 185
attr: [name: "rf_id"
int64_val: 821
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122930022
]
name: aten::bmm
id: 7282
duration_micros: 25
attr: [name: "rf_id"
int64_val: 821
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930022
]
name: aten::view
id: 7284
duration_micros: 9
attr: [name: "rf_id"
int64_val: 822
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930047
]
name: aten::permute
id: 7285
duration_micros: 13
attr: [name: "rf_id"
int64_val: 823
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930063
]
name: aten::as_strided
id: 7286
duration_micros: 8
attr: [name: "rf_id"
int64_val: 824
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930069
]
name: aten::contiguous
id: 7287
duration_micros: 8
attr: [name: "rf_id"
int64_val: 825
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930089
]
name: aten::clone
id: 7288
duration_micros: 14
attr: [name: "rf_id"
int64_val: 826
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930091
]
name: aten::empty_like
id: 7289
duration_micros: 11
attr: [name: "rf_id"
int64_val: 827
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930095
]
name: aten::empty
id: 7290
duration_micros: 17
attr: [name: "rf_id"
int64_val: 828
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930099
]
name: aten::copy_
id: 7291
duration_micros: 14
attr: [name: "rf_id"
int64_val: 829
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930127
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 7292
duration_micros: 20
attr: [name: "rf_id"
int64_val: 829
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122930144
]
name: aten::copy_
id: 7293
duration_micros: 14
attr: [name: "rf_id"
int64_val: 829
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930144
]
name: aten::view
id: 7295
duration_micros: 9
attr: [name: "rf_id"
int64_val: 830
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930183
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7296
duration_micros: 25
attr: [name: "rf_id"
int64_val: 831
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1715
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930234
]
name: aten::t
id: 7297
duration_micros: 39
attr: [name: "rf_id"
int64_val: 832
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930242
]
name: aten::transpose
id: 7298
duration_micros: 12
attr: [name: "rf_id"
int64_val: 833
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930246
]
name: aten::as_strided
id: 7299
duration_micros: 13
attr: [name: "rf_id"
int64_val: 834
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930251
]
name: aten::matmul
id: 7300
duration_micros: 19
attr: [name: "rf_id"
int64_val: 835
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930313
]
name: aten::reshape
id: 7301
duration_micros: 10
attr: [name: "rf_id"
int64_val: 836
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930318
]
name: aten::view
id: 7302
duration_micros: 9
attr: [name: "rf_id"
int64_val: 837
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930322
]
name: aten::mm
id: 7303
duration_micros: 28
attr: [name: "rf_id"
int64_val: 838
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930339
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 7304
duration_micros: 161
attr: [name: "rf_id"
int64_val: 838
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122930384
]
name: aten::mm
id: 7305
duration_micros: 28
attr: [name: "rf_id"
int64_val: 838
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930384
]
name: aten::_unsafe_view
id: 7307
duration_micros: 7
attr: [name: "rf_id"
int64_val: 839
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930402
]
name: _ReduceFromModelParallelRegion
id: 7308
duration_micros: 62
attr: [name: "rf_id"
int64_val: 840
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1716
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930439
]
name: c10d::allreduce_
id: 7309
duration_micros: 26
attr: [name: "rf_id"
int64_val: 841
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930467
]
name: record_param_comms
id: 7310
duration_micros: 28
attr: [name: "rf_id"
int64_val: 842
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930478
]
name: nccl:all_reduce
id: 7311
duration_micros: 24
attr: [name: "rf_id"
int64_val: 843
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930493
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 7312
duration_micros: 596
attr: [name: "rf_id"
int64_val: 843
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122930510
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 7313
duration_micros: 24
attr: [name: "rf_id"
int64_val: 843
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930510
]
name: record_param_comms
id: 7315
duration_micros: 6
attr: [name: "rf_id"
int64_val: 844
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930581
]
name: aten::view_as
id: 7316
duration_micros: 10
attr: [name: "rf_id"
int64_val: 845
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930604
]
name: aten::view
id: 7317
duration_micros: 11
attr: [name: "rf_id"
int64_val: 846
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930608
]
name: aten::expand_as
id: 7318
duration_micros: 42
attr: [name: "rf_id"
int64_val: 847
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930651
]
name: aten::expand
id: 7319
duration_micros: 14
attr: [name: "rf_id"
int64_val: 848
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930655
]
name: aten::as_strided
id: 7320
duration_micros: 9
attr: [name: "rf_id"
int64_val: 849
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930662
]
name: TorchDynamo Cache Lookup
id: 7321
duration_micros: 12
attr: [name: "rf_id"
int64_val: 850
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930741
]
name: Torch-Compiled Region
id: 7322
duration_micros: 72
attr: [name: "rf_id"
int64_val: 851
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930754
]
name: aten::empty
id: 7323
duration_micros: 22
attr: [name: "rf_id"
int64_val: 852
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930795
]
name: triton_poi_fused_add_0
id: 7324
duration_micros: 16
attr: [name: "rf_id"
int64_val: 853
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930830
]
name: triton__0d1d2d3d4de
id: 7325
duration_micros: 114
attr: [name: "rf_id"
int64_val: 853
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122930847
]
name: triton_poi_fused_add_0
id: 7326
duration_micros: 16
attr: [name: "rf_id"
int64_val: 853
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930847
]
name: FusedLayerNormAffineFunction
id: 7328
duration_micros: 48
attr: [name: "rf_id"
int64_val: 854
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1717
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930922
]
name: aten::empty_like
id: 7329
duration_micros: 15
attr: [name: "rf_id"
int64_val: 855
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930934
]
name: aten::empty_strided
id: 7330
duration_micros: 20
attr: [name: "rf_id"
int64_val: 856
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930940
]
name: aten::empty
id: 7331
duration_micros: 14
attr: [name: "rf_id"
int64_val: 857
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930972
]
name: aten::empty_like
id: 7332
duration_micros: 11
attr: [name: "rf_id"
int64_val: 858
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930989
]
name: aten::empty_strided
id: 7333
duration_micros: 6
attr: [name: "rf_id"
int64_val: 859
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122930993
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 7334
duration_micros: 136
attr: [name: "rf_id"
int64_val: 859
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122931026
]
name: aten::empty_strided
id: 7335
duration_micros: 6
attr: [name: "rf_id"
int64_val: 859
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931026
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7337
duration_micros: 25
attr: [name: "rf_id"
int64_val: 860
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1718
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931088
]
name: aten::t
id: 7338
duration_micros: 10
attr: [name: "rf_id"
int64_val: 861
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931097
]
name: aten::transpose
id: 7339
duration_micros: 13
attr: [name: "rf_id"
int64_val: 862
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931101
]
name: aten::as_strided
id: 7340
duration_micros: 10
attr: [name: "rf_id"
int64_val: 863
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931107
]
name: aten::matmul
id: 7341
duration_micros: 22
attr: [name: "rf_id"
int64_val: 864
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931135
]
name: aten::reshape
id: 7342
duration_micros: 8
attr: [name: "rf_id"
int64_val: 865
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931139
]
name: aten::view
id: 7343
duration_micros: 12
attr: [name: "rf_id"
int64_val: 866
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931142
]
name: aten::mm
id: 7344
duration_micros: 44
attr: [name: "rf_id"
int64_val: 867
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931162
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 7345
duration_micros: 523
attr: [name: "rf_id"
int64_val: 867
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122931209
]
name: aten::mm
id: 7346
duration_micros: 44
attr: [name: "rf_id"
int64_val: 867
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931209
]
name: aten::_unsafe_view
id: 7348
duration_micros: 8
attr: [name: "rf_id"
int64_val: 868
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931260
]
name: GeLUFunction
id: 7349
duration_micros: 31
attr: [name: "rf_id"
int64_val: 869
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1719
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931305
]
name: TorchDynamo Cache Lookup
id: 7350
duration_micros: 9
attr: [name: "rf_id"
int64_val: 870
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931325
]
name: Torch-Compiled Region
id: 7351
duration_micros: 69
attr: [name: "rf_id"
int64_val: 871
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931335
]
name: aten::empty
id: 7352
duration_micros: 21
attr: [name: "rf_id"
int64_val: 872
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931374
]
name: triton_poi_fused_add_mul_tanh_0
id: 7353
duration_micros: 15
attr: [name: "rf_id"
int64_val: 873
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931407
]
name: triton__0d1d2d3de
id: 7354
duration_micros: 43
attr: [name: "rf_id"
int64_val: 873
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122931423
]
name: triton_poi_fused_add_mul_tanh_0
id: 7355
duration_micros: 15
attr: [name: "rf_id"
int64_val: 873
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931423
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7357
duration_micros: 22
attr: [name: "rf_id"
int64_val: 874
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1720
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931502
]
name: aten::t
id: 7358
duration_micros: 9
attr: [name: "rf_id"
int64_val: 875
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931511
]
name: aten::transpose
id: 7359
duration_micros: 13
attr: [name: "rf_id"
int64_val: 876
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931514
]
name: aten::as_strided
id: 7360
duration_micros: 11
attr: [name: "rf_id"
int64_val: 877
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931520
]
name: aten::matmul
id: 7361
duration_micros: 19
attr: [name: "rf_id"
int64_val: 878
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931548
]
name: aten::reshape
id: 7362
duration_micros: 8
attr: [name: "rf_id"
int64_val: 879
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931552
]
name: aten::view
id: 7363
duration_micros: 8
attr: [name: "rf_id"
int64_val: 880
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931555
]
name: aten::mm
id: 7364
duration_micros: 31
attr: [name: "rf_id"
int64_val: 881
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931571
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 7365
duration_micros: 568
attr: [name: "rf_id"
int64_val: 881
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122931621
]
name: aten::mm
id: 7366
duration_micros: 31
attr: [name: "rf_id"
int64_val: 881
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931621
]
name: aten::_unsafe_view
id: 7368
duration_micros: 8
attr: [name: "rf_id"
int64_val: 882
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931639
]
name: _ReduceFromModelParallelRegion
id: 7369
duration_micros: 60
attr: [name: "rf_id"
int64_val: 883
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1721
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931675
]
name: c10d::allreduce_
id: 7370
duration_micros: 14445
attr: [name: "rf_id"
int64_val: 884
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931701
]
name: record_param_comms
id: 7371
duration_micros: 28
attr: [name: "rf_id"
int64_val: 885
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931713
]
name: nccl:all_reduce
id: 7372
duration_micros: 41
attr: [name: "rf_id"
int64_val: 886
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931728
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 7373
duration_micros: 630
attr: [name: "rf_id"
int64_val: 886
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122931748
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 7374
duration_micros: 41
attr: [name: "rf_id"
int64_val: 886
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122931748
]
name: record_param_comms
id: 7376
duration_micros: 11
attr: [name: "rf_id"
int64_val: 887
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946269
]
name: aten::view_as
id: 7377
duration_micros: 10
attr: [name: "rf_id"
int64_val: 888
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946296
]
name: aten::view
id: 7378
duration_micros: 10
attr: [name: "rf_id"
int64_val: 889
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946300
]
name: aten::expand_as
id: 7379
duration_micros: 9
attr: [name: "rf_id"
int64_val: 890
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946338
]
name: aten::expand
id: 7380
duration_micros: 13
attr: [name: "rf_id"
int64_val: 891
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946342
]
name: aten::as_strided
id: 7381
duration_micros: 9
attr: [name: "rf_id"
int64_val: 892
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946348
]
name: TorchDynamo Cache Lookup
id: 7382
duration_micros: 10
attr: [name: "rf_id"
int64_val: 893
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946390
]
name: Torch-Compiled Region
id: 7383
duration_micros: 71
attr: [name: "rf_id"
int64_val: 894
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946401
]
name: aten::empty
id: 7384
duration_micros: 25
attr: [name: "rf_id"
int64_val: 895
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946440
]
name: triton_poi_fused_add_0
id: 7385
duration_micros: 16
attr: [name: "rf_id"
int64_val: 896
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946478
]
name: triton__0d1d2d3d4de
id: 7386
duration_micros: 114
attr: [name: "rf_id"
int64_val: 896
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122946495
]
name: triton_poi_fused_add_0
id: 7387
duration_micros: 16
attr: [name: "rf_id"
int64_val: 896
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946495
]
name: FusedLayerNormAffineFunction
id: 7389
duration_micros: 54
attr: [name: "rf_id"
int64_val: 897
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1722
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946604
]
name: aten::empty_like
id: 7390
duration_micros: 15
attr: [name: "rf_id"
int64_val: 898
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946616
]
name: aten::empty_strided
id: 7391
duration_micros: 27
attr: [name: "rf_id"
int64_val: 899
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946623
]
name: aten::empty
id: 7392
duration_micros: 47
attr: [name: "rf_id"
int64_val: 900
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946662
]
name: aten::empty_like
id: 7393
duration_micros: 14
attr: [name: "rf_id"
int64_val: 901
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946715
]
name: aten::empty_strided
id: 7394
duration_micros: 7
attr: [name: "rf_id"
int64_val: 902
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946721
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 7395
duration_micros: 137
attr: [name: "rf_id"
int64_val: 902
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122946759
]
name: aten::empty_strided
id: 7396
duration_micros: 7
attr: [name: "rf_id"
int64_val: 902
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946759
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7398
duration_micros: 34
attr: [name: "rf_id"
int64_val: 903
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1723
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946828
]
name: aten::t
id: 7399
duration_micros: 10
attr: [name: "rf_id"
int64_val: 904
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946837
]
name: aten::transpose
id: 7400
duration_micros: 17
attr: [name: "rf_id"
int64_val: 905
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946841
]
name: aten::as_strided
id: 7401
duration_micros: 11
attr: [name: "rf_id"
int64_val: 906
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946851
]
name: aten::matmul
id: 7402
duration_micros: 20
attr: [name: "rf_id"
int64_val: 907
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946880
]
name: aten::reshape
id: 7403
duration_micros: 9
attr: [name: "rf_id"
int64_val: 908
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946884
]
name: aten::view
id: 7404
duration_micros: 7
attr: [name: "rf_id"
int64_val: 909
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946888
]
name: aten::mm
id: 7405
duration_micros: 27
attr: [name: "rf_id"
int64_val: 910
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946903
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 7406
duration_micros: 400
attr: [name: "rf_id"
int64_val: 910
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122946947
]
name: aten::mm
id: 7407
duration_micros: 27
attr: [name: "rf_id"
int64_val: 910
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946947
]
name: aten::_unsafe_view
id: 7409
duration_micros: 6
attr: [name: "rf_id"
int64_val: 911
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946965
]
name: aten::add
id: 7410
duration_micros: 16
attr: [name: "rf_id"
int64_val: 912
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122946986
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 7411
duration_micros: 54
attr: [name: "rf_id"
int64_val: 912
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122947007
]
name: aten::add
id: 7412
duration_micros: 16
attr: [name: "rf_id"
int64_val: 912
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947007
]
name: aten::view
id: 7414
duration_micros: 10
attr: [name: "rf_id"
int64_val: 913
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947045
]
name: aten::split_with_sizes
id: 7415
duration_micros: 32
attr: [name: "rf_id"
int64_val: 914
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947070
]
name: aten::as_strided
id: 7416
duration_micros: 9
attr: [name: "rf_id"
int64_val: 915
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947077
]
name: aten::as_strided
id: 7417
duration_micros: 9
attr: [name: "rf_id"
int64_val: 916
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947077
]
name: aten::as_strided
id: 7418
duration_micros: 37
attr: [name: "rf_id"
int64_val: 917
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947091
]
name: aten::view
id: 7419
duration_micros: 8
attr: [name: "rf_id"
int64_val: 918
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947167
]
name: aten::reshape
id: 7420
duration_micros: 13
attr: [name: "rf_id"
int64_val: 919
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947193
]
name: aten::_reshape_alias
id: 7421
duration_micros: 12
attr: [name: "rf_id"
int64_val: 920
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947200
]
name: aten::view
id: 7422
duration_micros: 6
attr: [name: "rf_id"
int64_val: 921
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947224
]
name: aten::slice
id: 7423
duration_micros: 15
attr: [name: "rf_id"
int64_val: 922
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947245
]
name: aten::as_strided
id: 7424
duration_micros: 8
attr: [name: "rf_id"
int64_val: 923
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947251
]
name: aten::view
id: 7425
duration_micros: 7
attr: [name: "rf_id"
int64_val: 924
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947276
]
name: aten::transpose
id: 7426
duration_micros: 13
attr: [name: "rf_id"
int64_val: 925
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947288
]
name: aten::as_strided
id: 7427
duration_micros: 7
attr: [name: "rf_id"
int64_val: 926
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947294
]
name: aten::transpose
id: 7428
duration_micros: 11
attr: [name: "rf_id"
int64_val: 927
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947311
]
name: aten::as_strided
id: 7429
duration_micros: 6
attr: [name: "rf_id"
int64_val: 928
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947316
]
name: aten::transpose
id: 7430
duration_micros: 35
attr: [name: "rf_id"
int64_val: 929
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947331
]
name: aten::as_strided
id: 7431
duration_micros: 7
attr: [name: "rf_id"
int64_val: 930
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947335
]
name: aten::baddbmm
id: 7432
duration_micros: 34
attr: [name: "rf_id"
int64_val: 931
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947390
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 7433
duration_micros: 294
attr: [name: "rf_id"
int64_val: 931
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122947441
]
name: aten::baddbmm
id: 7434
duration_micros: 34
attr: [name: "rf_id"
int64_val: 931
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947441
]
name: aten::view
id: 7436
duration_micros: 10
attr: [name: "rf_id"
int64_val: 932
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947471
]
name: aten::view
id: 7437
duration_micros: 10
attr: [name: "rf_id"
int64_val: 933
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947471
]
name: ScaledUpperTriangMaskedSoftmax
id: 7438
duration_micros: 62
attr: [name: "rf_id"
int64_val: 934
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1724
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947525
]
name: aten::empty
id: 7439
duration_micros: 12
attr: [name: "rf_id"
int64_val: 935
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947538
]
name: aten::to
id: 7440
duration_micros: 8
attr: [name: "rf_id"
int64_val: 936
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947555
]
name: aten::lift_fresh
id: 7441
duration_micros: 5
attr: [name: "rf_id"
int64_val: 937
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947565
]
name: aten::detach_
id: 7442
duration_micros: 7
attr: [name: "rf_id"
int64_val: 938
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947572
]
name: detach_
id: 7443
duration_micros: 2
attr: [name: "rf_id"
int64_val: 939
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947574
]
name: aten::select
id: 7444
duration_micros: 13
attr: [name: "rf_id"
int64_val: 940
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947586
]
name: aten::as_strided
id: 7445
duration_micros: 8
attr: [name: "rf_id"
int64_val: 941
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947592
]
name: aten::item
id: 7446
duration_micros: 6
attr: [name: "rf_id"
int64_val: 942
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947611
]
name: aten::_local_scalar_dense
id: 7447
duration_micros: 8
attr: [name: "rf_id"
int64_val: 943
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947613
]
name: aten::empty
id: 7448
duration_micros: 8
attr: [name: "rf_id"
int64_val: 944
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947629
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 7449
duration_micros: 426
attr: [name: "rf_id"
int64_val: 944
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122947660
]
name: aten::empty
id: 7450
duration_micros: 8
attr: [name: "rf_id"
int64_val: 944
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947660
]
name: aten::view
id: 7452
duration_micros: 10
attr: [name: "rf_id"
int64_val: 945
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947682
]
name: aten::dropout
id: 7453
duration_micros: 7
attr: [name: "rf_id"
int64_val: 946
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947744
]
name: aten::view
id: 7454
duration_micros: 43
attr: [name: "rf_id"
int64_val: 947
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947783
]
name: aten::view
id: 7455
duration_micros: 43
attr: [name: "rf_id"
int64_val: 948
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947783
]
name: aten::transpose
id: 7456
duration_micros: 11
attr: [name: "rf_id"
int64_val: 949
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947852
]
name: aten::as_strided
id: 7457
duration_micros: 9
attr: [name: "rf_id"
int64_val: 950
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947857
]
name: aten::bmm
id: 7458
duration_micros: 23
attr: [name: "rf_id"
int64_val: 951
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947877
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 7459
duration_micros: 184
attr: [name: "rf_id"
int64_val: 951
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122947912
]
name: aten::bmm
id: 7460
duration_micros: 23
attr: [name: "rf_id"
int64_val: 951
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947912
]
name: aten::view
id: 7462
duration_micros: 8
attr: [name: "rf_id"
int64_val: 952
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947933
]
name: aten::permute
id: 7463
duration_micros: 13
attr: [name: "rf_id"
int64_val: 953
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947948
]
name: aten::as_strided
id: 7464
duration_micros: 8
attr: [name: "rf_id"
int64_val: 954
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947954
]
name: aten::contiguous
id: 7465
duration_micros: 8
attr: [name: "rf_id"
int64_val: 955
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947974
]
name: aten::clone
id: 7466
duration_micros: 14
attr: [name: "rf_id"
int64_val: 956
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947976
]
name: aten::empty_like
id: 7467
duration_micros: 11
attr: [name: "rf_id"
int64_val: 957
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947980
]
name: aten::empty
id: 7468
duration_micros: 15
attr: [name: "rf_id"
int64_val: 958
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122947984
]
name: aten::copy_
id: 7469
duration_micros: 13
attr: [name: "rf_id"
int64_val: 959
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948010
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 7470
duration_micros: 20
attr: [name: "rf_id"
int64_val: 959
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122948026
]
name: aten::copy_
id: 7471
duration_micros: 13
attr: [name: "rf_id"
int64_val: 959
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948026
]
name: aten::view
id: 7473
duration_micros: 11
attr: [name: "rf_id"
int64_val: 960
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948066
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7474
duration_micros: 25
attr: [name: "rf_id"
int64_val: 961
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1725
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948119
]
name: aten::t
id: 7475
duration_micros: 12
attr: [name: "rf_id"
int64_val: 962
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948127
]
name: aten::transpose
id: 7476
duration_micros: 40
attr: [name: "rf_id"
int64_val: 963
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948131
]
name: aten::as_strided
id: 7477
duration_micros: 10
attr: [name: "rf_id"
int64_val: 964
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948136
]
name: aten::matmul
id: 7478
duration_micros: 18
attr: [name: "rf_id"
int64_val: 965
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948196
]
name: aten::reshape
id: 7479
duration_micros: 8
attr: [name: "rf_id"
int64_val: 966
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948201
]
name: aten::view
id: 7480
duration_micros: 8
attr: [name: "rf_id"
int64_val: 967
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948204
]
name: aten::mm
id: 7481
duration_micros: 27
attr: [name: "rf_id"
int64_val: 968
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948219
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 7482
duration_micros: 159
attr: [name: "rf_id"
int64_val: 968
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122948262
]
name: aten::mm
id: 7483
duration_micros: 27
attr: [name: "rf_id"
int64_val: 968
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948262
]
name: aten::_unsafe_view
id: 7485
duration_micros: 7
attr: [name: "rf_id"
int64_val: 969
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948278
]
name: _ReduceFromModelParallelRegion
id: 7486
duration_micros: 61
attr: [name: "rf_id"
int64_val: 970
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1726
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948315
]
name: c10d::allreduce_
id: 7487
duration_micros: 28
attr: [name: "rf_id"
int64_val: 971
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948342
]
name: record_param_comms
id: 7488
duration_micros: 24
attr: [name: "rf_id"
int64_val: 972
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948354
]
name: nccl:all_reduce
id: 7489
duration_micros: 26
attr: [name: "rf_id"
int64_val: 973
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948369
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 7490
duration_micros: 586
attr: [name: "rf_id"
int64_val: 973
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122948386
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 7491
duration_micros: 26
attr: [name: "rf_id"
int64_val: 973
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948386
]
name: record_param_comms
id: 7493
duration_micros: 6
attr: [name: "rf_id"
int64_val: 974
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948457
]
name: aten::view_as
id: 7494
duration_micros: 10
attr: [name: "rf_id"
int64_val: 975
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948481
]
name: aten::view
id: 7495
duration_micros: 11
attr: [name: "rf_id"
int64_val: 976
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948485
]
name: aten::expand_as
id: 7496
duration_micros: 11
attr: [name: "rf_id"
int64_val: 977
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948528
]
name: aten::expand
id: 7497
duration_micros: 46
attr: [name: "rf_id"
int64_val: 978
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948532
]
name: aten::as_strided
id: 7498
duration_micros: 9
attr: [name: "rf_id"
int64_val: 979
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948539
]
name: TorchDynamo Cache Lookup
id: 7499
duration_micros: 11
attr: [name: "rf_id"
int64_val: 980
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948618
]
name: Torch-Compiled Region
id: 7500
duration_micros: 71
attr: [name: "rf_id"
int64_val: 981
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948630
]
name: aten::empty
id: 7501
duration_micros: 19
attr: [name: "rf_id"
int64_val: 982
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948671
]
name: triton_poi_fused_add_0
id: 7502
duration_micros: 17
attr: [name: "rf_id"
int64_val: 983
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948702
]
name: triton__0d1d2d3d4de
id: 7503
duration_micros: 114
attr: [name: "rf_id"
int64_val: 983
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122948720
]
name: triton_poi_fused_add_0
id: 7504
duration_micros: 17
attr: [name: "rf_id"
int64_val: 983
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948720
]
name: FusedLayerNormAffineFunction
id: 7506
duration_micros: 67
attr: [name: "rf_id"
int64_val: 984
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1727
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948796
]
name: aten::empty_like
id: 7507
duration_micros: 14
attr: [name: "rf_id"
int64_val: 985
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948807
]
name: aten::empty_strided
id: 7508
duration_micros: 19
attr: [name: "rf_id"
int64_val: 986
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948813
]
name: aten::empty
id: 7509
duration_micros: 12
attr: [name: "rf_id"
int64_val: 987
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948844
]
name: aten::empty_like
id: 7510
duration_micros: 12
attr: [name: "rf_id"
int64_val: 988
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948878
]
name: aten::empty_strided
id: 7511
duration_micros: 6
attr: [name: "rf_id"
int64_val: 989
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948882
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 7512
duration_micros: 136
attr: [name: "rf_id"
int64_val: 989
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122948915
]
name: aten::empty_strided
id: 7513
duration_micros: 6
attr: [name: "rf_id"
int64_val: 989
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948915
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7515
duration_micros: 26
attr: [name: "rf_id"
int64_val: 990
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1728
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948979
]
name: aten::t
id: 7516
duration_micros: 10
attr: [name: "rf_id"
int64_val: 991
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948988
]
name: aten::transpose
id: 7517
duration_micros: 13
attr: [name: "rf_id"
int64_val: 992
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948992
]
name: aten::as_strided
id: 7518
duration_micros: 10
attr: [name: "rf_id"
int64_val: 993
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122948998
]
name: aten::matmul
id: 7519
duration_micros: 27
attr: [name: "rf_id"
int64_val: 994
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949026
]
name: aten::reshape
id: 7520
duration_micros: 37
attr: [name: "rf_id"
int64_val: 995
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949030
]
name: aten::view
id: 7521
duration_micros: 11
attr: [name: "rf_id"
int64_val: 996
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949033
]
name: aten::mm
id: 7522
duration_micros: 29
attr: [name: "rf_id"
int64_val: 997
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949084
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 7523
duration_micros: 522
attr: [name: "rf_id"
int64_val: 997
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122949131
]
name: aten::mm
id: 7524
duration_micros: 29
attr: [name: "rf_id"
int64_val: 997
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949131
]
name: aten::_unsafe_view
id: 7526
duration_micros: 7
attr: [name: "rf_id"
int64_val: 998
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949154
]
name: GeLUFunction
id: 7527
duration_micros: 32
attr: [name: "rf_id"
int64_val: 999
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1729
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949199
]
name: TorchDynamo Cache Lookup
id: 7528
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1000
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949220
]
name: Torch-Compiled Region
id: 7529
duration_micros: 68
attr: [name: "rf_id"
int64_val: 1001
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949230
]
name: aten::empty
id: 7530
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1002
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949268
]
name: triton_poi_fused_add_mul_tanh_0
id: 7531
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1003
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949298
]
name: triton__0d1d2d3de
id: 7532
duration_micros: 43
attr: [name: "rf_id"
int64_val: 1003
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122949314
]
name: triton_poi_fused_add_mul_tanh_0
id: 7533
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1003
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949314
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7535
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1004
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1730
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949392
]
name: aten::t
id: 7536
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1005
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949400
]
name: aten::transpose
id: 7537
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1006
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949403
]
name: aten::as_strided
id: 7538
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1007
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949410
]
name: aten::matmul
id: 7539
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1008
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949439
]
name: aten::reshape
id: 7540
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1009
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949442
]
name: aten::view
id: 7541
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1010
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949450
]
name: aten::mm
id: 7542
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1011
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949466
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 7543
duration_micros: 566
attr: [name: "rf_id"
int64_val: 1011
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122949515
]
name: aten::mm
id: 7544
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1011
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949515
]
name: aten::_unsafe_view
id: 7546
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1012
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949533
]
name: _ReduceFromModelParallelRegion
id: 7547
duration_micros: 63
attr: [name: "rf_id"
int64_val: 1013
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1731
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949603
]
name: c10d::allreduce_
id: 7548
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1014
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949632
]
name: record_param_comms
id: 7549
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1015
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949644
]
name: nccl:all_reduce
id: 7550
duration_micros: 31
attr: [name: "rf_id"
int64_val: 1016
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949660
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 7551
duration_micros: 623
attr: [name: "rf_id"
int64_val: 1016
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122949680
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 7552
duration_micros: 31
attr: [name: "rf_id"
int64_val: 1016
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949680
]
name: record_param_comms
id: 7554
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1017
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949758
]
name: aten::view_as
id: 7555
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1018
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949781
]
name: aten::view
id: 7556
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1019
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949785
]
name: aten::expand_as
id: 7557
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1020
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949824
]
name: aten::expand
id: 7558
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1021
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949828
]
name: aten::as_strided
id: 7559
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1022
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949835
]
name: TorchDynamo Cache Lookup
id: 7560
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1023
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949900
]
name: Torch-Compiled Region
id: 7561
duration_micros: 71
attr: [name: "rf_id"
int64_val: 1024
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949912
]
name: aten::empty
id: 7562
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1025
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949954
]
name: triton_poi_fused_add_0
id: 7563
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1026
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122949984
]
name: triton__0d1d2d3d4de
id: 7564
duration_micros: 114
attr: [name: "rf_id"
int64_val: 1026
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122950001
]
name: triton_poi_fused_add_0
id: 7565
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1026
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950001
]
name: FusedLayerNormAffineFunction
id: 7567
duration_micros: 57
attr: [name: "rf_id"
int64_val: 1027
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1732
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950108
]
name: aten::empty_like
id: 7568
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1028
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950120
]
name: aten::empty_strided
id: 7569
duration_micros: 21
attr: [name: "rf_id"
int64_val: 1029
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950127
]
name: aten::empty
id: 7570
duration_micros: 46
attr: [name: "rf_id"
int64_val: 1030
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950163
]
name: aten::empty_like
id: 7571
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1031
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950216
]
name: aten::empty_strided
id: 7572
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1032
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950220
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 7573
duration_micros: 139
attr: [name: "rf_id"
int64_val: 1032
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122950260
]
name: aten::empty_strided
id: 7574
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1032
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950260
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7576
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1033
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1733
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950327
]
name: aten::t
id: 7577
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1034
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950336
]
name: aten::transpose
id: 7578
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1035
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950340
]
name: aten::as_strided
id: 7579
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1036
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950346
]
name: aten::matmul
id: 7580
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1037
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950375
]
name: aten::reshape
id: 7581
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1038
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950379
]
name: aten::view
id: 7582
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1039
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950381
]
name: aten::mm
id: 7583
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1040
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950397
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 7584
duration_micros: 401
attr: [name: "rf_id"
int64_val: 1040
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122950441
]
name: aten::mm
id: 7585
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1040
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950441
]
name: aten::_unsafe_view
id: 7587
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1041
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950459
]
name: aten::add
id: 7588
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1042
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950481
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 7589
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1042
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122950503
]
name: aten::add
id: 7590
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1042
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950503
]
name: aten::view
id: 7592
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1043
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950540
]
name: aten::split_with_sizes
id: 7593
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1044
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950565
]
name: aten::as_strided
id: 7594
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1045
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950571
]
name: aten::as_strided
id: 7595
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1046
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950571
]
name: aten::as_strided
id: 7596
duration_micros: 39
attr: [name: "rf_id"
int64_val: 1047
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950586
]
name: aten::view
id: 7597
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1048
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950664
]
name: aten::reshape
id: 7598
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1049
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950690
]
name: aten::_reshape_alias
id: 7599
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1050
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950699
]
name: aten::view
id: 7600
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1051
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950720
]
name: aten::slice
id: 7601
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1052
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950741
]
name: aten::as_strided
id: 7602
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1053
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950746
]
name: aten::view
id: 7603
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1054
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950771
]
name: aten::transpose
id: 7604
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1055
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950784
]
name: aten::as_strided
id: 7605
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1056
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950790
]
name: aten::transpose
id: 7606
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1057
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950807
]
name: aten::as_strided
id: 7607
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1058
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950812
]
name: aten::transpose
id: 7608
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1059
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950831
]
name: aten::as_strided
id: 7609
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1060
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950835
]
name: aten::baddbmm
id: 7610
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1061
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950888
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 7611
duration_micros: 295
attr: [name: "rf_id"
int64_val: 1061
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122950942
]
name: aten::baddbmm
id: 7612
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1061
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950942
]
name: aten::view
id: 7614
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1062
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950968
]
name: aten::view
id: 7615
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1063
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122950968
]
name: ScaledUpperTriangMaskedSoftmax
id: 7616
duration_micros: 64
attr: [name: "rf_id"
int64_val: 1064
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1734
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951023
]
name: aten::empty
id: 7617
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1065
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951036
]
name: aten::to
id: 7618
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1066
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951052
]
name: aten::lift_fresh
id: 7619
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1067
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951063
]
name: aten::detach_
id: 7620
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1068
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951070
]
name: detach_
id: 7621
duration_micros: 2
attr: [name: "rf_id"
int64_val: 1069
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951072
]
name: aten::select
id: 7622
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1070
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951084
]
name: aten::as_strided
id: 7623
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1071
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951089
]
name: aten::item
id: 7624
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1072
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951113
]
name: aten::_local_scalar_dense
id: 7625
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1073
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951115
]
name: aten::empty
id: 7626
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1074
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951131
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 7627
duration_micros: 427
attr: [name: "rf_id"
int64_val: 1074
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122951164
]
name: aten::empty
id: 7628
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1074
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951164
]
name: aten::view
id: 7630
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1075
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951186
]
name: aten::dropout
id: 7631
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1076
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951247
]
name: aten::view
id: 7632
duration_micros: 40
attr: [name: "rf_id"
int64_val: 1077
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951287
]
name: aten::view
id: 7633
duration_micros: 40
attr: [name: "rf_id"
int64_val: 1078
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951287
]
name: aten::transpose
id: 7634
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1079
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951352
]
name: aten::as_strided
id: 7635
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1080
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951358
]
name: aten::bmm
id: 7636
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1081
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951378
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 7637
duration_micros: 185
attr: [name: "rf_id"
int64_val: 1081
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122951418
]
name: aten::bmm
id: 7638
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1081
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951418
]
name: aten::view
id: 7640
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1082
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951440
]
name: aten::permute
id: 7641
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1083
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951455
]
name: aten::as_strided
id: 7642
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1084
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951464
]
name: aten::contiguous
id: 7643
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1085
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951485
]
name: aten::clone
id: 7644
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1086
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951487
]
name: aten::empty_like
id: 7645
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1087
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951491
]
name: aten::empty
id: 7646
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1088
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951495
]
name: aten::copy_
id: 7647
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1089
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951520
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 7648
duration_micros: 21
attr: [name: "rf_id"
int64_val: 1089
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122951537
]
name: aten::copy_
id: 7649
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1089
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951537
]
name: aten::view
id: 7651
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1090
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951576
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7652
duration_micros: 12921
attr: [name: "rf_id"
int64_val: 1091
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1735
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122951626
]
name: aten::t
id: 7653
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1092
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964529
]
name: aten::transpose
id: 7654
duration_micros: 44
attr: [name: "rf_id"
int64_val: 1093
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964533
]
name: aten::as_strided
id: 7655
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1094
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964540
]
name: aten::matmul
id: 7656
duration_micros: 20
attr: [name: "rf_id"
int64_val: 1095
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964604
]
name: aten::reshape
id: 7657
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1096
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964609
]
name: aten::view
id: 7658
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1097
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964612
]
name: aten::mm
id: 7659
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1098
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964632
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 7660
duration_micros: 159
attr: [name: "rf_id"
int64_val: 1098
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122964677
]
name: aten::mm
id: 7661
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1098
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964677
]
name: aten::_unsafe_view
id: 7663
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1099
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964694
]
name: _ReduceFromModelParallelRegion
id: 7664
duration_micros: 62
attr: [name: "rf_id"
int64_val: 1100
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1736
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964732
]
name: c10d::allreduce_
id: 7665
duration_micros: 29
attr: [name: "rf_id"
int64_val: 1101
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964760
]
name: record_param_comms
id: 7666
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1102
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964771
]
name: nccl:all_reduce
id: 7667
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1103
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964786
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 7668
duration_micros: 658
attr: [name: "rf_id"
int64_val: 1103
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122964803
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 7669
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1103
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964803
]
name: record_param_comms
id: 7671
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1104
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964872
]
name: aten::view_as
id: 7672
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1105
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964895
]
name: aten::view
id: 7673
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1106
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964899
]
name: aten::expand_as
id: 7674
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1107
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964942
]
name: aten::expand
id: 7675
duration_micros: 45
attr: [name: "rf_id"
int64_val: 1108
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964946
]
name: aten::as_strided
id: 7676
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1109
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122964953
]
name: TorchDynamo Cache Lookup
id: 7677
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1110
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965032
]
name: Torch-Compiled Region
id: 7678
duration_micros: 71
attr: [name: "rf_id"
int64_val: 1111
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965043
]
name: aten::empty
id: 7679
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1112
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965083
]
name: triton_poi_fused_add_0
id: 7680
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1113
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965114
]
name: triton__0d1d2d3d4de
id: 7681
duration_micros: 113
attr: [name: "rf_id"
int64_val: 1113
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122965131
]
name: triton_poi_fused_add_0
id: 7682
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1113
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965131
]
name: FusedLayerNormAffineFunction
id: 7684
duration_micros: 48
attr: [name: "rf_id"
int64_val: 1114
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1737
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965206
]
name: aten::empty_like
id: 7685
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1115
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965218
]
name: aten::empty_strided
id: 7686
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1116
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965224
]
name: aten::empty
id: 7687
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1117
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965254
]
name: aten::empty_like
id: 7688
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1118
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965269
]
name: aten::empty_strided
id: 7689
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1119
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965273
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 7690
duration_micros: 138
attr: [name: "rf_id"
int64_val: 1119
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122965304
]
name: aten::empty_strided
id: 7691
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1119
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965304
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7693
duration_micros: 23
attr: [name: "rf_id"
int64_val: 1120
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1738
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965366
]
name: aten::t
id: 7694
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1121
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965375
]
name: aten::transpose
id: 7695
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1122
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965378
]
name: aten::as_strided
id: 7696
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1123
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965385
]
name: aten::matmul
id: 7697
duration_micros: 23
attr: [name: "rf_id"
int64_val: 1124
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965412
]
name: aten::reshape
id: 7698
duration_micros: 38
attr: [name: "rf_id"
int64_val: 1125
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965416
]
name: aten::view
id: 7699
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1126
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965420
]
name: aten::mm
id: 7700
duration_micros: 29
attr: [name: "rf_id"
int64_val: 1127
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965468
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 7701
duration_micros: 524
attr: [name: "rf_id"
int64_val: 1127
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122965515
]
name: aten::mm
id: 7702
duration_micros: 29
attr: [name: "rf_id"
int64_val: 1127
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965515
]
name: aten::_unsafe_view
id: 7704
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1128
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965534
]
name: GeLUFunction
id: 7705
duration_micros: 31
attr: [name: "rf_id"
int64_val: 1129
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1739
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965579
]
name: TorchDynamo Cache Lookup
id: 7706
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1130
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965599
]
name: Torch-Compiled Region
id: 7707
duration_micros: 69
attr: [name: "rf_id"
int64_val: 1131
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965608
]
name: aten::empty
id: 7708
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1132
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965646
]
name: triton_poi_fused_add_mul_tanh_0
id: 7709
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1133
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965675
]
name: triton__0d1d2d3de
id: 7710
duration_micros: 43
attr: [name: "rf_id"
int64_val: 1133
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122965691
]
name: triton_poi_fused_add_mul_tanh_0
id: 7711
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1133
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965691
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7713
duration_micros: 52
attr: [name: "rf_id"
int64_val: 1134
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1740
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965778
]
name: aten::t
id: 7714
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1135
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965786
]
name: aten::transpose
id: 7715
duration_micros: 22
attr: [name: "rf_id"
int64_val: 1136
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965789
]
name: aten::as_strided
id: 7716
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1137
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965804
]
name: aten::matmul
id: 7717
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1138
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965833
]
name: aten::reshape
id: 7718
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1139
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965837
]
name: aten::view
id: 7719
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1140
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965840
]
name: aten::mm
id: 7720
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1141
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965856
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 7721
duration_micros: 567
attr: [name: "rf_id"
int64_val: 1141
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122965905
]
name: aten::mm
id: 7722
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1141
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965905
]
name: aten::_unsafe_view
id: 7724
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1142
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965922
]
name: _ReduceFromModelParallelRegion
id: 7725
duration_micros: 62
attr: [name: "rf_id"
int64_val: 1143
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1741
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122965991
]
name: c10d::allreduce_
id: 7726
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1144
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966019
]
name: record_param_comms
id: 7727
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1145
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966030
]
name: nccl:all_reduce
id: 7728
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1146
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966047
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 7729
duration_micros: 650
attr: [name: "rf_id"
int64_val: 1146
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122966063
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 7730
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1146
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966063
]
name: record_param_comms
id: 7732
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1147
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966134
]
name: aten::view_as
id: 7733
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1148
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966157
]
name: aten::view
id: 7734
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1149
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966161
]
name: aten::expand_as
id: 7735
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1150
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966199
]
name: aten::expand
id: 7736
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1151
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966203
]
name: aten::as_strided
id: 7737
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1152
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966209
]
name: TorchDynamo Cache Lookup
id: 7738
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1153
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966252
]
name: Torch-Compiled Region
id: 7739
duration_micros: 69
attr: [name: "rf_id"
int64_val: 1154
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966263
]
name: aten::empty
id: 7740
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1155
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966300
]
name: triton_poi_fused_add_0
id: 7741
duration_micros: 2944
attr: [name: "rf_id"
int64_val: 1156
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122966329
]
name: triton__0d1d2d3d4de
id: 7742
duration_micros: 113
attr: [name: "rf_id"
int64_val: 1156
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122972202
]
name: triton_poi_fused_add_0
id: 7743
duration_micros: 2944
attr: [name: "rf_id"
int64_val: 1156
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972202
]
name: FusedLayerNormAffineFunction
id: 7745
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1157
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1742
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972315
]
name: aten::empty_like
id: 7746
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1158
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972327
]
name: aten::empty_strided
id: 7747
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1159
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972334
]
name: aten::empty
id: 7748
duration_micros: 43
attr: [name: "rf_id"
int64_val: 1160
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972371
]
name: aten::empty_like
id: 7749
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1161
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972420
]
name: aten::empty_strided
id: 7750
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1162
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972425
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 7751
duration_micros: 135
attr: [name: "rf_id"
int64_val: 1162
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122972463
]
name: aten::empty_strided
id: 7752
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1162
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972463
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7754
duration_micros: 33
attr: [name: "rf_id"
int64_val: 1163
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1743
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972529
]
name: aten::t
id: 7755
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1164
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972538
]
name: aten::transpose
id: 7756
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1165
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972542
]
name: aten::as_strided
id: 7757
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1166
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972548
]
name: aten::matmul
id: 7758
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1167
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972576
]
name: aten::reshape
id: 7759
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1168
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972580
]
name: aten::view
id: 7760
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1169
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972583
]
name: aten::mm
id: 7761
duration_micros: 29
attr: [name: "rf_id"
int64_val: 1170
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972599
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 7762
duration_micros: 400
attr: [name: "rf_id"
int64_val: 1170
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122972646
]
name: aten::mm
id: 7763
duration_micros: 29
attr: [name: "rf_id"
int64_val: 1170
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972646
]
name: aten::_unsafe_view
id: 7765
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1171
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972664
]
name: aten::add
id: 7766
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1172
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972685
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 7767
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1172
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122972706
]
name: aten::add
id: 7768
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1172
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972706
]
name: aten::view
id: 7770
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1173
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972744
]
name: aten::split_with_sizes
id: 7771
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1174
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972768
]
name: aten::as_strided
id: 7772
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1175
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972776
]
name: aten::as_strided
id: 7773
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1176
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972776
]
name: aten::as_strided
id: 7774
duration_micros: 36
attr: [name: "rf_id"
int64_val: 1177
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972790
]
name: aten::view
id: 7775
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1178
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972865
]
name: aten::reshape
id: 7776
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1179
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972890
]
name: aten::_reshape_alias
id: 7777
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1180
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972898
]
name: aten::view
id: 7778
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1181
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972918
]
name: aten::slice
id: 7779
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1182
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972938
]
name: aten::as_strided
id: 7780
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1183
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972944
]
name: aten::view
id: 7781
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1184
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972969
]
name: aten::transpose
id: 7782
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1185
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972985
]
name: aten::as_strided
id: 7783
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1186
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122972990
]
name: aten::transpose
id: 7784
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1187
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973008
]
name: aten::as_strided
id: 7785
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1188
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973013
]
name: aten::transpose
id: 7786
duration_micros: 36
attr: [name: "rf_id"
int64_val: 1189
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973028
]
name: aten::as_strided
id: 7787
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1190
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973033
]
name: aten::baddbmm
id: 7788
duration_micros: 33
attr: [name: "rf_id"
int64_val: 1191
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973087
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 7789
duration_micros: 295
attr: [name: "rf_id"
int64_val: 1191
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122973138
]
name: aten::baddbmm
id: 7790
duration_micros: 33
attr: [name: "rf_id"
int64_val: 1191
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973138
]
name: aten::view
id: 7792
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1192
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973165
]
name: aten::view
id: 7793
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1193
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973165
]
name: ScaledUpperTriangMaskedSoftmax
id: 7794
duration_micros: 71
attr: [name: "rf_id"
int64_val: 1194
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1744
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973220
]
name: aten::empty
id: 7795
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1195
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973238
]
name: aten::to
id: 7796
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1196
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973255
]
name: aten::lift_fresh
id: 7797
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1197
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973265
]
name: aten::detach_
id: 7798
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1198
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973273
]
name: detach_
id: 7799
duration_micros: 3
attr: [name: "rf_id"
int64_val: 1199
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973274
]
name: aten::select
id: 7800
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1200
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973287
]
name: aten::as_strided
id: 7801
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1201
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973293
]
name: aten::item
id: 7802
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1202
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973312
]
name: aten::_local_scalar_dense
id: 7803
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1203
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973314
]
name: aten::empty
id: 7804
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1204
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973330
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 7805
duration_micros: 425
attr: [name: "rf_id"
int64_val: 1204
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122973362
]
name: aten::empty
id: 7806
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1204
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973362
]
name: aten::view
id: 7808
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1205
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973383
]
name: aten::dropout
id: 7809
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1206
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973445
]
name: aten::view
id: 7810
duration_micros: 40
attr: [name: "rf_id"
int64_val: 1207
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973485
]
name: aten::view
id: 7811
duration_micros: 40
attr: [name: "rf_id"
int64_val: 1208
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973485
]
name: aten::transpose
id: 7812
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1209
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973550
]
name: aten::as_strided
id: 7813
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1210
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973561
]
name: aten::bmm
id: 7814
duration_micros: 23
attr: [name: "rf_id"
int64_val: 1211
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973582
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 7815
duration_micros: 185
attr: [name: "rf_id"
int64_val: 1211
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122973616
]
name: aten::bmm
id: 7816
duration_micros: 23
attr: [name: "rf_id"
int64_val: 1211
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973616
]
name: aten::view
id: 7818
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1212
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973638
]
name: aten::permute
id: 7819
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1213
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973653
]
name: aten::as_strided
id: 7820
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1214
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973659
]
name: aten::contiguous
id: 7821
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1215
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973679
]
name: aten::clone
id: 7822
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1216
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973681
]
name: aten::empty_like
id: 7823
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1217
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973685
]
name: aten::empty
id: 7824
duration_micros: 22
attr: [name: "rf_id"
int64_val: 1218
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973689
]
name: aten::copy_
id: 7825
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1219
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973723
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 7826
duration_micros: 21
attr: [name: "rf_id"
int64_val: 1219
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122973740
]
name: aten::copy_
id: 7827
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1219
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973740
]
name: aten::view
id: 7829
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1220
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122973779
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7830
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1221
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1745
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976503
]
name: aten::t
id: 7831
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1222
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976511
]
name: aten::transpose
id: 7832
duration_micros: 47
attr: [name: "rf_id"
int64_val: 1223
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976515
]
name: aten::as_strided
id: 7833
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1224
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976522
]
name: aten::matmul
id: 7834
duration_micros: 20
attr: [name: "rf_id"
int64_val: 1225
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976592
]
name: aten::reshape
id: 7835
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1226
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976597
]
name: aten::view
id: 7836
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1227
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976601
]
name: aten::mm
id: 7837
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1228
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976617
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 7838
duration_micros: 161
attr: [name: "rf_id"
int64_val: 1228
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122976662
]
name: aten::mm
id: 7839
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1228
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976662
]
name: aten::_unsafe_view
id: 7841
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1229
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976679
]
name: _ReduceFromModelParallelRegion
id: 7842
duration_micros: 68
attr: [name: "rf_id"
int64_val: 1230
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1746
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976717
]
name: c10d::allreduce_
id: 7843
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1231
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976751
]
name: record_param_comms
id: 7844
duration_micros: 29
attr: [name: "rf_id"
int64_val: 1232
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976763
]
name: nccl:all_reduce
id: 7845
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1233
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976779
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 7846
duration_micros: 722
attr: [name: "rf_id"
int64_val: 1233
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122976796
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 7847
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1233
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976796
]
name: record_param_comms
id: 7849
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1234
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976869
]
name: aten::view_as
id: 7850
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1235
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976892
]
name: aten::view
id: 7851
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1236
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976896
]
name: aten::expand_as
id: 7852
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1237
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976940
]
name: aten::expand
id: 7853
duration_micros: 45
attr: [name: "rf_id"
int64_val: 1238
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976944
]
name: aten::as_strided
id: 7854
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1239
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122976951
]
name: TorchDynamo Cache Lookup
id: 7855
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1240
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977030
]
name: Torch-Compiled Region
id: 7856
duration_micros: 72
attr: [name: "rf_id"
int64_val: 1241
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977042
]
name: aten::empty
id: 7857
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1242
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977083
]
name: triton_poi_fused_add_0
id: 7858
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1243
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977115
]
name: triton__0d1d2d3d4de
id: 7859
duration_micros: 114
attr: [name: "rf_id"
int64_val: 1243
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122977132
]
name: triton_poi_fused_add_0
id: 7860
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1243
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977132
]
name: FusedLayerNormAffineFunction
id: 7862
duration_micros: 48
attr: [name: "rf_id"
int64_val: 1244
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1747
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977208
]
name: aten::empty_like
id: 7863
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1245
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977220
]
name: aten::empty_strided
id: 7864
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1246
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977226
]
name: aten::empty
id: 7865
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1247
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977257
]
name: aten::empty_like
id: 7866
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1248
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977273
]
name: aten::empty_strided
id: 7867
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1249
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977277
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 7868
duration_micros: 137
attr: [name: "rf_id"
int64_val: 1249
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122977308
]
name: aten::empty_strided
id: 7869
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1249
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977308
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7871
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1250
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1748
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977370
]
name: aten::t
id: 7872
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1251
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977379
]
name: aten::transpose
id: 7873
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1252
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977386
]
name: aten::as_strided
id: 7874
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1253
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977393
]
name: aten::matmul
id: 7875
duration_micros: 22
attr: [name: "rf_id"
int64_val: 1254
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977422
]
name: aten::reshape
id: 7876
duration_micros: 37
attr: [name: "rf_id"
int64_val: 1255
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977427
]
name: aten::view
id: 7877
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1256
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977430
]
name: aten::mm
id: 7878
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1257
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977477
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 7879
duration_micros: 522
attr: [name: "rf_id"
int64_val: 1257
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122977525
]
name: aten::mm
id: 7880
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1257
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977525
]
name: aten::_unsafe_view
id: 7882
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1258
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977544
]
name: GeLUFunction
id: 7883
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1259
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1749
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977592
]
name: TorchDynamo Cache Lookup
id: 7884
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1260
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977613
]
name: Torch-Compiled Region
id: 7885
duration_micros: 71
attr: [name: "rf_id"
int64_val: 1261
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977623
]
name: aten::empty
id: 7886
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1262
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977660
]
name: triton_poi_fused_add_mul_tanh_0
id: 7887
duration_micros: 3490
attr: [name: "rf_id"
int64_val: 1263
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122977691
]
name: triton__0d1d2d3de
id: 7888
duration_micros: 43
attr: [name: "rf_id"
int64_val: 1263
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122984656
]
name: triton_poi_fused_add_mul_tanh_0
id: 7889
duration_micros: 3490
attr: [name: "rf_id"
int64_val: 1263
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984656
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7891
duration_micros: 56
attr: [name: "rf_id"
int64_val: 1264
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1750
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984740
]
name: aten::t
id: 7892
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1265
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984749
]
name: aten::transpose
id: 7893
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1266
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984753
]
name: aten::as_strided
id: 7894
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1267
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984760
]
name: aten::matmul
id: 7895
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1268
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984790
]
name: aten::reshape
id: 7896
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1269
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984793
]
name: aten::view
id: 7897
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1270
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984797
]
name: aten::mm
id: 7898
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1271
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984813
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 7899
duration_micros: 565
attr: [name: "rf_id"
int64_val: 1271
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122984863
]
name: aten::mm
id: 7900
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1271
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984863
]
name: aten::_unsafe_view
id: 7902
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1272
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984880
]
name: _ReduceFromModelParallelRegion
id: 7903
duration_micros: 63
attr: [name: "rf_id"
int64_val: 1273
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1751
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984952
]
name: c10d::allreduce_
id: 7904
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1274
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984981
]
name: record_param_comms
id: 7905
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1275
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122984992
]
name: nccl:all_reduce
id: 7906
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1276
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985009
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 7907
duration_micros: 1571
attr: [name: "rf_id"
int64_val: 1276
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122985025
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 7908
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1276
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985025
]
name: record_param_comms
id: 7910
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1277
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985099
]
name: aten::view_as
id: 7911
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1278
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985121
]
name: aten::view
id: 7912
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1279
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985126
]
name: aten::expand_as
id: 7913
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1280
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985165
]
name: aten::expand
id: 7914
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1281
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985169
]
name: aten::as_strided
id: 7915
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1282
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985176
]
name: TorchDynamo Cache Lookup
id: 7916
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1283
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985218
]
name: Torch-Compiled Region
id: 7917
duration_micros: 67
attr: [name: "rf_id"
int64_val: 1284
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985230
]
name: aten::empty
id: 7918
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1285
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985268
]
name: triton_poi_fused_add_0
id: 7919
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1286
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985297
]
name: triton__0d1d2d3d4de
id: 7920
duration_micros: 114
attr: [name: "rf_id"
int64_val: 1286
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122985314
]
name: triton_poi_fused_add_0
id: 7921
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1286
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985314
]
name: FusedLayerNormAffineFunction
id: 7923
duration_micros: 53
attr: [name: "rf_id"
int64_val: 1287
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1752
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985419
]
name: aten::empty_like
id: 7924
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1288
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985431
]
name: aten::empty_strided
id: 7925
duration_micros: 21
attr: [name: "rf_id"
int64_val: 1289
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985437
]
name: aten::empty
id: 7926
duration_micros: 45
attr: [name: "rf_id"
int64_val: 1290
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985470
]
name: aten::empty_like
id: 7927
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1291
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985521
]
name: aten::empty_strided
id: 7928
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1292
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985525
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 7929
duration_micros: 135
attr: [name: "rf_id"
int64_val: 1292
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122985564
]
name: aten::empty_strided
id: 7930
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1292
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985564
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 7932
duration_micros: 36
attr: [name: "rf_id"
int64_val: 1293
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1753
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985632
]
name: aten::t
id: 7933
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1294
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985642
]
name: aten::transpose
id: 7934
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1295
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985645
]
name: aten::as_strided
id: 7935
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1296
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985655
]
name: aten::matmul
id: 7936
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1297
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985684
]
name: aten::reshape
id: 7937
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1298
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985688
]
name: aten::view
id: 7938
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1299
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985691
]
name: aten::mm
id: 7939
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1300
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985714
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 7940
duration_micros: 400
attr: [name: "rf_id"
int64_val: 1300
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122985759
]
name: aten::mm
id: 7941
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1300
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985759
]
name: aten::_unsafe_view
id: 7943
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1301
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985777
]
name: aten::add
id: 7944
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1302
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985799
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 7945
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1302
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122985821
]
name: aten::add
id: 7946
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1302
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985821
]
name: aten::view
id: 7948
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1303
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985859
]
name: aten::split_with_sizes
id: 7949
duration_micros: 32
attr: [name: "rf_id"
int64_val: 1304
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985884
]
name: aten::as_strided
id: 7950
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1305
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985891
]
name: aten::as_strided
id: 7951
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1306
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985891
]
name: aten::as_strided
id: 7952
duration_micros: 39
attr: [name: "rf_id"
int64_val: 1307
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985905
]
name: aten::view
id: 7953
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1308
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122985983
]
name: aten::reshape
id: 7954
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1309
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986008
]
name: aten::_reshape_alias
id: 7955
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1310
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986016
]
name: aten::view
id: 7956
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1311
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986039
]
name: aten::slice
id: 7957
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1312
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986059
]
name: aten::as_strided
id: 7958
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1313
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986065
]
name: aten::view
id: 7959
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1314
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986090
]
name: aten::transpose
id: 7960
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1315
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986103
]
name: aten::as_strided
id: 7961
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1316
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986108
]
name: aten::transpose
id: 7962
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1317
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986126
]
name: aten::as_strided
id: 7963
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1318
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986130
]
name: aten::transpose
id: 7964
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1319
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986146
]
name: aten::as_strided
id: 7965
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1320
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986150
]
name: aten::baddbmm
id: 7966
duration_micros: 35
attr: [name: "rf_id"
int64_val: 1321
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986204
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 7967
duration_micros: 293
attr: [name: "rf_id"
int64_val: 1321
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122986260
]
name: aten::baddbmm
id: 7968
duration_micros: 35
attr: [name: "rf_id"
int64_val: 1321
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986260
]
name: aten::view
id: 7970
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1322
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986288
]
name: aten::view
id: 7971
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1323
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986288
]
name: ScaledUpperTriangMaskedSoftmax
id: 7972
duration_micros: 8289
attr: [name: "rf_id"
int64_val: 1324
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1754
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986342
]
name: aten::empty
id: 7973
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1325
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986355
]
name: aten::to
id: 7974
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1326
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986372
]
name: aten::lift_fresh
id: 7975
duration_micros: 4
attr: [name: "rf_id"
int64_val: 1327
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986383
]
name: aten::detach_
id: 7976
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1328
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986390
]
name: detach_
id: 7977
duration_micros: 3
attr: [name: "rf_id"
int64_val: 1329
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986391
]
name: aten::select
id: 7978
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1330
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986404
]
name: aten::as_strided
id: 7979
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1331
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986410
]
name: aten::item
id: 7980
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1332
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986428
]
name: aten::_local_scalar_dense
id: 7981
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1333
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986430
]
name: aten::empty
id: 7982
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1334
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122986446
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 7983
duration_micros: 426
attr: [name: "rf_id"
int64_val: 1334
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122994706
]
name: aten::empty
id: 7984
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1334
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122994706
]
name: aten::view
id: 7986
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1335
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122994728
]
name: aten::dropout
id: 7987
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1336
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122994794
]
name: aten::view
id: 7988
duration_micros: 41
attr: [name: "rf_id"
int64_val: 1337
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122994839
]
name: aten::view
id: 7989
duration_micros: 41
attr: [name: "rf_id"
int64_val: 1338
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122994839
]
name: aten::transpose
id: 7990
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1339
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122994905
]
name: aten::as_strided
id: 7991
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1340
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122994911
]
name: aten::bmm
id: 7992
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1341
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122994930
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 7993
duration_micros: 184
attr: [name: "rf_id"
int64_val: 1341
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122994974
]
name: aten::bmm
id: 7994
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1341
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122994974
]
name: aten::view
id: 7996
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1342
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122994995
]
name: aten::permute
id: 7997
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1343
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995010
]
name: aten::as_strided
id: 7998
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1344
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995016
]
name: aten::contiguous
id: 7999
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1345
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995036
]
name: aten::clone
id: 8000
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1346
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995038
]
name: aten::empty_like
id: 8001
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1347
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995042
]
name: aten::empty
id: 8002
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1348
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995046
]
name: aten::copy_
id: 8003
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1349
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995071
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 8004
duration_micros: 21
attr: [name: "rf_id"
int64_val: 1349
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122995088
]
name: aten::copy_
id: 8005
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1349
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995088
]
name: aten::view
id: 8007
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1350
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995131
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8008
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1351
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1755
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995183
]
name: aten::t
id: 8009
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1352
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995191
]
name: aten::transpose
id: 8010
duration_micros: 40
attr: [name: "rf_id"
int64_val: 1353
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995195
]
name: aten::as_strided
id: 8011
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1354
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995200
]
name: aten::matmul
id: 8012
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1355
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995259
]
name: aten::reshape
id: 8013
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1356
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995264
]
name: aten::view
id: 8014
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1357
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995267
]
name: aten::mm
id: 8015
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1358
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995283
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 8016
duration_micros: 163
attr: [name: "rf_id"
int64_val: 1358
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122995326
]
name: aten::mm
id: 8017
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1358
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995326
]
name: aten::_unsafe_view
id: 8019
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1359
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995342
]
name: _ReduceFromModelParallelRegion
id: 8020
duration_micros: 66
attr: [name: "rf_id"
int64_val: 1360
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1756
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995379
]
name: c10d::allreduce_
id: 8021
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1361
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995412
]
name: record_param_comms
id: 8022
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1362
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995423
]
name: nccl:all_reduce
id: 8023
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1363
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995438
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 8024
duration_micros: 632
attr: [name: "rf_id"
int64_val: 1363
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122995455
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 8025
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1363
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995455
]
name: record_param_comms
id: 8027
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1364
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995525
]
name: aten::view_as
id: 8028
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1365
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995549
]
name: aten::view
id: 8029
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1366
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995553
]
name: aten::expand_as
id: 8030
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1367
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995596
]
name: aten::expand
id: 8031
duration_micros: 45
attr: [name: "rf_id"
int64_val: 1368
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995600
]
name: aten::as_strided
id: 8032
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1369
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995607
]
name: TorchDynamo Cache Lookup
id: 8033
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1370
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995685
]
name: Torch-Compiled Region
id: 8034
duration_micros: 71
attr: [name: "rf_id"
int64_val: 1371
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995697
]
name: aten::empty
id: 8035
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1372
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995738
]
name: triton_poi_fused_add_0
id: 8036
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1373
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995769
]
name: triton__0d1d2d3d4de
id: 8037
duration_micros: 114
attr: [name: "rf_id"
int64_val: 1373
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122995787
]
name: triton_poi_fused_add_0
id: 8038
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1373
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995787
]
name: FusedLayerNormAffineFunction
id: 8040
duration_micros: 48
attr: [name: "rf_id"
int64_val: 1374
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1757
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995862
]
name: aten::empty_like
id: 8041
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1375
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995873
]
name: aten::empty_strided
id: 8042
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1376
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995880
]
name: aten::empty
id: 8043
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1377
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995910
]
name: aten::empty_like
id: 8044
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1378
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995925
]
name: aten::empty_strided
id: 8045
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1379
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995929
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 8046
duration_micros: 136
attr: [name: "rf_id"
int64_val: 1379
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122995961
]
name: aten::empty_strided
id: 8047
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1379
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122995961
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8049
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1380
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1758
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996023
]
name: aten::t
id: 8050
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1381
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996032
]
name: aten::transpose
id: 8051
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1382
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996036
]
name: aten::as_strided
id: 8052
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1383
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996045
]
name: aten::matmul
id: 8053
duration_micros: 22
attr: [name: "rf_id"
int64_val: 1384
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996074
]
name: aten::reshape
id: 8054
duration_micros: 37
attr: [name: "rf_id"
int64_val: 1385
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996078
]
name: aten::view
id: 8055
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1386
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996081
]
name: aten::mm
id: 8056
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1387
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996128
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 8057
duration_micros: 521
attr: [name: "rf_id"
int64_val: 1387
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122996175
]
name: aten::mm
id: 8058
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1387
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996175
]
name: aten::_unsafe_view
id: 8060
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1388
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996196
]
name: GeLUFunction
id: 8061
duration_micros: 33
attr: [name: "rf_id"
int64_val: 1389
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1759
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996244
]
name: TorchDynamo Cache Lookup
id: 8062
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1390
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996265
]
name: Torch-Compiled Region
id: 8063
duration_micros: 67
attr: [name: "rf_id"
int64_val: 1391
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996275
]
name: aten::empty
id: 8064
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1392
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996312
]
name: triton_poi_fused_add_mul_tanh_0
id: 8065
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1393
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996342
]
name: triton__0d1d2d3de
id: 8066
duration_micros: 43
attr: [name: "rf_id"
int64_val: 1393
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850122996359
]
name: triton_poi_fused_add_mul_tanh_0
id: 8067
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1393
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996359
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8069
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1394
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1760
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996437
]
name: aten::t
id: 8070
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1395
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996445
]
name: aten::transpose
id: 8071
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1396
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996449
]
name: aten::as_strided
id: 8072
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1397
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996455
]
name: aten::matmul
id: 8073
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1398
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996483
]
name: aten::reshape
id: 8074
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1399
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996487
]
name: aten::view
id: 8075
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1400
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996490
]
name: aten::mm
id: 8076
duration_micros: 3283
attr: [name: "rf_id"
int64_val: 1401
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850122996505
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 8077
duration_micros: 565
attr: [name: "rf_id"
int64_val: 1401
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123003055
]
name: aten::mm
id: 8078
duration_micros: 3283
attr: [name: "rf_id"
int64_val: 1401
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003055
]
name: aten::_unsafe_view
id: 8080
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1402
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003077
]
name: _ReduceFromModelParallelRegion
id: 8081
duration_micros: 64
attr: [name: "rf_id"
int64_val: 1403
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1761
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003149
]
name: c10d::allreduce_
id: 8082
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1404
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003179
]
name: record_param_comms
id: 8083
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1405
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003190
]
name: nccl:all_reduce
id: 8084
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1406
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003211
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 8085
duration_micros: 643
attr: [name: "rf_id"
int64_val: 1406
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123003229
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 8086
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1406
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003229
]
name: record_param_comms
id: 8088
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1407
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003299
]
name: aten::view_as
id: 8089
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1408
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003322
]
name: aten::view
id: 8090
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1409
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003326
]
name: aten::expand_as
id: 8091
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1410
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003365
]
name: aten::expand
id: 8092
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1411
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003370
]
name: aten::as_strided
id: 8093
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1412
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003376
]
name: TorchDynamo Cache Lookup
id: 8094
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1413
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003419
]
name: Torch-Compiled Region
id: 8095
duration_micros: 66
attr: [name: "rf_id"
int64_val: 1414
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003430
]
name: aten::empty
id: 8096
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1415
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003467
]
name: triton_poi_fused_add_0
id: 8097
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1416
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003497
]
name: triton__0d1d2d3d4de
id: 8098
duration_micros: 113
attr: [name: "rf_id"
int64_val: 1416
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123003514
]
name: triton_poi_fused_add_0
id: 8099
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1416
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003514
]
name: FusedLayerNormAffineFunction
id: 8101
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1417
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1762
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003621
]
name: aten::empty_like
id: 8102
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1418
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003633
]
name: aten::empty_strided
id: 8103
duration_micros: 20
attr: [name: "rf_id"
int64_val: 1419
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003640
]
name: aten::empty
id: 8104
duration_micros: 44
attr: [name: "rf_id"
int64_val: 1420
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003673
]
name: aten::empty_like
id: 8105
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1421
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003723
]
name: aten::empty_strided
id: 8106
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1422
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003728
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 8107
duration_micros: 136
attr: [name: "rf_id"
int64_val: 1422
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123003770
]
name: aten::empty_strided
id: 8108
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1422
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003770
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8110
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1423
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1763
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003839
]
name: aten::t
id: 8111
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1424
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003848
]
name: aten::transpose
id: 8112
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1425
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003852
]
name: aten::as_strided
id: 8113
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1426
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003858
]
name: aten::matmul
id: 8114
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1427
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003886
]
name: aten::reshape
id: 8115
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1428
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003890
]
name: aten::view
id: 8116
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1429
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003893
]
name: aten::mm
id: 8117
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1430
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003909
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 8118
duration_micros: 401
attr: [name: "rf_id"
int64_val: 1430
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123003953
]
name: aten::mm
id: 8119
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1430
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003953
]
name: aten::_unsafe_view
id: 8121
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1431
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003971
]
name: aten::add
id: 8122
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1432
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123003992
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 8123
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1432
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123004014
]
name: aten::add
id: 8124
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1432
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004014
]
name: aten::view
id: 8126
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1433
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004051
]
name: aten::split_with_sizes
id: 8127
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1434
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004076
]
name: aten::as_strided
id: 8128
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1435
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004083
]
name: aten::as_strided
id: 8129
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1436
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004083
]
name: aten::as_strided
id: 8130
duration_micros: 38
attr: [name: "rf_id"
int64_val: 1437
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004097
]
name: aten::view
id: 8131
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1438
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004177
]
name: aten::reshape
id: 8132
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1439
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004203
]
name: aten::_reshape_alias
id: 8133
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1440
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004211
]
name: aten::view
id: 8134
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1441
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004230
]
name: aten::slice
id: 8135
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1442
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004251
]
name: aten::as_strided
id: 8136
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1443
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004257
]
name: aten::view
id: 8137
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1444
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004282
]
name: aten::transpose
id: 8138
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1445
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004295
]
name: aten::as_strided
id: 8139
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1446
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004300
]
name: aten::transpose
id: 8140
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1447
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004317
]
name: aten::as_strided
id: 8141
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1448
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004322
]
name: aten::transpose
id: 8142
duration_micros: 38
attr: [name: "rf_id"
int64_val: 1449
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004337
]
name: aten::as_strided
id: 8143
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1450
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004344
]
name: aten::baddbmm
id: 8144
duration_micros: 37
attr: [name: "rf_id"
int64_val: 1451
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004398
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 8145
duration_micros: 294
attr: [name: "rf_id"
int64_val: 1451
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123004457
]
name: aten::baddbmm
id: 8146
duration_micros: 37
attr: [name: "rf_id"
int64_val: 1451
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004457
]
name: aten::view
id: 8148
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1452
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004485
]
name: aten::view
id: 8149
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1453
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004485
]
name: ScaledUpperTriangMaskedSoftmax
id: 8150
duration_micros: 64
attr: [name: "rf_id"
int64_val: 1454
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1764
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004539
]
name: aten::empty
id: 8151
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1455
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004552
]
name: aten::to
id: 8152
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1456
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004569
]
name: aten::lift_fresh
id: 8153
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1457
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004579
]
name: aten::detach_
id: 8154
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1458
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004587
]
name: detach_
id: 8155
duration_micros: 3
attr: [name: "rf_id"
int64_val: 1459
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004588
]
name: aten::select
id: 8156
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1460
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004600
]
name: aten::as_strided
id: 8157
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1461
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004606
]
name: aten::item
id: 8158
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1462
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004625
]
name: aten::_local_scalar_dense
id: 8159
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1463
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004627
]
name: aten::empty
id: 8160
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1464
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004643
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 8161
duration_micros: 426
attr: [name: "rf_id"
int64_val: 1464
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123004678
]
name: aten::empty
id: 8162
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1464
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004678
]
name: aten::view
id: 8164
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1465
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004707
]
name: aten::dropout
id: 8165
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1466
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004790
]
name: aten::view
id: 8166
duration_micros: 40
attr: [name: "rf_id"
int64_val: 1467
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004833
]
name: aten::view
id: 8167
duration_micros: 40
attr: [name: "rf_id"
int64_val: 1468
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004833
]
name: aten::transpose
id: 8168
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1469
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004898
]
name: aten::as_strided
id: 8169
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1470
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004904
]
name: aten::bmm
id: 8170
duration_micros: 23
attr: [name: "rf_id"
int64_val: 1471
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004923
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 8171
duration_micros: 184
attr: [name: "rf_id"
int64_val: 1471
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123004959
]
name: aten::bmm
id: 8172
duration_micros: 23
attr: [name: "rf_id"
int64_val: 1471
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004959
]
name: aten::view
id: 8174
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1472
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004980
]
name: aten::permute
id: 8175
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1473
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123004995
]
name: aten::as_strided
id: 8176
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1474
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005001
]
name: aten::contiguous
id: 8177
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1475
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005024
]
name: aten::clone
id: 8178
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1476
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005026
]
name: aten::empty_like
id: 8179
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1477
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005030
]
name: aten::empty
id: 8180
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1478
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005034
]
name: aten::copy_
id: 8181
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1479
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005060
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 8182
duration_micros: 21
attr: [name: "rf_id"
int64_val: 1479
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123005077
]
name: aten::copy_
id: 8183
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1479
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005077
]
name: aten::view
id: 8185
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1480
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005116
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8186
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1481
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1765
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005167
]
name: aten::t
id: 8187
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1482
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005175
]
name: aten::transpose
id: 8188
duration_micros: 42
attr: [name: "rf_id"
int64_val: 1483
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005179
]
name: aten::as_strided
id: 8189
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1484
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005184
]
name: aten::matmul
id: 8190
duration_micros: 20
attr: [name: "rf_id"
int64_val: 1485
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005246
]
name: aten::reshape
id: 8191
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1486
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005251
]
name: aten::view
id: 8192
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1487
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005254
]
name: aten::mm
id: 8193
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1488
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005271
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 8194
duration_micros: 162
attr: [name: "rf_id"
int64_val: 1488
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123005314
]
name: aten::mm
id: 8195
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1488
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005314
]
name: aten::_unsafe_view
id: 8197
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1489
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005331
]
name: _ReduceFromModelParallelRegion
id: 8198
duration_micros: 61
attr: [name: "rf_id"
int64_val: 1490
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1766
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005371
]
name: c10d::allreduce_
id: 8199
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1491
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005399
]
name: record_param_comms
id: 8200
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1492
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005410
]
name: nccl:all_reduce
id: 8201
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1493
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005426
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 8202
duration_micros: 609
attr: [name: "rf_id"
int64_val: 1493
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123005443
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 8203
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1493
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005443
]
name: record_param_comms
id: 8205
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1494
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005511
]
name: aten::view_as
id: 8206
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1495
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005533
]
name: aten::view
id: 8207
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1496
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005538
]
name: aten::expand_as
id: 8208
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1497
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005579
]
name: aten::expand
id: 8209
duration_micros: 1109
attr: [name: "rf_id"
int64_val: 1498
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005584
]
name: aten::as_strided
id: 8210
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1499
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123005590
]
name: TorchDynamo Cache Lookup
id: 8211
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1500
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123006737
]
name: Torch-Compiled Region
id: 8212
duration_micros: 73
attr: [name: "rf_id"
int64_val: 1501
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123006749
]
name: aten::empty
id: 8213
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1502
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123006790
]
name: triton_poi_fused_add_0
id: 8214
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1503
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123006822
]
name: triton__0d1d2d3d4de
id: 8215
duration_micros: 113
attr: [name: "rf_id"
int64_val: 1503
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123006839
]
name: triton_poi_fused_add_0
id: 8216
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1503
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123006839
]
name: FusedLayerNormAffineFunction
id: 8218
duration_micros: 56
attr: [name: "rf_id"
int64_val: 1504
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1767
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123006916
]
name: aten::empty_like
id: 8219
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1505
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123006928
]
name: aten::empty_strided
id: 8220
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1506
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123006934
]
name: aten::empty
id: 8221
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1507
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123006972
]
name: aten::empty_like
id: 8222
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1508
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123006989
]
name: aten::empty_strided
id: 8223
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1509
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123006993
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 8224
duration_micros: 135
attr: [name: "rf_id"
int64_val: 1509
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123007026
]
name: aten::empty_strided
id: 8225
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1509
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007026
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8227
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1510
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1768
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007091
]
name: aten::t
id: 8228
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1511
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007100
]
name: aten::transpose
id: 8229
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1512
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007104
]
name: aten::as_strided
id: 8230
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1513
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007111
]
name: aten::matmul
id: 8231
duration_micros: 21
attr: [name: "rf_id"
int64_val: 1514
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007138
]
name: aten::reshape
id: 8232
duration_micros: 41
attr: [name: "rf_id"
int64_val: 1515
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007142
]
name: aten::view
id: 8233
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1516
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007146
]
name: aten::mm
id: 8234
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1517
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007195
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 8235
duration_micros: 521
attr: [name: "rf_id"
int64_val: 1517
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123007241
]
name: aten::mm
id: 8236
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1517
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007241
]
name: aten::_unsafe_view
id: 8238
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1518
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007261
]
name: GeLUFunction
id: 8239
duration_micros: 31
attr: [name: "rf_id"
int64_val: 1519
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1769
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007306
]
name: TorchDynamo Cache Lookup
id: 8240
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1520
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007327
]
name: Torch-Compiled Region
id: 8241
duration_micros: 67
attr: [name: "rf_id"
int64_val: 1521
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007337
]
name: aten::empty
id: 8242
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1522
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007375
]
name: triton_poi_fused_add_mul_tanh_0
id: 8243
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1523
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007404
]
name: triton__0d1d2d3de
id: 8244
duration_micros: 43
attr: [name: "rf_id"
int64_val: 1523
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123007420
]
name: triton_poi_fused_add_mul_tanh_0
id: 8245
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1523
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007420
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8247
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1524
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1770
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007498
]
name: aten::t
id: 8248
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1525
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007507
]
name: aten::transpose
id: 8249
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1526
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007510
]
name: aten::as_strided
id: 8250
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1527
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007516
]
name: aten::matmul
id: 8251
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1528
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007544
]
name: aten::reshape
id: 8252
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1529
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007548
]
name: aten::view
id: 8253
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1530
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007551
]
name: aten::mm
id: 8254
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1531
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007570
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 8255
duration_micros: 566
attr: [name: "rf_id"
int64_val: 1531
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123007619
]
name: aten::mm
id: 8256
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1531
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007619
]
name: aten::_unsafe_view
id: 8258
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1532
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007636
]
name: _ReduceFromModelParallelRegion
id: 8259
duration_micros: 63
attr: [name: "rf_id"
int64_val: 1533
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1771
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007706
]
name: c10d::allreduce_
id: 8260
duration_micros: 49
attr: [name: "rf_id"
int64_val: 1534
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007734
]
name: record_param_comms
id: 8261
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1535
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007766
]
name: nccl:all_reduce
id: 8262
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1536
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007784
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 8263
duration_micros: 626
attr: [name: "rf_id"
int64_val: 1536
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123007801
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 8264
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1536
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007801
]
name: record_param_comms
id: 8266
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1537
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007873
]
name: aten::view_as
id: 8267
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1538
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007896
]
name: aten::view
id: 8268
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1539
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007900
]
name: aten::expand_as
id: 8269
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1540
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007939
]
name: aten::expand
id: 8270
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1541
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007944
]
name: aten::as_strided
id: 8271
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1542
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007950
]
name: TorchDynamo Cache Lookup
id: 8272
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1543
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123007993
]
name: Torch-Compiled Region
id: 8273
duration_micros: 67
attr: [name: "rf_id"
int64_val: 1544
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008004
]
name: aten::empty
id: 8274
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1545
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008042
]
name: triton_poi_fused_add_0
id: 8275
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1546
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008071
]
name: triton__0d1d2d3d4de
id: 8276
duration_micros: 113
attr: [name: "rf_id"
int64_val: 1546
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123008088
]
name: triton_poi_fused_add_0
id: 8277
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1546
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008088
]
name: FusedLayerNormAffineFunction
id: 8279
duration_micros: 52
attr: [name: "rf_id"
int64_val: 1547
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1772
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008194
]
name: aten::empty_like
id: 8280
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1548
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008206
]
name: aten::empty_strided
id: 8281
duration_micros: 21
attr: [name: "rf_id"
int64_val: 1549
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008212
]
name: aten::empty
id: 8282
duration_micros: 45
attr: [name: "rf_id"
int64_val: 1550
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008245
]
name: aten::empty_like
id: 8283
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1551
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008296
]
name: aten::empty_strided
id: 8284
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1552
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008301
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 8285
duration_micros: 134
attr: [name: "rf_id"
int64_val: 1552
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123008340
]
name: aten::empty_strided
id: 8286
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1552
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008340
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8288
duration_micros: 33
attr: [name: "rf_id"
int64_val: 1553
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1773
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008408
]
name: aten::t
id: 8289
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1554
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008417
]
name: aten::transpose
id: 8290
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1555
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008420
]
name: aten::as_strided
id: 8291
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1556
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008427
]
name: aten::matmul
id: 8292
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1557
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008455
]
name: aten::reshape
id: 8293
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1558
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008459
]
name: aten::view
id: 8294
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1559
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008462
]
name: aten::mm
id: 8295
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1560
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008478
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 8296
duration_micros: 400
attr: [name: "rf_id"
int64_val: 1560
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123008522
]
name: aten::mm
id: 8297
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1560
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008522
]
name: aten::_unsafe_view
id: 8299
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1561
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008539
]
name: aten::add
id: 8300
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1562
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008560
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 8301
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1562
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123008582
]
name: aten::add
id: 8302
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1562
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008582
]
name: aten::view
id: 8304
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1563
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008620
]
name: aten::split_with_sizes
id: 8305
duration_micros: 33
attr: [name: "rf_id"
int64_val: 1564
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008644
]
name: aten::as_strided
id: 8306
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1565
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008651
]
name: aten::as_strided
id: 8307
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1566
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008651
]
name: aten::as_strided
id: 8308
duration_micros: 38
attr: [name: "rf_id"
int64_val: 1567
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008669
]
name: aten::view
id: 8309
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1568
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008746
]
name: aten::reshape
id: 8310
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1569
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008772
]
name: aten::_reshape_alias
id: 8311
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1570
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008779
]
name: aten::view
id: 8312
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1571
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008798
]
name: aten::slice
id: 8313
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1572
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008820
]
name: aten::as_strided
id: 8314
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1573
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008825
]
name: aten::view
id: 8315
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1574
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008850
]
name: aten::transpose
id: 8316
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1575
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008862
]
name: aten::as_strided
id: 8317
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1576
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008870
]
name: aten::transpose
id: 8318
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1577
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008888
]
name: aten::as_strided
id: 8319
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1578
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008893
]
name: aten::transpose
id: 8320
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1579
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008909
]
name: aten::as_strided
id: 8321
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1580
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008913
]
name: aten::baddbmm
id: 8322
duration_micros: 33
attr: [name: "rf_id"
int64_val: 1581
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123008967
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 8323
duration_micros: 295
attr: [name: "rf_id"
int64_val: 1581
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123009020
]
name: aten::baddbmm
id: 8324
duration_micros: 33
attr: [name: "rf_id"
int64_val: 1581
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009020
]
name: aten::view
id: 8326
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1582
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009046
]
name: aten::view
id: 8327
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1583
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009046
]
name: ScaledUpperTriangMaskedSoftmax
id: 8328
duration_micros: 62
attr: [name: "rf_id"
int64_val: 1584
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1774
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009100
]
name: aten::empty
id: 8329
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1585
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009112
]
name: aten::to
id: 8330
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1586
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009129
]
name: aten::lift_fresh
id: 8331
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1587
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009139
]
name: aten::detach_
id: 8332
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1588
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009146
]
name: detach_
id: 8333
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1589
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009148
]
name: aten::select
id: 8334
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1590
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009164
]
name: aten::as_strided
id: 8335
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1591
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009169
]
name: aten::item
id: 8336
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1592
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009188
]
name: aten::_local_scalar_dense
id: 8337
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1593
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009190
]
name: aten::empty
id: 8338
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1594
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009206
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 8339
duration_micros: 426
attr: [name: "rf_id"
int64_val: 1594
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123009245
]
name: aten::empty
id: 8340
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1594
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009245
]
name: aten::view
id: 8342
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1595
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009268
]
name: aten::dropout
id: 8343
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1596
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009329
]
name: aten::view
id: 8344
duration_micros: 39
attr: [name: "rf_id"
int64_val: 1597
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009370
]
name: aten::view
id: 8345
duration_micros: 39
attr: [name: "rf_id"
int64_val: 1598
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009370
]
name: aten::transpose
id: 8346
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1599
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009434
]
name: aten::as_strided
id: 8347
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1600
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009440
]
name: aten::bmm
id: 8348
duration_micros: 23
attr: [name: "rf_id"
int64_val: 1601
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009460
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 8349
duration_micros: 185
attr: [name: "rf_id"
int64_val: 1601
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123009495
]
name: aten::bmm
id: 8350
duration_micros: 23
attr: [name: "rf_id"
int64_val: 1601
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009495
]
name: aten::view
id: 8352
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1602
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009516
]
name: aten::permute
id: 8353
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1603
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009534
]
name: aten::as_strided
id: 8354
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1604
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009543
]
name: aten::contiguous
id: 8355
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1605
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009563
]
name: aten::clone
id: 8356
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1606
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009566
]
name: aten::empty_like
id: 8357
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1607
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009570
]
name: aten::empty
id: 8358
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1608
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009574
]
name: aten::copy_
id: 8359
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1609
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009599
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 8360
duration_micros: 20
attr: [name: "rf_id"
int64_val: 1609
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123009616
]
name: aten::copy_
id: 8361
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1609
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009616
]
name: aten::view
id: 8363
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1610
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009655
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8364
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1611
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1775
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009713
]
name: aten::t
id: 8365
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1612
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009722
]
name: aten::transpose
id: 8366
duration_micros: 41
attr: [name: "rf_id"
int64_val: 1613
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009725
]
name: aten::as_strided
id: 8367
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1614
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009731
]
name: aten::matmul
id: 8368
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1615
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009793
]
name: aten::reshape
id: 8369
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1616
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009798
]
name: aten::view
id: 8370
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1617
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009801
]
name: aten::mm
id: 8371
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1618
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009817
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 8372
duration_micros: 162
attr: [name: "rf_id"
int64_val: 1618
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123009860
]
name: aten::mm
id: 8373
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1618
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009860
]
name: aten::_unsafe_view
id: 8375
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1619
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009877
]
name: _ReduceFromModelParallelRegion
id: 8376
duration_micros: 60
attr: [name: "rf_id"
int64_val: 1620
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1776
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009913
]
name: c10d::allreduce_
id: 8377
duration_micros: 29
attr: [name: "rf_id"
int64_val: 1621
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009940
]
name: record_param_comms
id: 8378
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1622
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009951
]
name: nccl:all_reduce
id: 8379
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1623
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009967
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 8380
duration_micros: 5090
attr: [name: "rf_id"
int64_val: 1623
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123009983
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 8381
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1623
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123009983
]
name: record_param_comms
id: 8383
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1624
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010053
]
name: aten::view_as
id: 8384
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1625
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010076
]
name: aten::view
id: 8385
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1626
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010080
]
name: aten::expand_as
id: 8386
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1627
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010123
]
name: aten::expand
id: 8387
duration_micros: 45
attr: [name: "rf_id"
int64_val: 1628
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010127
]
name: aten::as_strided
id: 8388
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1629
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010133
]
name: TorchDynamo Cache Lookup
id: 8389
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1630
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010212
]
name: Torch-Compiled Region
id: 8390
duration_micros: 71
attr: [name: "rf_id"
int64_val: 1631
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010224
]
name: aten::empty
id: 8391
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1632
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010264
]
name: triton_poi_fused_add_0
id: 8392
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1633
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010295
]
name: triton__0d1d2d3d4de
id: 8393
duration_micros: 114
attr: [name: "rf_id"
int64_val: 1633
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123010312
]
name: triton_poi_fused_add_0
id: 8394
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1633
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010312
]
name: FusedLayerNormAffineFunction
id: 8396
duration_micros: 48
attr: [name: "rf_id"
int64_val: 1634
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1777
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010387
]
name: aten::empty_like
id: 8397
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1635
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010399
]
name: aten::empty_strided
id: 8398
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1636
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010405
]
name: aten::empty
id: 8399
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1637
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010436
]
name: aten::empty_like
id: 8400
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1638
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010451
]
name: aten::empty_strided
id: 8401
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1639
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010455
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 8402
duration_micros: 135
attr: [name: "rf_id"
int64_val: 1639
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123010486
]
name: aten::empty_strided
id: 8403
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1639
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010486
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8405
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1640
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1778
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010548
]
name: aten::t
id: 8406
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1641
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010557
]
name: aten::transpose
id: 8407
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1642
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010561
]
name: aten::as_strided
id: 8408
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1643
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010567
]
name: aten::matmul
id: 8409
duration_micros: 24
attr: [name: "rf_id"
int64_val: 1644
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010595
]
name: aten::reshape
id: 8410
duration_micros: 39
attr: [name: "rf_id"
int64_val: 1645
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010599
]
name: aten::view
id: 8411
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1646
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010602
]
name: aten::mm
id: 8412
duration_micros: 32
attr: [name: "rf_id"
int64_val: 1647
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010651
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 8413
duration_micros: 522
attr: [name: "rf_id"
int64_val: 1647
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123010699
]
name: aten::mm
id: 8414
duration_micros: 32
attr: [name: "rf_id"
int64_val: 1647
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010699
]
name: aten::_unsafe_view
id: 8416
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1648
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010724
]
name: GeLUFunction
id: 8417
duration_micros: 41
attr: [name: "rf_id"
int64_val: 1649
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1779
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010778
]
name: TorchDynamo Cache Lookup
id: 8418
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1650
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010801
]
name: Torch-Compiled Region
id: 8419
duration_micros: 81
attr: [name: "rf_id"
int64_val: 1651
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010814
]
name: aten::empty
id: 8420
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1652
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010858
]
name: triton_poi_fused_add_mul_tanh_0
id: 8421
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1653
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010898
]
name: triton__0d1d2d3de
id: 8422
duration_micros: 43
attr: [name: "rf_id"
int64_val: 1653
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123010917
]
name: triton_poi_fused_add_mul_tanh_0
id: 8423
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1653
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123010917
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8425
duration_micros: 65
attr: [name: "rf_id"
int64_val: 1654
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1780
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011016
]
name: aten::t
id: 8426
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1655
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011027
]
name: aten::transpose
id: 8427
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1656
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011031
]
name: aten::as_strided
id: 8428
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1657
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011040
]
name: aten::matmul
id: 8429
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1658
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011079
]
name: aten::reshape
id: 8430
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1659
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011085
]
name: aten::view
id: 8431
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1660
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011089
]
name: aten::mm
id: 8432
duration_micros: 37
attr: [name: "rf_id"
int64_val: 1661
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011113
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 8433
duration_micros: 566
attr: [name: "rf_id"
int64_val: 1661
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123011173
]
name: aten::mm
id: 8434
duration_micros: 37
attr: [name: "rf_id"
int64_val: 1661
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011173
]
name: aten::_unsafe_view
id: 8436
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1662
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011196
]
name: _ReduceFromModelParallelRegion
id: 8437
duration_micros: 79
attr: [name: "rf_id"
int64_val: 1663
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1781
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011282
]
name: c10d::allreduce_
id: 8438
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1664
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011326
]
name: record_param_comms
id: 8439
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1665
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011338
]
name: nccl:all_reduce
id: 8440
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1666
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011355
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 8441
duration_micros: 13247
attr: [name: "rf_id"
int64_val: 1666
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123011371
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 8442
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1666
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011371
]
name: record_param_comms
id: 8444
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1667
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011449
]
name: aten::view_as
id: 8445
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1668
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011472
]
name: aten::view
id: 8446
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1669
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011477
]
name: aten::expand_as
id: 8447
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1670
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011516
]
name: aten::expand
id: 8448
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1671
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011520
]
name: aten::as_strided
id: 8449
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1672
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011527
]
name: TorchDynamo Cache Lookup
id: 8450
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1673
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011569
]
name: Torch-Compiled Region
id: 8451
duration_micros: 67
attr: [name: "rf_id"
int64_val: 1674
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011581
]
name: aten::empty
id: 8452
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1675
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011618
]
name: triton_poi_fused_add_0
id: 8453
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1676
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011648
]
name: triton__0d1d2d3d4de
id: 8454
duration_micros: 113
attr: [name: "rf_id"
int64_val: 1676
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123011664
]
name: triton_poi_fused_add_0
id: 8455
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1676
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011664
]
name: FusedLayerNormAffineFunction
id: 8457
duration_micros: 52
attr: [name: "rf_id"
int64_val: 1677
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1782
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011769
]
name: aten::empty_like
id: 8458
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1678
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011780
]
name: aten::empty_strided
id: 8459
duration_micros: 21
attr: [name: "rf_id"
int64_val: 1679
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011787
]
name: aten::empty
id: 8460
duration_micros: 45
attr: [name: "rf_id"
int64_val: 1680
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011820
]
name: aten::empty_like
id: 8461
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1681
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011871
]
name: aten::empty_strided
id: 8462
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1682
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011876
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 8463
duration_micros: 136
attr: [name: "rf_id"
int64_val: 1682
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123011915
]
name: aten::empty_strided
id: 8464
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1682
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011915
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8466
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1683
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1783
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011983
]
name: aten::t
id: 8467
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1684
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011992
]
name: aten::transpose
id: 8468
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1685
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123011996
]
name: aten::as_strided
id: 8469
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1686
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012002
]
name: aten::matmul
id: 8470
duration_micros: 20
attr: [name: "rf_id"
int64_val: 1687
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012030
]
name: aten::reshape
id: 8471
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1688
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012035
]
name: aten::view
id: 8472
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1689
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012038
]
name: aten::mm
id: 8473
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1690
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012053
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 8474
duration_micros: 400
attr: [name: "rf_id"
int64_val: 1690
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123012100
]
name: aten::mm
id: 8475
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1690
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012100
]
name: aten::_unsafe_view
id: 8477
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1691
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012120
]
name: aten::add
id: 8478
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1692
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012141
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 8479
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1692
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123012163
]
name: aten::add
id: 8480
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1692
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012163
]
name: aten::view
id: 8482
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1693
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012202
]
name: aten::split_with_sizes
id: 8483
duration_micros: 31
attr: [name: "rf_id"
int64_val: 1694
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012226
]
name: aten::as_strided
id: 8484
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1695
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012233
]
name: aten::as_strided
id: 8485
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1696
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012233
]
name: aten::as_strided
id: 8486
duration_micros: 38
attr: [name: "rf_id"
int64_val: 1697
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012247
]
name: aten::view
id: 8487
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1698
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012323
]
name: aten::reshape
id: 8488
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1699
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012349
]
name: aten::_reshape_alias
id: 8489
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1700
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012356
]
name: aten::view
id: 8490
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1701
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012376
]
name: aten::slice
id: 8491
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1702
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012396
]
name: aten::as_strided
id: 8492
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1703
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012402
]
name: aten::view
id: 8493
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1704
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012426
]
name: aten::transpose
id: 8494
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1705
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012444
]
name: aten::as_strided
id: 8495
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1706
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012449
]
name: aten::transpose
id: 8496
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1707
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012467
]
name: aten::as_strided
id: 8497
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1708
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012472
]
name: aten::transpose
id: 8498
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1709
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012487
]
name: aten::as_strided
id: 8499
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1710
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012491
]
name: aten::baddbmm
id: 8500
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1711
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012544
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 8501
duration_micros: 294
attr: [name: "rf_id"
int64_val: 1711
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123012598
]
name: aten::baddbmm
id: 8502
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1711
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012598
]
name: aten::view
id: 8504
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1712
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012625
]
name: aten::view
id: 8505
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1713
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012625
]
name: ScaledUpperTriangMaskedSoftmax
id: 8506
duration_micros: 66
attr: [name: "rf_id"
int64_val: 1714
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1784
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012683
]
name: aten::empty
id: 8507
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1715
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012696
]
name: aten::to
id: 8508
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1716
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012713
]
name: aten::lift_fresh
id: 8509
duration_micros: 4
attr: [name: "rf_id"
int64_val: 1717
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012724
]
name: aten::detach_
id: 8510
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1718
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012731
]
name: detach_
id: 8511
duration_micros: 3
attr: [name: "rf_id"
int64_val: 1719
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012732
]
name: aten::select
id: 8512
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1720
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012745
]
name: aten::as_strided
id: 8513
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1721
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012750
]
name: aten::item
id: 8514
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1722
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012769
]
name: aten::_local_scalar_dense
id: 8515
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1723
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012771
]
name: aten::empty
id: 8516
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1724
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012787
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 8517
duration_micros: 425
attr: [name: "rf_id"
int64_val: 1724
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123012820
]
name: aten::empty
id: 8518
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1724
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012820
]
name: aten::view
id: 8520
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1725
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012843
]
name: aten::dropout
id: 8521
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1726
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012904
]
name: aten::view
id: 8522
duration_micros: 40
attr: [name: "rf_id"
int64_val: 1727
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012944
]
name: aten::view
id: 8523
duration_micros: 40
attr: [name: "rf_id"
int64_val: 1728
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123012944
]
name: aten::transpose
id: 8524
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1729
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013008
]
name: aten::as_strided
id: 8525
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1730
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013017
]
name: aten::bmm
id: 8526
duration_micros: 23
attr: [name: "rf_id"
int64_val: 1731
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013037
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 8527
duration_micros: 184
attr: [name: "rf_id"
int64_val: 1731
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123013074
]
name: aten::bmm
id: 8528
duration_micros: 23
attr: [name: "rf_id"
int64_val: 1731
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013074
]
name: aten::view
id: 8530
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1732
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013095
]
name: aten::permute
id: 8531
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1733
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013110
]
name: aten::as_strided
id: 8532
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1734
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013116
]
name: aten::contiguous
id: 8533
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1735
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013135
]
name: aten::clone
id: 8534
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1736
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013137
]
name: aten::empty_like
id: 8535
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1737
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013141
]
name: aten::empty
id: 8536
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1738
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013145
]
name: aten::copy_
id: 8537
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1739
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013173
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 8538
duration_micros: 21
attr: [name: "rf_id"
int64_val: 1739
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123013190
]
name: aten::copy_
id: 8539
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1739
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013190
]
name: aten::view
id: 8541
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1740
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013229
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8542
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1741
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1785
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013279
]
name: aten::t
id: 8543
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1742
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013288
]
name: aten::transpose
id: 8544
duration_micros: 43
attr: [name: "rf_id"
int64_val: 1743
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013291
]
name: aten::as_strided
id: 8545
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1744
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013300
]
name: aten::matmul
id: 8546
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1745
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013359
]
name: aten::reshape
id: 8547
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1746
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013364
]
name: aten::view
id: 8548
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1747
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013367
]
name: aten::mm
id: 8549
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1748
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013383
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 8550
duration_micros: 159
attr: [name: "rf_id"
int64_val: 1748
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123013428
]
name: aten::mm
id: 8551
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1748
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013428
]
name: aten::_unsafe_view
id: 8553
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1749
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013444
]
name: _ReduceFromModelParallelRegion
id: 8554
duration_micros: 59
attr: [name: "rf_id"
int64_val: 1750
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1786
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013481
]
name: c10d::allreduce_
id: 8555
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1751
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013507
]
name: record_param_comms
id: 8556
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1752
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013519
]
name: nccl:all_reduce
id: 8557
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1753
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013534
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 8558
duration_micros: 593
attr: [name: "rf_id"
int64_val: 1753
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123013550
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 8559
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1753
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013550
]
name: record_param_comms
id: 8561
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1754
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013621
]
name: aten::view_as
id: 8562
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1755
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013644
]
name: aten::view
id: 8563
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1756
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013648
]
name: aten::expand_as
id: 8564
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1757
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013690
]
name: aten::expand
id: 8565
duration_micros: 23222
attr: [name: "rf_id"
int64_val: 1758
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123013694
]
name: aten::as_strided
id: 8566
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1759
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123036881
]
name: TorchDynamo Cache Lookup
id: 8567
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1760
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123036961
]
name: Torch-Compiled Region
id: 8568
duration_micros: 79
attr: [name: "rf_id"
int64_val: 1761
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123036974
]
name: aten::empty
id: 8569
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1762
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037019
]
name: triton_poi_fused_add_0
id: 8570
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1763
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037062
]
name: triton__0d1d2d3d4de
id: 8571
duration_micros: 113
attr: [name: "rf_id"
int64_val: 1763
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123037079
]
name: triton_poi_fused_add_0
id: 8572
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1763
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037079
]
name: FusedLayerNormAffineFunction
id: 8574
duration_micros: 52
attr: [name: "rf_id"
int64_val: 1764
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1787
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037163
]
name: aten::empty_like
id: 8575
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1765
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037177
]
name: aten::empty_strided
id: 8576
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1766
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037183
]
name: aten::empty
id: 8577
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1767
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037214
]
name: aten::empty_like
id: 8578
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1768
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037230
]
name: aten::empty_strided
id: 8579
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1769
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037233
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 8580
duration_micros: 135
attr: [name: "rf_id"
int64_val: 1769
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123037265
]
name: aten::empty_strided
id: 8581
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1769
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037265
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8583
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1770
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1788
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037330
]
name: aten::t
id: 8584
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1771
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037339
]
name: aten::transpose
id: 8585
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1772
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037342
]
name: aten::as_strided
id: 8586
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1773
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037348
]
name: aten::matmul
id: 8587
duration_micros: 22
attr: [name: "rf_id"
int64_val: 1774
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037377
]
name: aten::reshape
id: 8588
duration_micros: 39
attr: [name: "rf_id"
int64_val: 1775
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037381
]
name: aten::view
id: 8589
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1776
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037384
]
name: aten::mm
id: 8590
duration_micros: 31
attr: [name: "rf_id"
int64_val: 1777
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037433
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 8591
duration_micros: 522
attr: [name: "rf_id"
int64_val: 1777
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123037482
]
name: aten::mm
id: 8592
duration_micros: 31
attr: [name: "rf_id"
int64_val: 1777
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037482
]
name: aten::_unsafe_view
id: 8594
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1778
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037502
]
name: GeLUFunction
id: 8595
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1779
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1789
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037550
]
name: TorchDynamo Cache Lookup
id: 8596
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1780
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037571
]
name: Torch-Compiled Region
id: 8597
duration_micros: 78
attr: [name: "rf_id"
int64_val: 1781
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037581
]
name: aten::empty
id: 8598
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1782
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037618
]
name: triton_poi_fused_add_mul_tanh_0
id: 8599
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1783
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037648
]
name: triton__0d1d2d3de
id: 8600
duration_micros: 43
attr: [name: "rf_id"
int64_val: 1783
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123037665
]
name: triton_poi_fused_add_mul_tanh_0
id: 8601
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1783
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037665
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8603
duration_micros: 55
attr: [name: "rf_id"
int64_val: 1784
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1790
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037755
]
name: aten::t
id: 8604
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1785
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037764
]
name: aten::transpose
id: 8605
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1786
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037768
]
name: aten::as_strided
id: 8606
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1787
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037774
]
name: aten::matmul
id: 8607
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1788
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037803
]
name: aten::reshape
id: 8608
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1789
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037807
]
name: aten::view
id: 8609
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1790
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037810
]
name: aten::mm
id: 8610
duration_micros: 31
attr: [name: "rf_id"
int64_val: 1791
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037825
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 8611
duration_micros: 565
attr: [name: "rf_id"
int64_val: 1791
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123037875
]
name: aten::mm
id: 8612
duration_micros: 31
attr: [name: "rf_id"
int64_val: 1791
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037875
]
name: aten::_unsafe_view
id: 8614
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1792
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037893
]
name: _ReduceFromModelParallelRegion
id: 8615
duration_micros: 66
attr: [name: "rf_id"
int64_val: 1793
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1791
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037962
]
name: c10d::allreduce_
id: 8616
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1794
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123037993
]
name: record_param_comms
id: 8617
duration_micros: 28
attr: [name: "rf_id"
int64_val: 1795
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038005
]
name: nccl:all_reduce
id: 8618
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1796
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038022
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 8619
duration_micros: 603
attr: [name: "rf_id"
int64_val: 1796
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123038040
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 8620
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1796
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038040
]
name: record_param_comms
id: 8622
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1797
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038115
]
name: aten::view_as
id: 8623
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1798
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038138
]
name: aten::view
id: 8624
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1799
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038142
]
name: aten::expand_as
id: 8625
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1800
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038182
]
name: aten::expand
id: 8626
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1801
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038190
]
name: aten::as_strided
id: 8627
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1802
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038197
]
name: TorchDynamo Cache Lookup
id: 8628
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1803
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038241
]
name: Torch-Compiled Region
id: 8629
duration_micros: 68
attr: [name: "rf_id"
int64_val: 1804
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038252
]
name: aten::empty
id: 8630
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1805
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038290
]
name: triton_poi_fused_add_0
id: 8631
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1806
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038320
]
name: triton__0d1d2d3d4de
id: 8632
duration_micros: 113
attr: [name: "rf_id"
int64_val: 1806
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123038337
]
name: triton_poi_fused_add_0
id: 8633
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1806
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038337
]
name: FusedLayerNormAffineFunction
id: 8635
duration_micros: 53
attr: [name: "rf_id"
int64_val: 1807
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1792
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038444
]
name: aten::empty_like
id: 8636
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1808
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038456
]
name: aten::empty_strided
id: 8637
duration_micros: 21
attr: [name: "rf_id"
int64_val: 1809
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038462
]
name: aten::empty
id: 8638
duration_micros: 46
attr: [name: "rf_id"
int64_val: 1810
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038495
]
name: aten::empty_like
id: 8639
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1811
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038547
]
name: aten::empty_strided
id: 8640
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1812
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038552
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 8641
duration_micros: 140
attr: [name: "rf_id"
int64_val: 1812
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123038592
]
name: aten::empty_strided
id: 8642
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1812
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038592
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8644
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1813
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1793
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038660
]
name: aten::t
id: 8645
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1814
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038669
]
name: aten::transpose
id: 8646
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1815
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038672
]
name: aten::as_strided
id: 8647
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1816
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038682
]
name: aten::matmul
id: 8648
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1817
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038714
]
name: aten::reshape
id: 8649
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1818
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038718
]
name: aten::view
id: 8650
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1819
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038721
]
name: aten::mm
id: 8651
duration_micros: 29
attr: [name: "rf_id"
int64_val: 1820
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038737
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 8652
duration_micros: 400
attr: [name: "rf_id"
int64_val: 1820
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123038783
]
name: aten::mm
id: 8653
duration_micros: 29
attr: [name: "rf_id"
int64_val: 1820
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038783
]
name: aten::_unsafe_view
id: 8655
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1821
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038801
]
name: aten::add
id: 8656
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1822
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038823
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 8657
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1822
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123038846
]
name: aten::add
id: 8658
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1822
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038846
]
name: aten::view
id: 8660
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1823
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038884
]
name: aten::split_with_sizes
id: 8661
duration_micros: 32
attr: [name: "rf_id"
int64_val: 1824
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038908
]
name: aten::as_strided
id: 8662
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1825
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038915
]
name: aten::as_strided
id: 8663
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1826
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038915
]
name: aten::as_strided
id: 8664
duration_micros: 37
attr: [name: "rf_id"
int64_val: 1827
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123038929
]
name: aten::view
id: 8665
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1828
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039004
]
name: aten::reshape
id: 8666
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1829
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039030
]
name: aten::_reshape_alias
id: 8667
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1830
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039037
]
name: aten::view
id: 8668
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1831
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039061
]
name: aten::slice
id: 8669
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1832
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039082
]
name: aten::as_strided
id: 8670
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1833
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039087
]
name: aten::view
id: 8671
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1834
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039112
]
name: aten::transpose
id: 8672
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1835
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039125
]
name: aten::as_strided
id: 8673
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1836
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039131
]
name: aten::transpose
id: 8674
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1837
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039148
]
name: aten::as_strided
id: 8675
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1838
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039153
]
name: aten::transpose
id: 8676
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1839
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039169
]
name: aten::as_strided
id: 8677
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1840
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039173
]
name: aten::baddbmm
id: 8678
duration_micros: 38
attr: [name: "rf_id"
int64_val: 1841
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039226
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 8679
duration_micros: 293
attr: [name: "rf_id"
int64_val: 1841
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123039288
]
name: aten::baddbmm
id: 8680
duration_micros: 38
attr: [name: "rf_id"
int64_val: 1841
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039288
]
name: aten::view
id: 8682
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1842
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039316
]
name: aten::view
id: 8683
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1843
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039316
]
name: ScaledUpperTriangMaskedSoftmax
id: 8684
duration_micros: 65
attr: [name: "rf_id"
int64_val: 1844
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1794
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039371
]
name: aten::empty
id: 8685
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1845
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039384
]
name: aten::to
id: 8686
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1846
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039401
]
name: aten::lift_fresh
id: 8687
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1847
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039411
]
name: aten::detach_
id: 8688
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1848
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039418
]
name: detach_
id: 8689
duration_micros: 2
attr: [name: "rf_id"
int64_val: 1849
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039420
]
name: aten::select
id: 8690
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1850
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039433
]
name: aten::as_strided
id: 8691
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1851
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039438
]
name: aten::item
id: 8692
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1852
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039458
]
name: aten::_local_scalar_dense
id: 8693
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1853
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039460
]
name: aten::empty
id: 8694
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1854
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039476
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 8695
duration_micros: 425
attr: [name: "rf_id"
int64_val: 1854
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123039507
]
name: aten::empty
id: 8696
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1854
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039507
]
name: aten::view
id: 8698
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1855
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039529
]
name: aten::dropout
id: 8699
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1856
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039590
]
name: aten::view
id: 8700
duration_micros: 39
attr: [name: "rf_id"
int64_val: 1857
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039634
]
name: aten::view
id: 8701
duration_micros: 39
attr: [name: "rf_id"
int64_val: 1858
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039634
]
name: aten::transpose
id: 8702
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1859
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039698
]
name: aten::as_strided
id: 8703
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1860
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039704
]
name: aten::bmm
id: 8704
duration_micros: 23
attr: [name: "rf_id"
int64_val: 1861
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039723
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 8705
duration_micros: 184
attr: [name: "rf_id"
int64_val: 1861
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123039758
]
name: aten::bmm
id: 8706
duration_micros: 23
attr: [name: "rf_id"
int64_val: 1861
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039758
]
name: aten::view
id: 8708
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1862
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039779
]
name: aten::permute
id: 8709
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1863
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039794
]
name: aten::as_strided
id: 8710
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1864
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039800
]
name: aten::contiguous
id: 8711
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1865
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039820
]
name: aten::clone
id: 8712
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1866
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039822
]
name: aten::empty_like
id: 8713
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1867
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039826
]
name: aten::empty
id: 8714
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1868
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039830
]
name: aten::copy_
id: 8715
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1869
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039859
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 8716
duration_micros: 21
attr: [name: "rf_id"
int64_val: 1869
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123039875
]
name: aten::copy_
id: 8717
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1869
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039875
]
name: aten::view
id: 8719
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1870
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039915
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8720
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1871
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1795
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039965
]
name: aten::t
id: 8721
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1872
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039974
]
name: aten::transpose
id: 8722
duration_micros: 40
attr: [name: "rf_id"
int64_val: 1873
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039977
]
name: aten::as_strided
id: 8723
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1874
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123039982
]
name: aten::matmul
id: 8724
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1875
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040041
]
name: aten::reshape
id: 8725
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1876
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040046
]
name: aten::view
id: 8726
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1877
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040050
]
name: aten::mm
id: 8727
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1878
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040065
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 8728
duration_micros: 159
attr: [name: "rf_id"
int64_val: 1878
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123040108
]
name: aten::mm
id: 8729
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1878
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040108
]
name: aten::_unsafe_view
id: 8731
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1879
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040125
]
name: _ReduceFromModelParallelRegion
id: 8732
duration_micros: 69
attr: [name: "rf_id"
int64_val: 1880
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1796
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040162
]
name: c10d::allreduce_
id: 8733
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1881
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040196
]
name: record_param_comms
id: 8734
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1882
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040207
]
name: nccl:all_reduce
id: 8735
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1883
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040223
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 8736
duration_micros: 9799
attr: [name: "rf_id"
int64_val: 1883
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123040240
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 8737
duration_micros: 27
attr: [name: "rf_id"
int64_val: 1883
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040240
]
name: record_param_comms
id: 8739
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1884
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040312
]
name: aten::view_as
id: 8740
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1885
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040335
]
name: aten::view
id: 8741
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1886
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040339
]
name: aten::expand_as
id: 8742
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1887
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040382
]
name: aten::expand
id: 8743
duration_micros: 45
attr: [name: "rf_id"
int64_val: 1888
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040386
]
name: aten::as_strided
id: 8744
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1889
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040393
]
name: TorchDynamo Cache Lookup
id: 8745
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1890
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040471
]
name: Torch-Compiled Region
id: 8746
duration_micros: 70
attr: [name: "rf_id"
int64_val: 1891
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040483
]
name: aten::empty
id: 8747
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1892
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040523
]
name: triton_poi_fused_add_0
id: 8748
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1893
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040554
]
name: triton__0d1d2d3d4de
id: 8749
duration_micros: 113
attr: [name: "rf_id"
int64_val: 1893
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123040571
]
name: triton_poi_fused_add_0
id: 8750
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1893
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040571
]
name: FusedLayerNormAffineFunction
id: 8752
duration_micros: 47
attr: [name: "rf_id"
int64_val: 1894
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1797
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040648
]
name: aten::empty_like
id: 8753
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1895
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040659
]
name: aten::empty_strided
id: 8754
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1896
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040665
]
name: aten::empty
id: 8755
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1897
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040696
]
name: aten::empty_like
id: 8756
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1898
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040711
]
name: aten::empty_strided
id: 8757
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1899
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040715
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 8758
duration_micros: 138
attr: [name: "rf_id"
int64_val: 1899
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123040747
]
name: aten::empty_strided
id: 8759
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1899
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040747
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8761
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1900
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1798
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040809
]
name: aten::t
id: 8762
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1901
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040818
]
name: aten::transpose
id: 8763
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1902
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040822
]
name: aten::as_strided
id: 8764
duration_micros: 12
attr: [name: "rf_id"
int64_val: 1903
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040831
]
name: aten::matmul
id: 8765
duration_micros: 13043
attr: [name: "rf_id"
int64_val: 1904
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123040861
]
name: aten::reshape
id: 8766
duration_micros: 39
attr: [name: "rf_id"
int64_val: 1905
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123053885
]
name: aten::view
id: 8767
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1906
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123053888
]
name: aten::mm
id: 8768
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1907
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123053942
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 8769
duration_micros: 523
attr: [name: "rf_id"
int64_val: 1907
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123053991
]
name: aten::mm
id: 8770
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1907
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123053991
]
name: aten::_unsafe_view
id: 8772
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1908
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054011
]
name: GeLUFunction
id: 8773
duration_micros: 32
attr: [name: "rf_id"
int64_val: 1909
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1799
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054057
]
name: TorchDynamo Cache Lookup
id: 8774
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1910
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054079
]
name: Torch-Compiled Region
id: 8775
duration_micros: 70
attr: [name: "rf_id"
int64_val: 1911
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054089
]
name: aten::empty
id: 8776
duration_micros: 19
attr: [name: "rf_id"
int64_val: 1912
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054128
]
name: triton_poi_fused_add_mul_tanh_0
id: 8777
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1913
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054159
]
name: triton__0d1d2d3de
id: 8778
duration_micros: 43
attr: [name: "rf_id"
int64_val: 1913
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123054176
]
name: triton_poi_fused_add_mul_tanh_0
id: 8779
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1913
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054176
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8781
duration_micros: 52
attr: [name: "rf_id"
int64_val: 1914
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1800
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054254
]
name: aten::t
id: 8782
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1915
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054262
]
name: aten::transpose
id: 8783
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1916
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054266
]
name: aten::as_strided
id: 8784
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1917
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054272
]
name: aten::matmul
id: 8785
duration_micros: 17
attr: [name: "rf_id"
int64_val: 1918
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054301
]
name: aten::reshape
id: 8786
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1919
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054305
]
name: aten::view
id: 8787
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1920
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054308
]
name: aten::mm
id: 8788
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1921
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054323
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 8789
duration_micros: 567
attr: [name: "rf_id"
int64_val: 1921
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123054372
]
name: aten::mm
id: 8790
duration_micros: 30
attr: [name: "rf_id"
int64_val: 1921
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054372
]
name: aten::_unsafe_view
id: 8792
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1922
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054390
]
name: _ReduceFromModelParallelRegion
id: 8793
duration_micros: 62
attr: [name: "rf_id"
int64_val: 1923
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1801
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054463
]
name: c10d::allreduce_
id: 8794
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1924
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054491
]
name: record_param_comms
id: 8795
duration_micros: 26
attr: [name: "rf_id"
int64_val: 1925
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054502
]
name: nccl:all_reduce
id: 8796
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1926
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054519
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 8797
duration_micros: 620
attr: [name: "rf_id"
int64_val: 1926
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123054536
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 8798
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1926
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054536
]
name: record_param_comms
id: 8800
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1927
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054605
]
name: aten::view_as
id: 8801
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1928
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054628
]
name: aten::view
id: 8802
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1929
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054632
]
name: aten::expand_as
id: 8803
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1930
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054671
]
name: aten::expand
id: 8804
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1931
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054675
]
name: aten::as_strided
id: 8805
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1932
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054681
]
name: TorchDynamo Cache Lookup
id: 8806
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1933
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054727
]
name: Torch-Compiled Region
id: 8807
duration_micros: 67
attr: [name: "rf_id"
int64_val: 1934
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054739
]
name: aten::empty
id: 8808
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1935
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054777
]
name: triton_poi_fused_add_0
id: 8809
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1936
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054807
]
name: triton__0d1d2d3d4de
id: 8810
duration_micros: 113
attr: [name: "rf_id"
int64_val: 1936
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123054824
]
name: triton_poi_fused_add_0
id: 8811
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1936
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054824
]
name: FusedLayerNormAffineFunction
id: 8813
duration_micros: 57
attr: [name: "rf_id"
int64_val: 1937
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1802
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054930
]
name: aten::empty_like
id: 8814
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1938
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054942
]
name: aten::empty_strided
id: 8815
duration_micros: 25
attr: [name: "rf_id"
int64_val: 1939
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054949
]
name: aten::empty
id: 8816
duration_micros: 46
attr: [name: "rf_id"
int64_val: 1940
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123054987
]
name: aten::empty_like
id: 8817
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1941
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123055039
]
name: aten::empty_strided
id: 8818
duration_micros: 2446
attr: [name: "rf_id"
int64_val: 1942
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123055044
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 8819
duration_micros: 136
attr: [name: "rf_id"
int64_val: 1942
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123059966
]
name: aten::empty_strided
id: 8820
duration_micros: 2446
attr: [name: "rf_id"
int64_val: 1942
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123059966
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8822
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1943
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1803
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060037
]
name: aten::t
id: 8823
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1944
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060046
]
name: aten::transpose
id: 8824
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1945
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060050
]
name: aten::as_strided
id: 8825
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1946
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060056
]
name: aten::matmul
id: 8826
duration_micros: 18
attr: [name: "rf_id"
int64_val: 1947
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060084
]
name: aten::reshape
id: 8827
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1948
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060088
]
name: aten::view
id: 8828
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1949
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060091
]
name: aten::mm
id: 8829
duration_micros: 31
attr: [name: "rf_id"
int64_val: 1950
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060106
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 8830
duration_micros: 400
attr: [name: "rf_id"
int64_val: 1950
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123060156
]
name: aten::mm
id: 8831
duration_micros: 31
attr: [name: "rf_id"
int64_val: 1950
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060156
]
name: aten::_unsafe_view
id: 8833
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1951
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060174
]
name: aten::add
id: 8834
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1952
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060195
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 8835
duration_micros: 54
attr: [name: "rf_id"
int64_val: 1952
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123060217
]
name: aten::add
id: 8836
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1952
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060217
]
name: aten::view
id: 8838
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1953
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060254
]
name: aten::split_with_sizes
id: 8839
duration_micros: 34
attr: [name: "rf_id"
int64_val: 1954
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060279
]
name: aten::as_strided
id: 8840
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1955
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060285
]
name: aten::as_strided
id: 8841
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1956
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060285
]
name: aten::as_strided
id: 8842
duration_micros: 39
attr: [name: "rf_id"
int64_val: 1957
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060299
]
name: aten::view
id: 8843
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1958
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060379
]
name: aten::reshape
id: 8844
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1959
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060404
]
name: aten::_reshape_alias
id: 8845
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1960
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060412
]
name: aten::view
id: 8846
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1961
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060431
]
name: aten::slice
id: 8847
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1962
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060452
]
name: aten::as_strided
id: 8848
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1963
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060458
]
name: aten::view
id: 8849
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1964
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060483
]
name: aten::transpose
id: 8850
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1965
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060495
]
name: aten::as_strided
id: 8851
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1966
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060501
]
name: aten::transpose
id: 8852
duration_micros: 10
attr: [name: "rf_id"
int64_val: 1967
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060518
]
name: aten::as_strided
id: 8853
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1968
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060523
]
name: aten::transpose
id: 8854
duration_micros: 36
attr: [name: "rf_id"
int64_val: 1969
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060539
]
name: aten::as_strided
id: 8855
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1970
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060545
]
name: aten::baddbmm
id: 8856
duration_micros: 33
attr: [name: "rf_id"
int64_val: 1971
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060598
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 8857
duration_micros: 294
attr: [name: "rf_id"
int64_val: 1971
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123060650
]
name: aten::baddbmm
id: 8858
duration_micros: 33
attr: [name: "rf_id"
int64_val: 1971
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060650
]
name: aten::view
id: 8860
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1972
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060678
]
name: aten::view
id: 8861
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1973
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060678
]
name: ScaledUpperTriangMaskedSoftmax
id: 8862
duration_micros: 78
attr: [name: "rf_id"
int64_val: 1974
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1804
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060731
]
name: aten::empty
id: 8863
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1975
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060745
]
name: aten::to
id: 8864
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1976
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060761
]
name: aten::lift_fresh
id: 8865
duration_micros: 5
attr: [name: "rf_id"
int64_val: 1977
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060771
]
name: aten::detach_
id: 8866
duration_micros: 6
attr: [name: "rf_id"
int64_val: 1978
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060779
]
name: detach_
id: 8867
duration_micros: 3
attr: [name: "rf_id"
int64_val: 1979
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060780
]
name: aten::select
id: 8868
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1980
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060806
]
name: aten::as_strided
id: 8869
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1981
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060812
]
name: aten::item
id: 8870
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1982
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060832
]
name: aten::_local_scalar_dense
id: 8871
duration_micros: 7
attr: [name: "rf_id"
int64_val: 1983
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060834
]
name: aten::empty
id: 8872
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1984
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060850
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 8873
duration_micros: 426
attr: [name: "rf_id"
int64_val: 1984
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123060887
]
name: aten::empty
id: 8874
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1984
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060887
]
name: aten::view
id: 8876
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1985
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060909
]
name: aten::dropout
id: 8877
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1986
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123060975
]
name: aten::view
id: 8878
duration_micros: 39
attr: [name: "rf_id"
int64_val: 1987
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061016
]
name: aten::view
id: 8879
duration_micros: 39
attr: [name: "rf_id"
int64_val: 1988
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061016
]
name: aten::transpose
id: 8880
duration_micros: 13
attr: [name: "rf_id"
int64_val: 1989
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061080
]
name: aten::as_strided
id: 8881
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1990
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061086
]
name: aten::bmm
id: 8882
duration_micros: 22
attr: [name: "rf_id"
int64_val: 1991
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061106
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 8883
duration_micros: 185
attr: [name: "rf_id"
int64_val: 1991
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123061140
]
name: aten::bmm
id: 8884
duration_micros: 22
attr: [name: "rf_id"
int64_val: 1991
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061140
]
name: aten::view
id: 8886
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1992
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061161
]
name: aten::permute
id: 8887
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1993
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061176
]
name: aten::as_strided
id: 8888
duration_micros: 8
attr: [name: "rf_id"
int64_val: 1994
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061182
]
name: aten::contiguous
id: 8889
duration_micros: 9
attr: [name: "rf_id"
int64_val: 1995
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061205
]
name: aten::clone
id: 8890
duration_micros: 16
attr: [name: "rf_id"
int64_val: 1996
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061208
]
name: aten::empty_like
id: 8891
duration_micros: 11
attr: [name: "rf_id"
int64_val: 1997
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061212
]
name: aten::empty
id: 8892
duration_micros: 15
attr: [name: "rf_id"
int64_val: 1998
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061216
]
name: aten::copy_
id: 8893
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1999
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061244
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 8894
duration_micros: 20
attr: [name: "rf_id"
int64_val: 1999
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123061262
]
name: aten::copy_
id: 8895
duration_micros: 14
attr: [name: "rf_id"
int64_val: 1999
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061262
]
name: aten::view
id: 8897
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2000
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061302
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8898
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2001
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1805
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061352
]
name: aten::t
id: 8899
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2002
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061361
]
name: aten::transpose
id: 8900
duration_micros: 41
attr: [name: "rf_id"
int64_val: 2003
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061364
]
name: aten::as_strided
id: 8901
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2004
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061370
]
name: aten::matmul
id: 8902
duration_micros: 20
attr: [name: "rf_id"
int64_val: 2005
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061429
]
name: aten::reshape
id: 8903
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2006
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061434
]
name: aten::view
id: 8904
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2007
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061437
]
name: aten::mm
id: 8905
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2008
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061453
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 8906
duration_micros: 158
attr: [name: "rf_id"
int64_val: 2008
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123061496
]
name: aten::mm
id: 8907
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2008
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061496
]
name: aten::_unsafe_view
id: 8909
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2009
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061513
]
name: _ReduceFromModelParallelRegion
id: 8910
duration_micros: 62
attr: [name: "rf_id"
int64_val: 2010
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1806
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061554
]
name: c10d::allreduce_
id: 8911
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2011
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061582
]
name: record_param_comms
id: 8912
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2012
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061594
]
name: nccl:all_reduce
id: 8913
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2013
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061609
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 8914
duration_micros: 605
attr: [name: "rf_id"
int64_val: 2013
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123061626
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 8915
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2013
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061626
]
name: record_param_comms
id: 8917
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2014
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061694
]
name: aten::view_as
id: 8918
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2015
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061726
]
name: aten::view
id: 8919
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2016
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061730
]
name: aten::expand_as
id: 8920
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2017
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061777
]
name: aten::expand
id: 8921
duration_micros: 43
attr: [name: "rf_id"
int64_val: 2018
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061782
]
name: aten::as_strided
id: 8922
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2019
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061788
]
name: TorchDynamo Cache Lookup
id: 8923
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2020
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061866
]
name: Torch-Compiled Region
id: 8924
duration_micros: 72
attr: [name: "rf_id"
int64_val: 2021
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061878
]
name: aten::empty
id: 8925
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2022
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061919
]
name: triton_poi_fused_add_0
id: 8926
duration_micros: 17
attr: [name: "rf_id"
int64_val: 2023
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061950
]
name: triton__0d1d2d3d4de
id: 8927
duration_micros: 114
attr: [name: "rf_id"
int64_val: 2023
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123061968
]
name: triton_poi_fused_add_0
id: 8928
duration_micros: 17
attr: [name: "rf_id"
int64_val: 2023
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123061968
]
name: FusedLayerNormAffineFunction
id: 8930
duration_micros: 48
attr: [name: "rf_id"
int64_val: 2024
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1807
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062044
]
name: aten::empty_like
id: 8931
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2025
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062055
]
name: aten::empty_strided
id: 8932
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2026
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062062
]
name: aten::empty
id: 8933
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2027
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062092
]
name: aten::empty_like
id: 8934
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2028
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062108
]
name: aten::empty_strided
id: 8935
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2029
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062111
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 8936
duration_micros: 140
attr: [name: "rf_id"
int64_val: 2029
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123062143
]
name: aten::empty_strided
id: 8937
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2029
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062143
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8939
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2030
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1808
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062206
]
name: aten::t
id: 8940
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2031
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062215
]
name: aten::transpose
id: 8941
duration_micros: 17
attr: [name: "rf_id"
int64_val: 2032
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062218
]
name: aten::as_strided
id: 8942
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2033
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062229
]
name: aten::matmul
id: 8943
duration_micros: 22
attr: [name: "rf_id"
int64_val: 2034
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062257
]
name: aten::reshape
id: 8944
duration_micros: 39
attr: [name: "rf_id"
int64_val: 2035
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062261
]
name: aten::view
id: 8945
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2036
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062264
]
name: aten::mm
id: 8946
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2037
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062313
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 8947
duration_micros: 522
attr: [name: "rf_id"
int64_val: 2037
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123062359
]
name: aten::mm
id: 8948
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2037
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062359
]
name: aten::_unsafe_view
id: 8950
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2038
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062380
]
name: GeLUFunction
id: 8951
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2039
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1809
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062425
]
name: TorchDynamo Cache Lookup
id: 8952
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2040
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062445
]
name: Torch-Compiled Region
id: 8953
duration_micros: 69
attr: [name: "rf_id"
int64_val: 2041
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062455
]
name: aten::empty
id: 8954
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2042
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062493
]
name: triton_poi_fused_add_mul_tanh_0
id: 8955
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2043
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062524
]
name: triton__0d1d2d3de
id: 8956
duration_micros: 43
attr: [name: "rf_id"
int64_val: 2043
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123062540
]
name: triton_poi_fused_add_mul_tanh_0
id: 8957
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2043
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062540
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 8959
duration_micros: 53
attr: [name: "rf_id"
int64_val: 2044
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1810
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062617
]
name: aten::t
id: 8960
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2045
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062625
]
name: aten::transpose
id: 8961
duration_micros: 35
attr: [name: "rf_id"
int64_val: 2046
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062629
]
name: aten::as_strided
id: 8962
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2047
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062657
]
name: aten::matmul
id: 8963
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2048
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062687
]
name: aten::reshape
id: 8964
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2049
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062691
]
name: aten::view
id: 8965
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2050
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062694
]
name: aten::mm
id: 8966
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2051
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062717
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 8967
duration_micros: 567
attr: [name: "rf_id"
int64_val: 2051
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123062767
]
name: aten::mm
id: 8968
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2051
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062767
]
name: aten::_unsafe_view
id: 8970
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2052
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062785
]
name: _ReduceFromModelParallelRegion
id: 8971
duration_micros: 69
attr: [name: "rf_id"
int64_val: 2053
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1811
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062854
]
name: c10d::allreduce_
id: 8972
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2054
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062889
]
name: record_param_comms
id: 8973
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2055
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062900
]
name: nccl:all_reduce
id: 8974
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2056
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062917
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 8975
duration_micros: 620
attr: [name: "rf_id"
int64_val: 2056
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123062934
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 8976
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2056
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123062934
]
name: record_param_comms
id: 8978
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2057
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063005
]
name: aten::view_as
id: 8979
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2058
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063029
]
name: aten::view
id: 8980
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2059
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063033
]
name: aten::expand_as
id: 8981
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2060
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063072
]
name: aten::expand
id: 8982
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2061
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063076
]
name: aten::as_strided
id: 8983
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2062
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063082
]
name: TorchDynamo Cache Lookup
id: 8984
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2063
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063124
]
name: Torch-Compiled Region
id: 8985
duration_micros: 65
attr: [name: "rf_id"
int64_val: 2064
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063136
]
name: aten::empty
id: 8986
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2065
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063173
]
name: triton_poi_fused_add_0
id: 8987
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2066
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063202
]
name: triton__0d1d2d3d4de
id: 8988
duration_micros: 113
attr: [name: "rf_id"
int64_val: 2066
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123063219
]
name: triton_poi_fused_add_0
id: 8989
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2066
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063219
]
name: FusedLayerNormAffineFunction
id: 8991
duration_micros: 10299
attr: [name: "rf_id"
int64_val: 2067
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1812
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063324
]
name: aten::empty_like
id: 8992
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2068
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063336
]
name: aten::empty_strided
id: 8993
duration_micros: 20
attr: [name: "rf_id"
int64_val: 2069
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063343
]
name: aten::empty
id: 8994
duration_micros: 44
attr: [name: "rf_id"
int64_val: 2070
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063376
]
name: aten::empty_like
id: 8995
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2071
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063426
]
name: aten::empty_strided
id: 8996
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2072
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123063431
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 8997
duration_micros: 137
attr: [name: "rf_id"
int64_val: 2072
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123073715
]
name: aten::empty_strided
id: 8998
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2072
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073715
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9000
duration_micros: 34
attr: [name: "rf_id"
int64_val: 2073
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1813
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073784
]
name: aten::t
id: 9001
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2074
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073793
]
name: aten::transpose
id: 9002
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2075
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073797
]
name: aten::as_strided
id: 9003
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2076
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073803
]
name: aten::matmul
id: 9004
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2077
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073831
]
name: aten::reshape
id: 9005
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2078
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073835
]
name: aten::view
id: 9006
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2079
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073838
]
name: aten::mm
id: 9007
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2080
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073853
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 9008
duration_micros: 399
attr: [name: "rf_id"
int64_val: 2080
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123073904
]
name: aten::mm
id: 9009
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2080
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073904
]
name: aten::_unsafe_view
id: 9011
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2081
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073921
]
name: aten::add
id: 9012
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2082
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073943
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 9013
duration_micros: 54
attr: [name: "rf_id"
int64_val: 2082
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123073963
]
name: aten::add
id: 9014
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2082
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123073963
]
name: aten::view
id: 9016
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2083
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074001
]
name: aten::split_with_sizes
id: 9017
duration_micros: 32
attr: [name: "rf_id"
int64_val: 2084
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074026
]
name: aten::as_strided
id: 9018
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2085
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074033
]
name: aten::as_strided
id: 9019
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2086
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074033
]
name: aten::as_strided
id: 9020
duration_micros: 38
attr: [name: "rf_id"
int64_val: 2087
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074051
]
name: aten::view
id: 9021
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2088
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074127
]
name: aten::reshape
id: 9022
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2089
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074153
]
name: aten::_reshape_alias
id: 9023
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2090
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074161
]
name: aten::view
id: 9024
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2091
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074180
]
name: aten::slice
id: 9025
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2092
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074201
]
name: aten::as_strided
id: 9026
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2093
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074206
]
name: aten::view
id: 9027
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2094
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074231
]
name: aten::transpose
id: 9028
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2095
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074243
]
name: aten::as_strided
id: 9029
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2096
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074251
]
name: aten::transpose
id: 9030
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2097
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074269
]
name: aten::as_strided
id: 9031
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2098
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074274
]
name: aten::transpose
id: 9032
duration_micros: 36
attr: [name: "rf_id"
int64_val: 2099
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074289
]
name: aten::as_strided
id: 9033
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2100
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074294
]
name: aten::baddbmm
id: 9034
duration_micros: 33
attr: [name: "rf_id"
int64_val: 2101
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074347
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 9035
duration_micros: 292
attr: [name: "rf_id"
int64_val: 2101
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123074399
]
name: aten::baddbmm
id: 9036
duration_micros: 33
attr: [name: "rf_id"
int64_val: 2101
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074399
]
name: aten::view
id: 9038
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2102
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074425
]
name: aten::view
id: 9039
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2103
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074425
]
name: ScaledUpperTriangMaskedSoftmax
id: 9040
duration_micros: 66
attr: [name: "rf_id"
int64_val: 2104
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1814
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074479
]
name: aten::empty
id: 9041
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2105
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074492
]
name: aten::to
id: 9042
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2106
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074509
]
name: aten::lift_fresh
id: 9043
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2107
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074519
]
name: aten::detach_
id: 9044
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2108
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074526
]
name: detach_
id: 9045
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2109
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074528
]
name: aten::select
id: 9046
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2110
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074544
]
name: aten::as_strided
id: 9047
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2111
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074550
]
name: aten::item
id: 9048
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2112
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074569
]
name: aten::_local_scalar_dense
id: 9049
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2113
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074571
]
name: aten::empty
id: 9050
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2114
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074587
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 9051
duration_micros: 426
attr: [name: "rf_id"
int64_val: 2114
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123074619
]
name: aten::empty
id: 9052
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2114
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074619
]
name: aten::view
id: 9054
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2115
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074641
]
name: aten::dropout
id: 9055
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2116
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074704
]
name: aten::view
id: 9056
duration_micros: 42
attr: [name: "rf_id"
int64_val: 2117
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074745
]
name: aten::view
id: 9057
duration_micros: 42
attr: [name: "rf_id"
int64_val: 2118
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074745
]
name: aten::transpose
id: 9058
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2119
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074812
]
name: aten::as_strided
id: 9059
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2120
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074818
]
name: aten::bmm
id: 9060
duration_micros: 23
attr: [name: "rf_id"
int64_val: 2121
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074837
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 9061
duration_micros: 183
attr: [name: "rf_id"
int64_val: 2121
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123074872
]
name: aten::bmm
id: 9062
duration_micros: 23
attr: [name: "rf_id"
int64_val: 2121
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074872
]
name: aten::view
id: 9064
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2122
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074893
]
name: aten::permute
id: 9065
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2123
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074912
]
name: aten::as_strided
id: 9066
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2124
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074918
]
name: aten::contiguous
id: 9067
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2125
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074938
]
name: aten::clone
id: 9068
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2126
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074940
]
name: aten::empty_like
id: 9069
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2127
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074944
]
name: aten::empty
id: 9070
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2128
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074948
]
name: aten::copy_
id: 9071
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2129
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074974
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 9072
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2129
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123074991
]
name: aten::copy_
id: 9073
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2129
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123074991
]
name: aten::view
id: 9075
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2130
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123075030
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9076
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2131
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1815
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123075079
]
name: aten::t
id: 9077
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2132
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123075088
]
name: aten::transpose
id: 9078
duration_micros: 41
attr: [name: "rf_id"
int64_val: 2133
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123075091
]
name: aten::as_strided
id: 9079
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2134
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123075096
]
name: aten::matmul
id: 9080
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2135
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123075157
]
name: aten::reshape
id: 9081
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2136
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123075162
]
name: aten::view
id: 9082
duration_micros: 10088
attr: [name: "rf_id"
int64_val: 2137
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123075172
]
name: aten::mm
id: 9083
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2138
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085272
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 9084
duration_micros: 161
attr: [name: "rf_id"
int64_val: 2138
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123085313
]
name: aten::mm
id: 9085
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2138
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085313
]
name: aten::_unsafe_view
id: 9087
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2139
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085331
]
name: _ReduceFromModelParallelRegion
id: 9088
duration_micros: 69
attr: [name: "rf_id"
int64_val: 2140
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1816
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085370
]
name: c10d::allreduce_
id: 9089
duration_micros: 29
attr: [name: "rf_id"
int64_val: 2141
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085405
]
name: record_param_comms
id: 9090
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2142
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085417
]
name: nccl:all_reduce
id: 9091
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2143
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085432
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 9092
duration_micros: 664
attr: [name: "rf_id"
int64_val: 2143
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123085450
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 9093
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2143
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085450
]
name: record_param_comms
id: 9095
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2144
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085519
]
name: aten::view_as
id: 9096
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2145
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085542
]
name: aten::view
id: 9097
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2146
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085546
]
name: aten::expand_as
id: 9098
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2147
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085589
]
name: aten::expand
id: 9099
duration_micros: 48
attr: [name: "rf_id"
int64_val: 2148
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085594
]
name: aten::as_strided
id: 9100
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2149
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085600
]
name: TorchDynamo Cache Lookup
id: 9101
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2150
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085683
]
name: Torch-Compiled Region
id: 9102
duration_micros: 81
attr: [name: "rf_id"
int64_val: 2151
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085695
]
name: aten::empty
id: 9103
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2152
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085744
]
name: triton_poi_fused_add_0
id: 9104
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2153
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085775
]
name: triton__0d1d2d3d4de
id: 9105
duration_micros: 113
attr: [name: "rf_id"
int64_val: 2153
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123085793
]
name: triton_poi_fused_add_0
id: 9106
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2153
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085793
]
name: FusedLayerNormAffineFunction
id: 9108
duration_micros: 49
attr: [name: "rf_id"
int64_val: 2154
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1817
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085870
]
name: aten::empty_like
id: 9109
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2155
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085882
]
name: aten::empty_strided
id: 9110
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2156
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085888
]
name: aten::empty
id: 9111
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2157
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085919
]
name: aten::empty_like
id: 9112
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2158
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085934
]
name: aten::empty_strided
id: 9113
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2159
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085938
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 9114
duration_micros: 137
attr: [name: "rf_id"
int64_val: 2159
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123085970
]
name: aten::empty_strided
id: 9115
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2159
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123085970
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9117
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2160
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1818
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086033
]
name: aten::t
id: 9118
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2161
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086042
]
name: aten::transpose
id: 9119
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2162
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086045
]
name: aten::as_strided
id: 9120
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2163
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086051
]
name: aten::matmul
id: 9121
duration_micros: 22
attr: [name: "rf_id"
int64_val: 2164
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086079
]
name: aten::reshape
id: 9122
duration_micros: 40
attr: [name: "rf_id"
int64_val: 2165
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086083
]
name: aten::view
id: 9123
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2166
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086086
]
name: aten::mm
id: 9124
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2167
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086137
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 9125
duration_micros: 523
attr: [name: "rf_id"
int64_val: 2167
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123086185
]
name: aten::mm
id: 9126
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2167
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086185
]
name: aten::_unsafe_view
id: 9128
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2168
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086204
]
name: GeLUFunction
id: 9129
duration_micros: 33
attr: [name: "rf_id"
int64_val: 2169
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1819
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086250
]
name: TorchDynamo Cache Lookup
id: 9130
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2170
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086271
]
name: Torch-Compiled Region
id: 9131
duration_micros: 68
attr: [name: "rf_id"
int64_val: 2171
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086286
]
name: aten::empty
id: 9132
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2172
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086324
]
name: triton_poi_fused_add_mul_tanh_0
id: 9133
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2173
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086355
]
name: triton__0d1d2d3de
id: 9134
duration_micros: 43
attr: [name: "rf_id"
int64_val: 2173
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123086371
]
name: triton_poi_fused_add_mul_tanh_0
id: 9135
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2173
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086371
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9137
duration_micros: 53
attr: [name: "rf_id"
int64_val: 2174
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1820
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086449
]
name: aten::t
id: 9138
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2175
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086457
]
name: aten::transpose
id: 9139
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2176
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086461
]
name: aten::as_strided
id: 9140
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2177
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086467
]
name: aten::matmul
id: 9141
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2178
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086495
]
name: aten::reshape
id: 9142
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2179
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086499
]
name: aten::view
id: 9143
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2180
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086502
]
name: aten::mm
id: 9144
duration_micros: 29
attr: [name: "rf_id"
int64_val: 2181
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086518
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 9145
duration_micros: 566
attr: [name: "rf_id"
int64_val: 2181
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123086566
]
name: aten::mm
id: 9146
duration_micros: 29
attr: [name: "rf_id"
int64_val: 2181
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086566
]
name: aten::_unsafe_view
id: 9148
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2182
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123086582
]
name: _ReduceFromModelParallelRegion
id: 9149
duration_micros: 62
attr: [name: "rf_id"
int64_val: 2183
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1821
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092082
]
name: c10d::allreduce_
id: 9150
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2184
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092110
]
name: record_param_comms
id: 9151
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2185
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092122
]
name: nccl:all_reduce
id: 9152
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2186
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092138
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 9153
duration_micros: 589
attr: [name: "rf_id"
int64_val: 2186
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123092155
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 9154
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2186
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092155
]
name: record_param_comms
id: 9156
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2187
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092229
]
name: aten::view_as
id: 9157
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2188
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092252
]
name: aten::view
id: 9158
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2189
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092256
]
name: aten::expand_as
id: 9159
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2190
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092295
]
name: aten::expand
id: 9160
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2191
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092299
]
name: aten::as_strided
id: 9161
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2192
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092306
]
name: TorchDynamo Cache Lookup
id: 9162
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2193
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092349
]
name: Torch-Compiled Region
id: 9163
duration_micros: 67
attr: [name: "rf_id"
int64_val: 2194
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092361
]
name: aten::empty
id: 9164
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2195
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092398
]
name: triton_poi_fused_add_0
id: 9165
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2196
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092428
]
name: triton__0d1d2d3d4de
id: 9166
duration_micros: 114
attr: [name: "rf_id"
int64_val: 2196
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123092445
]
name: triton_poi_fused_add_0
id: 9167
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2196
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092445
]
name: FusedLayerNormAffineFunction
id: 9169
duration_micros: 53
attr: [name: "rf_id"
int64_val: 2197
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1822
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092553
]
name: aten::empty_like
id: 9170
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2198
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092565
]
name: aten::empty_strided
id: 9171
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2199
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092571
]
name: aten::empty
id: 9172
duration_micros: 45
attr: [name: "rf_id"
int64_val: 2200
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092605
]
name: aten::empty_like
id: 9173
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2201
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092656
]
name: aten::empty_strided
id: 9174
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2202
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092661
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 9175
duration_micros: 137
attr: [name: "rf_id"
int64_val: 2202
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123092700
]
name: aten::empty_strided
id: 9176
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2202
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092700
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9178
duration_micros: 35
attr: [name: "rf_id"
int64_val: 2203
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1823
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092773
]
name: aten::t
id: 9179
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2204
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092783
]
name: aten::transpose
id: 9180
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2205
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092786
]
name: aten::as_strided
id: 9181
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2206
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092793
]
name: aten::matmul
id: 9182
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2207
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092822
]
name: aten::reshape
id: 9183
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2208
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092826
]
name: aten::view
id: 9184
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2209
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092831
]
name: aten::mm
id: 9185
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2210
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092846
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 9186
duration_micros: 400
attr: [name: "rf_id"
int64_val: 2210
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123092896
]
name: aten::mm
id: 9187
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2210
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092896
]
name: aten::_unsafe_view
id: 9189
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2211
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092914
]
name: aten::add
id: 9190
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2212
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092936
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 9191
duration_micros: 54
attr: [name: "rf_id"
int64_val: 2212
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123092957
]
name: aten::add
id: 9192
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2212
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092957
]
name: aten::view
id: 9194
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2213
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123092995
]
name: aten::split_with_sizes
id: 9195
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2214
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093020
]
name: aten::as_strided
id: 9196
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2215
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093026
]
name: aten::as_strided
id: 9197
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2216
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093026
]
name: aten::as_strided
id: 9198
duration_micros: 36
attr: [name: "rf_id"
int64_val: 2217
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093041
]
name: aten::view
id: 9199
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2218
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093116
]
name: aten::reshape
id: 9200
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2219
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093142
]
name: aten::_reshape_alias
id: 9201
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2220
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093150
]
name: aten::view
id: 9202
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2221
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093170
]
name: aten::slice
id: 9203
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2222
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093191
]
name: aten::as_strided
id: 9204
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2223
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093197
]
name: aten::view
id: 9205
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2224
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093232
]
name: aten::transpose
id: 9206
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2225
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093246
]
name: aten::as_strided
id: 9207
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2226
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093252
]
name: aten::transpose
id: 9208
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2227
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093269
]
name: aten::as_strided
id: 9209
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2228
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093274
]
name: aten::transpose
id: 9210
duration_micros: 35
attr: [name: "rf_id"
int64_val: 2229
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093289
]
name: aten::as_strided
id: 9211
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2230
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093294
]
name: aten::baddbmm
id: 9212
duration_micros: 33
attr: [name: "rf_id"
int64_val: 2231
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093346
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 9213
duration_micros: 295
attr: [name: "rf_id"
int64_val: 2231
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123093398
]
name: aten::baddbmm
id: 9214
duration_micros: 33
attr: [name: "rf_id"
int64_val: 2231
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093398
]
name: aten::view
id: 9216
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2232
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093425
]
name: aten::view
id: 9217
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2233
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093425
]
name: ScaledUpperTriangMaskedSoftmax
id: 9218
duration_micros: 64
attr: [name: "rf_id"
int64_val: 2234
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1824
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093484
]
name: aten::empty
id: 9219
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2235
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093497
]
name: aten::to
id: 9220
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2236
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093513
]
name: aten::lift_fresh
id: 9221
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2237
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093524
]
name: aten::detach_
id: 9222
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2238
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093531
]
name: detach_
id: 9223
duration_micros: 3
attr: [name: "rf_id"
int64_val: 2239
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093533
]
name: aten::select
id: 9224
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2240
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093546
]
name: aten::as_strided
id: 9225
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2241
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093551
]
name: aten::item
id: 9226
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2242
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093570
]
name: aten::_local_scalar_dense
id: 9227
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2243
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093572
]
name: aten::empty
id: 9228
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2244
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093589
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 9229
duration_micros: 425
attr: [name: "rf_id"
int64_val: 2244
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123093620
]
name: aten::empty
id: 9230
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2244
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093620
]
name: aten::view
id: 9232
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2245
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093642
]
name: aten::dropout
id: 9233
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2246
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093712
]
name: aten::view
id: 9234
duration_micros: 39
attr: [name: "rf_id"
int64_val: 2247
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093754
]
name: aten::view
id: 9235
duration_micros: 39
attr: [name: "rf_id"
int64_val: 2248
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093754
]
name: aten::transpose
id: 9236
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2249
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093819
]
name: aten::as_strided
id: 9237
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2250
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093828
]
name: aten::bmm
id: 9238
duration_micros: 23
attr: [name: "rf_id"
int64_val: 2251
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093848
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 9239
duration_micros: 182
attr: [name: "rf_id"
int64_val: 2251
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123093883
]
name: aten::bmm
id: 9240
duration_micros: 23
attr: [name: "rf_id"
int64_val: 2251
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093883
]
name: aten::view
id: 9242
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2252
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093904
]
name: aten::permute
id: 9243
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2253
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093919
]
name: aten::as_strided
id: 9244
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2254
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093925
]
name: aten::contiguous
id: 9245
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2255
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093945
]
name: aten::clone
id: 9246
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2256
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093947
]
name: aten::empty_like
id: 9247
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2257
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093951
]
name: aten::empty
id: 9248
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2258
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093955
]
name: aten::copy_
id: 9249
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2259
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093981
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 9250
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2259
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123093998
]
name: aten::copy_
id: 9251
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2259
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123093998
]
name: aten::view
id: 9253
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2260
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094037
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9254
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2261
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1825
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094087
]
name: aten::t
id: 9255
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2262
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094096
]
name: aten::transpose
id: 9256
duration_micros: 44
attr: [name: "rf_id"
int64_val: 2263
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094099
]
name: aten::as_strided
id: 9257
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2264
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094108
]
name: aten::matmul
id: 9258
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2265
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094168
]
name: aten::reshape
id: 9259
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2266
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094173
]
name: aten::view
id: 9260
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2267
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094176
]
name: aten::mm
id: 9261
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2268
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094192
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 9262
duration_micros: 160
attr: [name: "rf_id"
int64_val: 2268
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123094235
]
name: aten::mm
id: 9263
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2268
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094235
]
name: aten::_unsafe_view
id: 9265
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2269
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094251
]
name: _ReduceFromModelParallelRegion
id: 9266
duration_micros: 61
attr: [name: "rf_id"
int64_val: 2270
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1826
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094288
]
name: c10d::allreduce_
id: 9267
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2271
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094315
]
name: record_param_comms
id: 9268
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2272
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094330
]
name: nccl:all_reduce
id: 9269
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2273
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094346
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 9270
duration_micros: 600
attr: [name: "rf_id"
int64_val: 2273
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123094363
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 9271
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2273
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094363
]
name: record_param_comms
id: 9273
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2274
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094433
]
name: aten::view_as
id: 9274
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2275
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094456
]
name: aten::view
id: 9275
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2276
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094460
]
name: aten::expand_as
id: 9276
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2277
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094503
]
name: aten::expand
id: 9277
duration_micros: 44
attr: [name: "rf_id"
int64_val: 2278
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094507
]
name: aten::as_strided
id: 9278
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2279
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094513
]
name: TorchDynamo Cache Lookup
id: 9279
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2280
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094591
]
name: Torch-Compiled Region
id: 9280
duration_micros: 71
attr: [name: "rf_id"
int64_val: 2281
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094603
]
name: aten::empty
id: 9281
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2282
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094643
]
name: triton_poi_fused_add_0
id: 9282
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2283
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094674
]
name: triton__0d1d2d3d4de
id: 9283
duration_micros: 113
attr: [name: "rf_id"
int64_val: 2283
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123094691
]
name: triton_poi_fused_add_0
id: 9284
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2283
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094691
]
name: FusedLayerNormAffineFunction
id: 9286
duration_micros: 49
attr: [name: "rf_id"
int64_val: 2284
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1827
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094771
]
name: aten::empty_like
id: 9287
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2285
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094783
]
name: aten::empty_strided
id: 9288
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2286
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094789
]
name: aten::empty
id: 9289
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2287
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094820
]
name: aten::empty_like
id: 9290
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2288
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094836
]
name: aten::empty_strided
id: 9291
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2289
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094839
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 9292
duration_micros: 135
attr: [name: "rf_id"
int64_val: 2289
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123094871
]
name: aten::empty_strided
id: 9293
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2289
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094871
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9295
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2290
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1828
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094931
]
name: aten::t
id: 9296
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2291
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094940
]
name: aten::transpose
id: 9297
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2292
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094943
]
name: aten::as_strided
id: 9298
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2293
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094949
]
name: aten::matmul
id: 9299
duration_micros: 23
attr: [name: "rf_id"
int64_val: 2294
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094977
]
name: aten::reshape
id: 9300
duration_micros: 38
attr: [name: "rf_id"
int64_val: 2295
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094982
]
name: aten::view
id: 9301
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2296
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123094985
]
name: aten::mm
id: 9302
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2297
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123095039
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 9303
duration_micros: 523
attr: [name: "rf_id"
int64_val: 2297
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123095087
]
name: aten::mm
id: 9304
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2297
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123095087
]
name: aten::_unsafe_view
id: 9306
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2298
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123095106
]
name: GeLUFunction
id: 9307
duration_micros: 2020
attr: [name: "rf_id"
int64_val: 2299
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1829
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123095151
]
name: TorchDynamo Cache Lookup
id: 9308
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2300
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123095171
]
name: Torch-Compiled Region
id: 9309
duration_micros: 68
attr: [name: "rf_id"
int64_val: 2301
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123095181
]
name: aten::empty
id: 9310
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2302
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123095219
]
name: triton_poi_fused_add_mul_tanh_0
id: 9311
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2303
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123095250
]
name: triton__0d1d2d3de
id: 9312
duration_micros: 43
attr: [name: "rf_id"
int64_val: 2303
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123095265
]
name: triton_poi_fused_add_mul_tanh_0
id: 9313
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2303
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123095265
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9315
duration_micros: 55
attr: [name: "rf_id"
int64_val: 2304
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1830
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097337
]
name: aten::t
id: 9316
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2305
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097346
]
name: aten::transpose
id: 9317
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2306
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097349
]
name: aten::as_strided
id: 9318
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2307
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097355
]
name: aten::matmul
id: 9319
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2308
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097382
]
name: aten::reshape
id: 9320
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2309
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097386
]
name: aten::view
id: 9321
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2310
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097389
]
name: aten::mm
id: 9322
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2311
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097404
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 9323
duration_micros: 566
attr: [name: "rf_id"
int64_val: 2311
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123097455
]
name: aten::mm
id: 9324
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2311
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097455
]
name: aten::_unsafe_view
id: 9326
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2312
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097473
]
name: _ReduceFromModelParallelRegion
id: 9327
duration_micros: 68
attr: [name: "rf_id"
int64_val: 2313
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1831
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097544
]
name: c10d::allreduce_
id: 9328
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2314
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097578
]
name: record_param_comms
id: 9329
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2315
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097590
]
name: nccl:all_reduce
id: 9330
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2316
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097607
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 9331
duration_micros: 593
attr: [name: "rf_id"
int64_val: 2316
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123097626
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 9332
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2316
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097626
]
name: record_param_comms
id: 9334
duration_micros: 17
attr: [name: "rf_id"
int64_val: 2317
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097696
]
name: aten::view_as
id: 9335
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2318
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097730
]
name: aten::view
id: 9336
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2319
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097735
]
name: aten::expand_as
id: 9337
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2320
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097778
]
name: aten::expand
id: 9338
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2321
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097782
]
name: aten::as_strided
id: 9339
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2322
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097789
]
name: TorchDynamo Cache Lookup
id: 9340
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2323
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097832
]
name: Torch-Compiled Region
id: 9341
duration_micros: 68
attr: [name: "rf_id"
int64_val: 2324
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097844
]
name: aten::empty
id: 9342
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2325
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097882
]
name: triton_poi_fused_add_0
id: 9343
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2326
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097913
]
name: triton__0d1d2d3d4de
id: 9344
duration_micros: 114
attr: [name: "rf_id"
int64_val: 2326
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123097929
]
name: triton_poi_fused_add_0
id: 9345
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2326
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123097929
]
name: FusedLayerNormAffineFunction
id: 9347
duration_micros: 55
attr: [name: "rf_id"
int64_val: 2327
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1832
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098038
]
name: aten::empty_like
id: 9348
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2328
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098050
]
name: aten::empty_strided
id: 9349
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2329
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098056
]
name: aten::empty
id: 9350
duration_micros: 46
attr: [name: "rf_id"
int64_val: 2330
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098090
]
name: aten::empty_like
id: 9351
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2331
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098142
]
name: aten::empty_strided
id: 9352
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2332
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098147
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 9353
duration_micros: 136
attr: [name: "rf_id"
int64_val: 2332
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123098187
]
name: aten::empty_strided
id: 9354
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2332
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098187
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9356
duration_micros: 34
attr: [name: "rf_id"
int64_val: 2333
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1833
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098255
]
name: aten::t
id: 9357
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2334
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098263
]
name: aten::transpose
id: 9358
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2335
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098271
]
name: aten::as_strided
id: 9359
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2336
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098277
]
name: aten::matmul
id: 9360
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2337
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098305
]
name: aten::reshape
id: 9361
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2338
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098309
]
name: aten::view
id: 9362
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2339
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098312
]
name: aten::mm
id: 9363
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2340
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098328
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 9364
duration_micros: 400
attr: [name: "rf_id"
int64_val: 2340
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123098372
]
name: aten::mm
id: 9365
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2340
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098372
]
name: aten::_unsafe_view
id: 9367
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2341
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098390
]
name: aten::add
id: 9368
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2342
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098412
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 9369
duration_micros: 54
attr: [name: "rf_id"
int64_val: 2342
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123098434
]
name: aten::add
id: 9370
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2342
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098434
]
name: aten::view
id: 9372
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2343
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098471
]
name: aten::split_with_sizes
id: 9373
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2344
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098496
]
name: aten::as_strided
id: 9374
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2345
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098503
]
name: aten::as_strided
id: 9375
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2346
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098503
]
name: aten::as_strided
id: 9376
duration_micros: 38
attr: [name: "rf_id"
int64_val: 2347
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098516
]
name: aten::view
id: 9377
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2348
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098592
]
name: aten::reshape
id: 9378
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2349
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098618
]
name: aten::_reshape_alias
id: 9379
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2350
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098628
]
name: aten::view
id: 9380
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2351
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098648
]
name: aten::slice
id: 9381
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2352
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098669
]
name: aten::as_strided
id: 9382
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2353
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098675
]
name: aten::view
id: 9383
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2354
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098703
]
name: aten::transpose
id: 9384
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2355
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098716
]
name: aten::as_strided
id: 9385
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2356
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098722
]
name: aten::transpose
id: 9386
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2357
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098739
]
name: aten::as_strided
id: 9387
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2358
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098744
]
name: aten::transpose
id: 9388
duration_micros: 38
attr: [name: "rf_id"
int64_val: 2359
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098759
]
name: aten::as_strided
id: 9389
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2360
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098764
]
name: aten::baddbmm
id: 9390
duration_micros: 36
attr: [name: "rf_id"
int64_val: 2361
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098819
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 9391
duration_micros: 294
attr: [name: "rf_id"
int64_val: 2361
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123098878
]
name: aten::baddbmm
id: 9392
duration_micros: 36
attr: [name: "rf_id"
int64_val: 2361
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098878
]
name: aten::view
id: 9394
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2362
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098905
]
name: aten::view
id: 9395
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2363
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098905
]
name: ScaledUpperTriangMaskedSoftmax
id: 9396
duration_micros: 64
attr: [name: "rf_id"
int64_val: 2364
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1834
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098959
]
name: aten::empty
id: 9397
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2365
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098972
]
name: aten::to
id: 9398
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2366
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098988
]
name: aten::lift_fresh
id: 9399
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2367
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123098999
]
name: aten::detach_
id: 9400
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2368
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099006
]
name: detach_
id: 9401
duration_micros: 3
attr: [name: "rf_id"
int64_val: 2369
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099007
]
name: aten::select
id: 9402
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2370
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099020
]
name: aten::as_strided
id: 9403
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2371
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099025
]
name: aten::item
id: 9404
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2372
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099044
]
name: aten::_local_scalar_dense
id: 9405
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2373
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099046
]
name: aten::empty
id: 9406
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2374
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099062
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 9407
duration_micros: 425
attr: [name: "rf_id"
int64_val: 2374
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123099093
]
name: aten::empty
id: 9408
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2374
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099093
]
name: aten::view
id: 9410
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2375
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099115
]
name: aten::dropout
id: 9411
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2376
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099180
]
name: aten::view
id: 9412
duration_micros: 39
attr: [name: "rf_id"
int64_val: 2377
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099221
]
name: aten::view
id: 9413
duration_micros: 39
attr: [name: "rf_id"
int64_val: 2378
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099221
]
name: aten::transpose
id: 9414
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2379
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099285
]
name: aten::as_strided
id: 9415
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2380
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099291
]
name: aten::bmm
id: 9416
duration_micros: 23
attr: [name: "rf_id"
int64_val: 2381
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099310
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 9417
duration_micros: 185
attr: [name: "rf_id"
int64_val: 2381
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123099346
]
name: aten::bmm
id: 9418
duration_micros: 23
attr: [name: "rf_id"
int64_val: 2381
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099346
]
name: aten::view
id: 9420
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2382
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099367
]
name: aten::permute
id: 9421
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2383
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099382
]
name: aten::as_strided
id: 9422
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2384
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099388
]
name: aten::contiguous
id: 9423
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2385
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099408
]
name: aten::clone
id: 9424
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2386
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099410
]
name: aten::empty_like
id: 9425
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2387
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099414
]
name: aten::empty
id: 9426
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2388
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099421
]
name: aten::copy_
id: 9427
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2389
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099448
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 9428
duration_micros: 20
attr: [name: "rf_id"
int64_val: 2389
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123099465
]
name: aten::copy_
id: 9429
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2389
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099465
]
name: aten::view
id: 9431
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2390
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099504
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9432
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2391
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1835
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099554
]
name: aten::t
id: 9433
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2392
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099567
]
name: aten::transpose
id: 9434
duration_micros: 40
attr: [name: "rf_id"
int64_val: 2393
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099571
]
name: aten::as_strided
id: 9435
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2394
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099577
]
name: aten::matmul
id: 9436
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2395
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099637
]
name: aten::reshape
id: 9437
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2396
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099641
]
name: aten::view
id: 9438
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2397
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099645
]
name: aten::mm
id: 9439
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2398
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099661
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 9440
duration_micros: 161
attr: [name: "rf_id"
int64_val: 2398
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123099704
]
name: aten::mm
id: 9441
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2398
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099704
]
name: aten::_unsafe_view
id: 9443
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2399
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099720
]
name: _ReduceFromModelParallelRegion
id: 9444
duration_micros: 68
attr: [name: "rf_id"
int64_val: 2400
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1836
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099757
]
name: c10d::allreduce_
id: 9445
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2401
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099791
]
name: record_param_comms
id: 9446
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2402
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099802
]
name: nccl:all_reduce
id: 9447
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2403
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099818
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 9448
duration_micros: 19058
attr: [name: "rf_id"
int64_val: 2403
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123099837
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 9449
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2403
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099837
]
name: record_param_comms
id: 9451
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2404
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099905
]
name: aten::view_as
id: 9452
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2405
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099928
]
name: aten::view
id: 9453
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2406
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099932
]
name: aten::expand_as
id: 9454
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2407
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099975
]
name: aten::expand
id: 9455
duration_micros: 45
attr: [name: "rf_id"
int64_val: 2408
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099979
]
name: aten::as_strided
id: 9456
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2409
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123099986
]
name: TorchDynamo Cache Lookup
id: 9457
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2410
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100064
]
name: Torch-Compiled Region
id: 9458
duration_micros: 71
attr: [name: "rf_id"
int64_val: 2411
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100077
]
name: aten::empty
id: 9459
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2412
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100117
]
name: triton_poi_fused_add_0
id: 9460
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2413
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100148
]
name: triton__0d1d2d3d4de
id: 9461
duration_micros: 114
attr: [name: "rf_id"
int64_val: 2413
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123100165
]
name: triton_poi_fused_add_0
id: 9462
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2413
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100165
]
name: FusedLayerNormAffineFunction
id: 9464
duration_micros: 48
attr: [name: "rf_id"
int64_val: 2414
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1837
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100240
]
name: aten::empty_like
id: 9465
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2415
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100252
]
name: aten::empty_strided
id: 9466
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2416
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100258
]
name: aten::empty
id: 9467
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2417
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100289
]
name: aten::empty_like
id: 9468
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2418
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100304
]
name: aten::empty_strided
id: 9469
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2419
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100308
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 9470
duration_micros: 134
attr: [name: "rf_id"
int64_val: 2419
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123100340
]
name: aten::empty_strided
id: 9471
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2419
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100340
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9473
duration_micros: 23
attr: [name: "rf_id"
int64_val: 2420
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1838
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100402
]
name: aten::t
id: 9474
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2421
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100410
]
name: aten::transpose
id: 9475
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2422
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100414
]
name: aten::as_strided
id: 9476
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2423
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100424
]
name: aten::matmul
id: 9477
duration_micros: 22
attr: [name: "rf_id"
int64_val: 2424
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100452
]
name: aten::reshape
id: 9478
duration_micros: 38
attr: [name: "rf_id"
int64_val: 2425
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100456
]
name: aten::view
id: 9479
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2426
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100459
]
name: aten::mm
id: 9480
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2427
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100507
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 9481
duration_micros: 523
attr: [name: "rf_id"
int64_val: 2427
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123100554
]
name: aten::mm
id: 9482
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2427
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100554
]
name: aten::_unsafe_view
id: 9484
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2428
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100574
]
name: GeLUFunction
id: 9485
duration_micros: 32
attr: [name: "rf_id"
int64_val: 2429
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1839
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100619
]
name: TorchDynamo Cache Lookup
id: 9486
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2430
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100639
]
name: Torch-Compiled Region
id: 9487
duration_micros: 67
attr: [name: "rf_id"
int64_val: 2431
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100649
]
name: aten::empty
id: 9488
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2432
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100687
]
name: triton_poi_fused_add_mul_tanh_0
id: 9489
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2433
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100717
]
name: triton__0d1d2d3de
id: 9490
duration_micros: 43
attr: [name: "rf_id"
int64_val: 2433
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123100732
]
name: triton_poi_fused_add_mul_tanh_0
id: 9491
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2433
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100732
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9493
duration_micros: 52
attr: [name: "rf_id"
int64_val: 2434
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1840
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100809
]
name: aten::t
id: 9494
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2435
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100817
]
name: aten::transpose
id: 9495
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2436
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100821
]
name: aten::as_strided
id: 9496
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2437
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100827
]
name: aten::matmul
id: 9497
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2438
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100855
]
name: aten::reshape
id: 9498
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2439
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100859
]
name: aten::view
id: 9499
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2440
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100863
]
name: aten::mm
id: 9500
duration_micros: 32
attr: [name: "rf_id"
int64_val: 2441
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100878
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 9501
duration_micros: 566
attr: [name: "rf_id"
int64_val: 2441
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123100930
]
name: aten::mm
id: 9502
duration_micros: 32
attr: [name: "rf_id"
int64_val: 2441
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100930
]
name: aten::_unsafe_view
id: 9504
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2442
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123100948
]
name: _ReduceFromModelParallelRegion
id: 9505
duration_micros: 61
attr: [name: "rf_id"
int64_val: 2443
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1841
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101016
]
name: c10d::allreduce_
id: 9506
duration_micros: 29
attr: [name: "rf_id"
int64_val: 2444
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101044
]
name: record_param_comms
id: 9507
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2445
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101055
]
name: nccl:all_reduce
id: 9508
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2446
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101072
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 9509
duration_micros: 595
attr: [name: "rf_id"
int64_val: 2446
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123101089
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 9510
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2446
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101089
]
name: record_param_comms
id: 9512
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2447
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101161
]
name: aten::view_as
id: 9513
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2448
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101184
]
name: aten::view
id: 9514
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2449
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101188
]
name: aten::expand_as
id: 9515
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2450
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101227
]
name: aten::expand
id: 9516
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2451
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101231
]
name: aten::as_strided
id: 9517
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2452
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101237
]
name: TorchDynamo Cache Lookup
id: 9518
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2453
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101280
]
name: Torch-Compiled Region
id: 9519
duration_micros: 67
attr: [name: "rf_id"
int64_val: 2454
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101291
]
name: aten::empty
id: 9520
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2455
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101328
]
name: triton_poi_fused_add_0
id: 9521
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2456
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101358
]
name: triton__0d1d2d3d4de
id: 9522
duration_micros: 113
attr: [name: "rf_id"
int64_val: 2456
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123101374
]
name: triton_poi_fused_add_0
id: 9523
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2456
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101374
]
name: FusedLayerNormAffineFunction
id: 9525
duration_micros: 53
attr: [name: "rf_id"
int64_val: 2457
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1842
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101478
]
name: aten::empty_like
id: 9526
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2458
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101490
]
name: aten::empty_strided
id: 9527
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2459
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101496
]
name: aten::empty
id: 9528
duration_micros: 44
attr: [name: "rf_id"
int64_val: 2460
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101530
]
name: aten::empty_like
id: 9529
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2461
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101580
]
name: aten::empty_strided
id: 9530
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2462
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101585
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 9531
duration_micros: 139
attr: [name: "rf_id"
int64_val: 2462
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123101624
]
name: aten::empty_strided
id: 9532
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2462
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101624
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9534
duration_micros: 42
attr: [name: "rf_id"
int64_val: 2463
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1843
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101691
]
name: aten::t
id: 9535
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2464
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101708
]
name: aten::transpose
id: 9536
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2465
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101711
]
name: aten::as_strided
id: 9537
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2466
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101718
]
name: aten::matmul
id: 9538
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2467
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101746
]
name: aten::reshape
id: 9539
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2468
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101750
]
name: aten::view
id: 9540
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2469
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101753
]
name: aten::mm
id: 9541
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2470
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101768
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 9542
duration_micros: 400
attr: [name: "rf_id"
int64_val: 2470
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123101812
]
name: aten::mm
id: 9543
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2470
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101812
]
name: aten::_unsafe_view
id: 9545
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2471
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101830
]
name: aten::add
id: 9546
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2472
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101852
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 9547
duration_micros: 54
attr: [name: "rf_id"
int64_val: 2472
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123101874
]
name: aten::add
id: 9548
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2472
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101874
]
name: aten::view
id: 9550
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2473
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101911
]
name: aten::split_with_sizes
id: 9551
duration_micros: 35
attr: [name: "rf_id"
int64_val: 2474
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101936
]
name: aten::as_strided
id: 9552
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2475
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101943
]
name: aten::as_strided
id: 9553
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2476
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101943
]
name: aten::as_strided
id: 9554
duration_micros: 37
attr: [name: "rf_id"
int64_val: 2477
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123101957
]
name: aten::view
id: 9555
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2478
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102035
]
name: aten::reshape
id: 9556
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2479
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102061
]
name: aten::_reshape_alias
id: 9557
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2480
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102068
]
name: aten::view
id: 9558
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2481
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102088
]
name: aten::slice
id: 9559
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2482
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102108
]
name: aten::as_strided
id: 9560
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2483
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102114
]
name: aten::view
id: 9561
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2484
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102139
]
name: aten::transpose
id: 9562
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2485
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102152
]
name: aten::as_strided
id: 9563
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2486
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102157
]
name: aten::transpose
id: 9564
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2487
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102175
]
name: aten::as_strided
id: 9565
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2488
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102179
]
name: aten::transpose
id: 9566
duration_micros: 38
attr: [name: "rf_id"
int64_val: 2489
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102197
]
name: aten::as_strided
id: 9567
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2490
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102202
]
name: aten::baddbmm
id: 9568
duration_micros: 33
attr: [name: "rf_id"
int64_val: 2491
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102258
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 9569
duration_micros: 294
attr: [name: "rf_id"
int64_val: 2491
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123102311
]
name: aten::baddbmm
id: 9570
duration_micros: 33
attr: [name: "rf_id"
int64_val: 2491
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102311
]
name: aten::view
id: 9572
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2492
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102338
]
name: aten::view
id: 9573
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2493
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102338
]
name: ScaledUpperTriangMaskedSoftmax
id: 9574
duration_micros: 61
attr: [name: "rf_id"
int64_val: 2494
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1844
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102391
]
name: aten::empty
id: 9575
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2495
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102403
]
name: aten::to
id: 9576
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2496
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102420
]
name: aten::lift_fresh
id: 9577
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2497
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102430
]
name: aten::detach_
id: 9578
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2498
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102437
]
name: detach_
id: 9579
duration_micros: 2
attr: [name: "rf_id"
int64_val: 2499
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102439
]
name: aten::select
id: 9580
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2500
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102451
]
name: aten::as_strided
id: 9581
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2501
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102457
]
name: aten::item
id: 9582
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2502
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102475
]
name: aten::_local_scalar_dense
id: 9583
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2503
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102477
]
name: aten::empty
id: 9584
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2504
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102498
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 9585
duration_micros: 425
attr: [name: "rf_id"
int64_val: 2504
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123102531
]
name: aten::empty
id: 9586
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2504
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102531
]
name: aten::view
id: 9588
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2505
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102554
]
name: aten::dropout
id: 9589
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2506
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102614
]
name: aten::view
id: 9590
duration_micros: 39
attr: [name: "rf_id"
int64_val: 2507
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102654
]
name: aten::view
id: 9591
duration_micros: 39
attr: [name: "rf_id"
int64_val: 2508
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102654
]
name: aten::transpose
id: 9592
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2509
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102723
]
name: aten::as_strided
id: 9593
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2510
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102729
]
name: aten::bmm
id: 9594
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2511
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102749
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 9595
duration_micros: 184
attr: [name: "rf_id"
int64_val: 2511
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123102786
]
name: aten::bmm
id: 9596
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2511
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102786
]
name: aten::view
id: 9598
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2512
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102807
]
name: aten::permute
id: 9599
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2513
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102822
]
name: aten::as_strided
id: 9600
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2514
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102830
]
name: aten::contiguous
id: 9601
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2515
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102859
]
name: aten::clone
id: 9602
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2516
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102861
]
name: aten::empty_like
id: 9603
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2517
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102865
]
name: aten::empty
id: 9604
duration_micros: 17
attr: [name: "rf_id"
int64_val: 2518
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102869
]
name: aten::copy_
id: 9605
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2519
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102897
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 9606
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2519
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123102915
]
name: aten::copy_
id: 9607
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2519
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102915
]
name: aten::view
id: 9609
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2520
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123102953
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9610
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2521
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1845
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123103003
]
name: aten::t
id: 9611
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2522
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123103012
]
name: aten::transpose
id: 9612
duration_micros: 42
attr: [name: "rf_id"
int64_val: 2523
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123103015
]
name: aten::as_strided
id: 9613
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2524
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123103021
]
name: aten::matmul
id: 9614
duration_micros: 22
attr: [name: "rf_id"
int64_val: 2525
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123103082
]
name: aten::reshape
id: 9615
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2526
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123103087
]
name: aten::view
id: 9616
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2527
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123103093
]
name: aten::mm
id: 9617
duration_micros: 11215
attr: [name: "rf_id"
int64_val: 2528
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123103109
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 9618
duration_micros: 159
attr: [name: "rf_id"
int64_val: 2528
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123125525
]
name: aten::mm
id: 9619
duration_micros: 11215
attr: [name: "rf_id"
int64_val: 2528
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125525
]
name: aten::_unsafe_view
id: 9621
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2529
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125548
]
name: _ReduceFromModelParallelRegion
id: 9622
duration_micros: 70
attr: [name: "rf_id"
int64_val: 2530
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1846
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125587
]
name: c10d::allreduce_
id: 9623
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2531
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125623
]
name: record_param_comms
id: 9624
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2532
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125634
]
name: nccl:all_reduce
id: 9625
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2533
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125650
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 9626
duration_micros: 604
attr: [name: "rf_id"
int64_val: 2533
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123125668
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 9627
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2533
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125668
]
name: record_param_comms
id: 9629
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2534
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125745
]
name: aten::view_as
id: 9630
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2535
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125769
]
name: aten::view
id: 9631
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2536
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125773
]
name: aten::expand_as
id: 9632
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2537
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125817
]
name: aten::expand
id: 9633
duration_micros: 46
attr: [name: "rf_id"
int64_val: 2538
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125822
]
name: aten::as_strided
id: 9634
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2539
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125828
]
name: TorchDynamo Cache Lookup
id: 9635
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2540
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125911
]
name: Torch-Compiled Region
id: 9636
duration_micros: 80
attr: [name: "rf_id"
int64_val: 2541
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125925
]
name: aten::empty
id: 9637
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2542
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123125971
]
name: triton_poi_fused_add_0
id: 9638
duration_micros: 17
attr: [name: "rf_id"
int64_val: 2543
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126011
]
name: triton__0d1d2d3d4de
id: 9639
duration_micros: 113
attr: [name: "rf_id"
int64_val: 2543
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123126029
]
name: triton_poi_fused_add_0
id: 9640
duration_micros: 17
attr: [name: "rf_id"
int64_val: 2543
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126029
]
name: FusedLayerNormAffineFunction
id: 9642
duration_micros: 50
attr: [name: "rf_id"
int64_val: 2544
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1847
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126109
]
name: aten::empty_like
id: 9643
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2545
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126122
]
name: aten::empty_strided
id: 9644
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2546
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126129
]
name: aten::empty
id: 9645
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2547
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126159
]
name: aten::empty_like
id: 9646
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2548
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126175
]
name: aten::empty_strided
id: 9647
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2549
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126179
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 9648
duration_micros: 137
attr: [name: "rf_id"
int64_val: 2549
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123126210
]
name: aten::empty_strided
id: 9649
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2549
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126210
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9651
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2550
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1848
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126275
]
name: aten::t
id: 9652
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2551
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126284
]
name: aten::transpose
id: 9653
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2552
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126288
]
name: aten::as_strided
id: 9654
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2553
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126294
]
name: aten::matmul
id: 9655
duration_micros: 22
attr: [name: "rf_id"
int64_val: 2554
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126323
]
name: aten::reshape
id: 9656
duration_micros: 39
attr: [name: "rf_id"
int64_val: 2555
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126327
]
name: aten::view
id: 9657
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2556
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126330
]
name: aten::mm
id: 9658
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2557
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126379
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 9659
duration_micros: 522
attr: [name: "rf_id"
int64_val: 2557
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123126427
]
name: aten::mm
id: 9660
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2557
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126427
]
name: aten::_unsafe_view
id: 9662
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2558
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126448
]
name: GeLUFunction
id: 9663
duration_micros: 34
attr: [name: "rf_id"
int64_val: 2559
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1849
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126516
]
name: TorchDynamo Cache Lookup
id: 9664
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2560
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126539
]
name: Torch-Compiled Region
id: 9665
duration_micros: 71
attr: [name: "rf_id"
int64_val: 2561
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126549
]
name: aten::empty
id: 9666
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2562
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126589
]
name: triton_poi_fused_add_mul_tanh_0
id: 9667
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2563
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126620
]
name: triton__0d1d2d3de
id: 9668
duration_micros: 43
attr: [name: "rf_id"
int64_val: 2563
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123126636
]
name: triton_poi_fused_add_mul_tanh_0
id: 9669
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2563
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126636
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9671
duration_micros: 54
attr: [name: "rf_id"
int64_val: 2564
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1850
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126718
]
name: aten::t
id: 9672
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2565
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126727
]
name: aten::transpose
id: 9673
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2566
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126730
]
name: aten::as_strided
id: 9674
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2567
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126737
]
name: aten::matmul
id: 9675
duration_micros: 22
attr: [name: "rf_id"
int64_val: 2568
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126766
]
name: aten::reshape
id: 9676
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2569
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126773
]
name: aten::view
id: 9677
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2570
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126776
]
name: aten::mm
id: 9678
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2571
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126792
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 9679
duration_micros: 566
attr: [name: "rf_id"
int64_val: 2571
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123126841
]
name: aten::mm
id: 9680
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2571
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126841
]
name: aten::_unsafe_view
id: 9682
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2572
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126859
]
name: _ReduceFromModelParallelRegion
id: 9683
duration_micros: 63
attr: [name: "rf_id"
int64_val: 2573
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1851
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126929
]
name: c10d::allreduce_
id: 9684
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2574
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126958
]
name: record_param_comms
id: 9685
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2575
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126969
]
name: nccl:all_reduce
id: 9686
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2576
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123126986
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 9687
duration_micros: 611
attr: [name: "rf_id"
int64_val: 2576
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123127003
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 9688
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2576
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127003
]
name: record_param_comms
id: 9690
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2577
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127075
]
name: aten::view_as
id: 9691
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2578
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127098
]
name: aten::view
id: 9692
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2579
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127102
]
name: aten::expand_as
id: 9693
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2580
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127142
]
name: aten::expand
id: 9694
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2581
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127146
]
name: aten::as_strided
id: 9695
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2582
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127152
]
name: TorchDynamo Cache Lookup
id: 9696
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2583
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127194
]
name: Torch-Compiled Region
id: 9697
duration_micros: 67
attr: [name: "rf_id"
int64_val: 2584
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127206
]
name: aten::empty
id: 9698
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2585
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127243
]
name: triton_poi_fused_add_0
id: 9699
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2586
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127273
]
name: triton__0d1d2d3d4de
id: 9700
duration_micros: 113
attr: [name: "rf_id"
int64_val: 2586
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123127289
]
name: triton_poi_fused_add_0
id: 9701
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2586
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127289
]
name: FusedLayerNormAffineFunction
id: 9703
duration_micros: 57
attr: [name: "rf_id"
int64_val: 2587
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1852
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127396
]
name: aten::empty_like
id: 9704
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2588
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127408
]
name: aten::empty_strided
id: 9705
duration_micros: 22
attr: [name: "rf_id"
int64_val: 2589
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127414
]
name: aten::empty
id: 9706
duration_micros: 6302
attr: [name: "rf_id"
int64_val: 2590
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123127448
]
name: aten::empty_like
id: 9707
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2591
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123133758
]
name: aten::empty_strided
id: 9708
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2592
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123133765
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 9709
duration_micros: 136
attr: [name: "rf_id"
int64_val: 2592
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123133815
]
name: aten::empty_strided
id: 9710
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2592
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123133815
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9712
duration_micros: 35
attr: [name: "rf_id"
int64_val: 2593
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1853
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123133886
]
name: aten::t
id: 9713
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2594
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123133895
]
name: aten::transpose
id: 9714
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2595
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123133899
]
name: aten::as_strided
id: 9715
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2596
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123133905
]
name: aten::matmul
id: 9716
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2597
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123133933
]
name: aten::reshape
id: 9717
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2598
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123133937
]
name: aten::view
id: 9718
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2599
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123133945
]
name: aten::mm
id: 9719
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2600
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123133961
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 9720
duration_micros: 400
attr: [name: "rf_id"
int64_val: 2600
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123134004
]
name: aten::mm
id: 9721
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2600
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134004
]
name: aten::_unsafe_view
id: 9723
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2601
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134022
]
name: aten::add
id: 9724
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2602
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134044
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 9725
duration_micros: 54
attr: [name: "rf_id"
int64_val: 2602
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123134065
]
name: aten::add
id: 9726
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2602
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134065
]
name: aten::view
id: 9728
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2603
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134104
]
name: aten::split_with_sizes
id: 9729
duration_micros: 32
attr: [name: "rf_id"
int64_val: 2604
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134135
]
name: aten::as_strided
id: 9730
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2605
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134141
]
name: aten::as_strided
id: 9731
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2606
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134141
]
name: aten::as_strided
id: 9732
duration_micros: 36
attr: [name: "rf_id"
int64_val: 2607
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134156
]
name: aten::view
id: 9733
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2608
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134231
]
name: aten::reshape
id: 9734
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2609
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134258
]
name: aten::_reshape_alias
id: 9735
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2610
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134266
]
name: aten::view
id: 9736
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2611
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134285
]
name: aten::slice
id: 9737
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2612
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134307
]
name: aten::as_strided
id: 9738
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2613
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134313
]
name: aten::view
id: 9739
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2614
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134338
]
name: aten::transpose
id: 9740
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2615
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134355
]
name: aten::as_strided
id: 9741
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2616
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134361
]
name: aten::transpose
id: 9742
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2617
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134378
]
name: aten::as_strided
id: 9743
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2618
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134383
]
name: aten::transpose
id: 9744
duration_micros: 35
attr: [name: "rf_id"
int64_val: 2619
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134398
]
name: aten::as_strided
id: 9745
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2620
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134403
]
name: aten::baddbmm
id: 9746
duration_micros: 33
attr: [name: "rf_id"
int64_val: 2621
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134455
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 9747
duration_micros: 294
attr: [name: "rf_id"
int64_val: 2621
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123134507
]
name: aten::baddbmm
id: 9748
duration_micros: 33
attr: [name: "rf_id"
int64_val: 2621
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134507
]
name: aten::view
id: 9750
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2622
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134535
]
name: aten::view
id: 9751
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2623
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134535
]
name: ScaledUpperTriangMaskedSoftmax
id: 9752
duration_micros: 70
attr: [name: "rf_id"
int64_val: 2624
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1854
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134590
]
name: aten::empty
id: 9753
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2625
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134603
]
name: aten::to
id: 9754
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2626
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134624
]
name: aten::lift_fresh
id: 9755
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2627
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134635
]
name: aten::detach_
id: 9756
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2628
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134642
]
name: detach_
id: 9757
duration_micros: 2
attr: [name: "rf_id"
int64_val: 2629
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134644
]
name: aten::select
id: 9758
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2630
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134657
]
name: aten::as_strided
id: 9759
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2631
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134662
]
name: aten::item
id: 9760
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2632
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134682
]
name: aten::_local_scalar_dense
id: 9761
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2633
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134684
]
name: aten::empty
id: 9762
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2634
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134703
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 9763
duration_micros: 425
attr: [name: "rf_id"
int64_val: 2634
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123134735
]
name: aten::empty
id: 9764
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2634
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134735
]
name: aten::view
id: 9766
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2635
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134758
]
name: aten::dropout
id: 9767
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2636
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134821
]
name: aten::view
id: 9768
duration_micros: 39
attr: [name: "rf_id"
int64_val: 2637
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134862
]
name: aten::view
id: 9769
duration_micros: 39
attr: [name: "rf_id"
int64_val: 2638
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134862
]
name: aten::transpose
id: 9770
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2639
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134926
]
name: aten::as_strided
id: 9771
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2640
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134932
]
name: aten::bmm
id: 9772
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2641
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134951
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 9773
duration_micros: 184
attr: [name: "rf_id"
int64_val: 2641
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123134986
]
name: aten::bmm
id: 9774
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2641
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123134986
]
name: aten::view
id: 9776
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2642
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135011
]
name: aten::permute
id: 9777
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2643
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135026
]
name: aten::as_strided
id: 9778
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2644
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135032
]
name: aten::contiguous
id: 9779
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2645
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135052
]
name: aten::clone
id: 9780
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2646
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135055
]
name: aten::empty_like
id: 9781
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2647
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135059
]
name: aten::empty
id: 9782
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2648
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135063
]
name: aten::copy_
id: 9783
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2649
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135088
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 9784
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2649
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123135106
]
name: aten::copy_
id: 9785
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2649
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135106
]
name: aten::view
id: 9787
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2650
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135146
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9788
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2651
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1855
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135196
]
name: aten::t
id: 9789
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2652
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135205
]
name: aten::transpose
id: 9790
duration_micros: 40
attr: [name: "rf_id"
int64_val: 2653
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135208
]
name: aten::as_strided
id: 9791
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2654
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135214
]
name: aten::matmul
id: 9792
duration_micros: 20
attr: [name: "rf_id"
int64_val: 2655
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135276
]
name: aten::reshape
id: 9793
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2656
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135281
]
name: aten::view
id: 9794
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2657
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135284
]
name: aten::mm
id: 9795
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2658
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135300
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 9796
duration_micros: 162
attr: [name: "rf_id"
int64_val: 2658
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123135343
]
name: aten::mm
id: 9797
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2658
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135343
]
name: aten::_unsafe_view
id: 9799
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2659
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135360
]
name: _ReduceFromModelParallelRegion
id: 9800
duration_micros: 87
attr: [name: "rf_id"
int64_val: 2660
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1856
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135397
]
name: c10d::allreduce_
id: 9801
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2661
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135431
]
name: record_param_comms
id: 9802
duration_micros: 32
attr: [name: "rf_id"
int64_val: 2662
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135443
]
name: nccl:all_reduce
id: 9803
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2663
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135458
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 9804
duration_micros: 639
attr: [name: "rf_id"
int64_val: 2663
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123135475
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 9805
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2663
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135475
]
name: record_param_comms
id: 9807
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2664
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135569
]
name: aten::view_as
id: 9808
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2665
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135594
]
name: aten::view
id: 9809
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2666
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135599
]
name: aten::expand_as
id: 9810
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2667
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135642
]
name: aten::expand
id: 9811
duration_micros: 47
attr: [name: "rf_id"
int64_val: 2668
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135647
]
name: aten::as_strided
id: 9812
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2669
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135653
]
name: TorchDynamo Cache Lookup
id: 9813
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2670
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135735
]
name: Torch-Compiled Region
id: 9814
duration_micros: 71
attr: [name: "rf_id"
int64_val: 2671
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135747
]
name: aten::empty
id: 9815
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2672
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135788
]
name: triton_poi_fused_add_0
id: 9816
duration_micros: 17
attr: [name: "rf_id"
int64_val: 2673
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135819
]
name: triton__0d1d2d3d4de
id: 9817
duration_micros: 114
attr: [name: "rf_id"
int64_val: 2673
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123135837
]
name: triton_poi_fused_add_0
id: 9818
duration_micros: 17
attr: [name: "rf_id"
int64_val: 2673
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135837
]
name: FusedLayerNormAffineFunction
id: 9820
duration_micros: 49
attr: [name: "rf_id"
int64_val: 2674
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1857
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135913
]
name: aten::empty_like
id: 9821
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2675
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135925
]
name: aten::empty_strided
id: 9822
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2676
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135932
]
name: aten::empty
id: 9823
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2677
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135962
]
name: aten::empty_like
id: 9824
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2678
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135978
]
name: aten::empty_strided
id: 9825
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2679
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123135982
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 9826
duration_micros: 136
attr: [name: "rf_id"
int64_val: 2679
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123136013
]
name: aten::empty_strided
id: 9827
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2679
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136013
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9829
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2680
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1858
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136076
]
name: aten::t
id: 9830
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2681
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136084
]
name: aten::transpose
id: 9831
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2682
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136088
]
name: aten::as_strided
id: 9832
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2683
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136094
]
name: aten::matmul
id: 9833
duration_micros: 22
attr: [name: "rf_id"
int64_val: 2684
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136122
]
name: aten::reshape
id: 9834
duration_micros: 38
attr: [name: "rf_id"
int64_val: 2685
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136126
]
name: aten::view
id: 9835
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2686
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136129
]
name: aten::mm
id: 9836
duration_micros: 29
attr: [name: "rf_id"
int64_val: 2687
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136177
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 9837
duration_micros: 521
attr: [name: "rf_id"
int64_val: 2687
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123136223
]
name: aten::mm
id: 9838
duration_micros: 29
attr: [name: "rf_id"
int64_val: 2687
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136223
]
name: aten::_unsafe_view
id: 9840
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2688
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136243
]
name: GeLUFunction
id: 9841
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2689
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1859
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136292
]
name: TorchDynamo Cache Lookup
id: 9842
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2690
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136312
]
name: Torch-Compiled Region
id: 9843
duration_micros: 69
attr: [name: "rf_id"
int64_val: 2691
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136322
]
name: aten::empty
id: 9844
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2692
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136361
]
name: triton_poi_fused_add_mul_tanh_0
id: 9845
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2693
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136391
]
name: triton__0d1d2d3de
id: 9846
duration_micros: 43
attr: [name: "rf_id"
int64_val: 2693
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123136407
]
name: triton_poi_fused_add_mul_tanh_0
id: 9847
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2693
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136407
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9849
duration_micros: 54
attr: [name: "rf_id"
int64_val: 2694
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1860
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136485
]
name: aten::t
id: 9850
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2695
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136494
]
name: aten::transpose
id: 9851
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2696
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136497
]
name: aten::as_strided
id: 9852
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2697
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136503
]
name: aten::matmul
id: 9853
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2698
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136531
]
name: aten::reshape
id: 9854
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2699
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136535
]
name: aten::view
id: 9855
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2700
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136538
]
name: aten::mm
id: 9856
duration_micros: 29
attr: [name: "rf_id"
int64_val: 2701
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136554
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 9857
duration_micros: 567
attr: [name: "rf_id"
int64_val: 2701
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123136602
]
name: aten::mm
id: 9858
duration_micros: 29
attr: [name: "rf_id"
int64_val: 2701
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136602
]
name: aten::_unsafe_view
id: 9860
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2702
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136619
]
name: _ReduceFromModelParallelRegion
id: 9861
duration_micros: 62
attr: [name: "rf_id"
int64_val: 2703
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1861
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136689
]
name: c10d::allreduce_
id: 9862
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2704
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136717
]
name: record_param_comms
id: 9863
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2705
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136729
]
name: nccl:all_reduce
id: 9864
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2706
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136745
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 9865
duration_micros: 10652
attr: [name: "rf_id"
int64_val: 2706
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123136762
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 9866
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2706
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136762
]
name: record_param_comms
id: 9868
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2707
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136835
]
name: aten::view_as
id: 9869
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2708
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136858
]
name: aten::view
id: 9870
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2709
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136862
]
name: aten::expand_as
id: 9871
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2710
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136901
]
name: aten::expand
id: 9872
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2711
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136905
]
name: aten::as_strided
id: 9873
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2712
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136912
]
name: TorchDynamo Cache Lookup
id: 9874
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2713
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136955
]
name: Torch-Compiled Region
id: 9875
duration_micros: 67
attr: [name: "rf_id"
int64_val: 2714
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123136966
]
name: aten::empty
id: 9876
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2715
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137004
]
name: triton_poi_fused_add_0
id: 9877
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2716
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137033
]
name: triton__0d1d2d3d4de
id: 9878
duration_micros: 113
attr: [name: "rf_id"
int64_val: 2716
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123137049
]
name: triton_poi_fused_add_0
id: 9879
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2716
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137049
]
name: FusedLayerNormAffineFunction
id: 9881
duration_micros: 53
attr: [name: "rf_id"
int64_val: 2717
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1862
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137154
]
name: aten::empty_like
id: 9882
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2718
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137166
]
name: aten::empty_strided
id: 9883
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2719
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137173
]
name: aten::empty
id: 9884
duration_micros: 45
attr: [name: "rf_id"
int64_val: 2720
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137206
]
name: aten::empty_like
id: 9885
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2721
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137257
]
name: aten::empty_strided
id: 9886
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2722
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137262
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 9887
duration_micros: 136
attr: [name: "rf_id"
int64_val: 2722
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123137300
]
name: aten::empty_strided
id: 9888
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2722
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137300
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9890
duration_micros: 8143
attr: [name: "rf_id"
int64_val: 2723
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1863
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137369
]
name: aten::t
id: 9891
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2724
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137378
]
name: aten::transpose
id: 9892
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2725
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137381
]
name: aten::as_strided
id: 9893
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2726
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137391
]
name: aten::matmul
id: 9894
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2727
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137419
]
name: aten::reshape
id: 9895
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2728
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137423
]
name: aten::view
id: 9896
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2729
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137427
]
name: aten::mm
id: 9897
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2730
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137442
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 9898
duration_micros: 401
attr: [name: "rf_id"
int64_val: 2730
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123137487
]
name: aten::mm
id: 9899
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2730
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137487
]
name: aten::_unsafe_view
id: 9901
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2731
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123137504
]
name: aten::add
id: 9902
duration_micros: 20
attr: [name: "rf_id"
int64_val: 2732
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145634
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 9903
duration_micros: 54
attr: [name: "rf_id"
int64_val: 2732
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123145662
]
name: aten::add
id: 9904
duration_micros: 20
attr: [name: "rf_id"
int64_val: 2732
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145662
]
name: aten::view
id: 9906
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2733
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145709
]
name: aten::split_with_sizes
id: 9907
duration_micros: 32
attr: [name: "rf_id"
int64_val: 2734
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145737
]
name: aten::as_strided
id: 9908
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2735
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145744
]
name: aten::as_strided
id: 9909
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2736
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145744
]
name: aten::as_strided
id: 9910
duration_micros: 37
attr: [name: "rf_id"
int64_val: 2737
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145758
]
name: aten::view
id: 9911
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2738
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145834
]
name: aten::reshape
id: 9912
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2739
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145861
]
name: aten::_reshape_alias
id: 9913
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2740
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145869
]
name: aten::view
id: 9914
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2741
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145889
]
name: aten::slice
id: 9915
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2742
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145914
]
name: aten::as_strided
id: 9916
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2743
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145919
]
name: aten::view
id: 9917
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2744
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145945
]
name: aten::transpose
id: 9918
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2745
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145958
]
name: aten::as_strided
id: 9919
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2746
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145963
]
name: aten::transpose
id: 9920
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2747
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145981
]
name: aten::as_strided
id: 9921
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2748
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123145985
]
name: aten::transpose
id: 9922
duration_micros: 34
attr: [name: "rf_id"
int64_val: 2749
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146001
]
name: aten::as_strided
id: 9923
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2750
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146005
]
name: aten::baddbmm
id: 9924
duration_micros: 35
attr: [name: "rf_id"
int64_val: 2751
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146058
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 9925
duration_micros: 295
attr: [name: "rf_id"
int64_val: 2751
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123146113
]
name: aten::baddbmm
id: 9926
duration_micros: 35
attr: [name: "rf_id"
int64_val: 2751
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146113
]
name: aten::view
id: 9928
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2752
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146140
]
name: aten::view
id: 9929
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2753
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146140
]
name: ScaledUpperTriangMaskedSoftmax
id: 9930
duration_micros: 66
attr: [name: "rf_id"
int64_val: 2754
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1864
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146200
]
name: aten::empty
id: 9931
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2755
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146213
]
name: aten::to
id: 9932
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2756
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146230
]
name: aten::lift_fresh
id: 9933
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2757
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146241
]
name: aten::detach_
id: 9934
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2758
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146249
]
name: detach_
id: 9935
duration_micros: 3
attr: [name: "rf_id"
int64_val: 2759
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146250
]
name: aten::select
id: 9936
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2760
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146263
]
name: aten::as_strided
id: 9937
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2761
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146269
]
name: aten::item
id: 9938
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2762
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146288
]
name: aten::_local_scalar_dense
id: 9939
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2763
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146290
]
name: aten::empty
id: 9940
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2764
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146306
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 9941
duration_micros: 425
attr: [name: "rf_id"
int64_val: 2764
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123146340
]
name: aten::empty
id: 9942
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2764
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146340
]
name: aten::view
id: 9944
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2765
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146362
]
name: aten::dropout
id: 9945
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2766
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146425
]
name: aten::view
id: 9946
duration_micros: 40
attr: [name: "rf_id"
int64_val: 2767
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146465
]
name: aten::view
id: 9947
duration_micros: 40
attr: [name: "rf_id"
int64_val: 2768
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146465
]
name: aten::transpose
id: 9948
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2769
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146533
]
name: aten::as_strided
id: 9949
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2770
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146539
]
name: aten::bmm
id: 9950
duration_micros: 23
attr: [name: "rf_id"
int64_val: 2771
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146559
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 9951
duration_micros: 184
attr: [name: "rf_id"
int64_val: 2771
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123146595
]
name: aten::bmm
id: 9952
duration_micros: 23
attr: [name: "rf_id"
int64_val: 2771
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146595
]
name: aten::view
id: 9954
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2772
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146617
]
name: aten::permute
id: 9955
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2773
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146632
]
name: aten::as_strided
id: 9956
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2774
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146638
]
name: aten::contiguous
id: 9957
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2775
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146658
]
name: aten::clone
id: 9958
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2776
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146660
]
name: aten::empty_like
id: 9959
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2777
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146664
]
name: aten::empty
id: 9960
duration_micros: 17
attr: [name: "rf_id"
int64_val: 2778
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146668
]
name: aten::copy_
id: 9961
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2779
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146696
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 9962
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2779
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123146715
]
name: aten::copy_
id: 9963
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2779
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146715
]
name: aten::view
id: 9965
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2780
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146755
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 9966
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2781
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1865
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146814
]
name: aten::t
id: 9967
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2782
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146823
]
name: aten::transpose
id: 9968
duration_micros: 41
attr: [name: "rf_id"
int64_val: 2783
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146827
]
name: aten::as_strided
id: 9969
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2784
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146833
]
name: aten::matmul
id: 9970
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2785
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146893
]
name: aten::reshape
id: 9971
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2786
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146898
]
name: aten::view
id: 9972
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2787
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146904
]
name: aten::mm
id: 9973
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2788
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146921
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 9974
duration_micros: 159
attr: [name: "rf_id"
int64_val: 2788
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123146967
]
name: aten::mm
id: 9975
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2788
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146967
]
name: aten::_unsafe_view
id: 9977
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2789
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123146983
]
name: _ReduceFromModelParallelRegion
id: 9978
duration_micros: 61
attr: [name: "rf_id"
int64_val: 2790
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1866
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147021
]
name: c10d::allreduce_
id: 9979
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2791
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147048
]
name: record_param_comms
id: 9980
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2792
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147059
]
name: nccl:all_reduce
id: 9981
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2793
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147074
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 9982
duration_micros: 606
attr: [name: "rf_id"
int64_val: 2793
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123147090
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 9983
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2793
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147090
]
name: record_param_comms
id: 9985
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2794
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147162
]
name: aten::view_as
id: 9986
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2795
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147185
]
name: aten::view
id: 9987
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2796
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147189
]
name: aten::expand_as
id: 9988
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2797
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147232
]
name: aten::expand
id: 9989
duration_micros: 44
attr: [name: "rf_id"
int64_val: 2798
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147236
]
name: aten::as_strided
id: 9990
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2799
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147243
]
name: TorchDynamo Cache Lookup
id: 9991
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2800
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147320
]
name: Torch-Compiled Region
id: 9992
duration_micros: 73
attr: [name: "rf_id"
int64_val: 2801
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147332
]
name: aten::empty
id: 9993
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2802
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147373
]
name: triton_poi_fused_add_0
id: 9994
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2803
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147407
]
name: triton__0d1d2d3d4de
id: 9995
duration_micros: 113
attr: [name: "rf_id"
int64_val: 2803
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123147425
]
name: triton_poi_fused_add_0
id: 9996
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2803
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147425
]
name: FusedLayerNormAffineFunction
id: 9998
duration_micros: 8148
attr: [name: "rf_id"
int64_val: 2804
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1867
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147501
]
name: aten::empty_like
id: 9999
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2805
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147513
]
name: aten::empty_strided
id: 10000
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2806
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147519
]
name: aten::empty
id: 10001
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2807
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147552
]
name: aten::empty_like
id: 10002
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2808
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147569
]
name: aten::empty_strided
id: 10003
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2809
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123147573
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 10004
duration_micros: 137
attr: [name: "rf_id"
int64_val: 2809
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123155703
]
name: aten::empty_strided
id: 10005
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2809
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123155703
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10007
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2810
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1868
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123155772
]
name: aten::t
id: 10008
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2811
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123155781
]
name: aten::transpose
id: 10009
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2812
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123155784
]
name: aten::as_strided
id: 10010
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2813
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123155791
]
name: aten::matmul
id: 10011
duration_micros: 22
attr: [name: "rf_id"
int64_val: 2814
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123155818
]
name: aten::reshape
id: 10012
duration_micros: 41
attr: [name: "rf_id"
int64_val: 2815
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123155822
]
name: aten::view
id: 10013
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2816
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123155828
]
name: aten::mm
id: 10014
duration_micros: 34
attr: [name: "rf_id"
int64_val: 2817
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123155877
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 10015
duration_micros: 522
attr: [name: "rf_id"
int64_val: 2817
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123155932
]
name: aten::mm
id: 10016
duration_micros: 34
attr: [name: "rf_id"
int64_val: 2817
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123155932
]
name: aten::_unsafe_view
id: 10018
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2818
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123155952
]
name: GeLUFunction
id: 10019
duration_micros: 32
attr: [name: "rf_id"
int64_val: 2819
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1869
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123155997
]
name: TorchDynamo Cache Lookup
id: 10020
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2820
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156018
]
name: Torch-Compiled Region
id: 10021
duration_micros: 68
attr: [name: "rf_id"
int64_val: 2821
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156028
]
name: aten::empty
id: 10022
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2822
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156067
]
name: triton_poi_fused_add_mul_tanh_0
id: 10023
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2823
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156097
]
name: triton__0d1d2d3de
id: 10024
duration_micros: 43
attr: [name: "rf_id"
int64_val: 2823
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123156114
]
name: triton_poi_fused_add_mul_tanh_0
id: 10025
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2823
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156114
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10027
duration_micros: 54
attr: [name: "rf_id"
int64_val: 2824
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1870
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156191
]
name: aten::t
id: 10028
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2825
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156199
]
name: aten::transpose
id: 10029
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2826
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156203
]
name: aten::as_strided
id: 10030
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2827
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156209
]
name: aten::matmul
id: 10031
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2828
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156237
]
name: aten::reshape
id: 10032
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2829
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156241
]
name: aten::view
id: 10033
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2830
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156244
]
name: aten::mm
id: 10034
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2831
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156259
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 10035
duration_micros: 568
attr: [name: "rf_id"
int64_val: 2831
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123156307
]
name: aten::mm
id: 10036
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2831
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156307
]
name: aten::_unsafe_view
id: 10038
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2832
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156325
]
name: _ReduceFromModelParallelRegion
id: 10039
duration_micros: 69
attr: [name: "rf_id"
int64_val: 2833
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1871
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156395
]
name: c10d::allreduce_
id: 10040
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2834
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156430
]
name: record_param_comms
id: 10041
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2835
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156443
]
name: nccl:all_reduce
id: 10042
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2836
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156460
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 10043
duration_micros: 590
attr: [name: "rf_id"
int64_val: 2836
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123156477
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 10044
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2836
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156477
]
name: record_param_comms
id: 10046
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2837
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156546
]
name: aten::view_as
id: 10047
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2838
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156569
]
name: aten::view
id: 10048
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2839
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156573
]
name: aten::expand_as
id: 10049
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2840
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156612
]
name: aten::expand
id: 10050
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2841
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156617
]
name: aten::as_strided
id: 10051
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2842
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156623
]
name: TorchDynamo Cache Lookup
id: 10052
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2843
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156665
]
name: Torch-Compiled Region
id: 10053
duration_micros: 66
attr: [name: "rf_id"
int64_val: 2844
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156677
]
name: aten::empty
id: 10054
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2845
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156714
]
name: triton_poi_fused_add_0
id: 10055
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2846
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156744
]
name: triton__0d1d2d3d4de
id: 10056
duration_micros: 113
attr: [name: "rf_id"
int64_val: 2846
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123156761
]
name: triton_poi_fused_add_0
id: 10057
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2846
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156761
]
name: FusedLayerNormAffineFunction
id: 10059
duration_micros: 54
attr: [name: "rf_id"
int64_val: 2847
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1872
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156867
]
name: aten::empty_like
id: 10060
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2848
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156879
]
name: aten::empty_strided
id: 10061
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2849
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156885
]
name: aten::empty
id: 10062
duration_micros: 45
attr: [name: "rf_id"
int64_val: 2850
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156918
]
name: aten::empty_like
id: 10063
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2851
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156969
]
name: aten::empty_strided
id: 10064
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2852
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123156974
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 10065
duration_micros: 136
attr: [name: "rf_id"
int64_val: 2852
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123157013
]
name: aten::empty_strided
id: 10066
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2852
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157013
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10068
duration_micros: 34
attr: [name: "rf_id"
int64_val: 2853
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1873
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157085
]
name: aten::t
id: 10069
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2854
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157094
]
name: aten::transpose
id: 10070
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2855
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157098
]
name: aten::as_strided
id: 10071
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2856
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157104
]
name: aten::matmul
id: 10072
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2857
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157132
]
name: aten::reshape
id: 10073
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2858
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157136
]
name: aten::view
id: 10074
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2859
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157139
]
name: aten::mm
id: 10075
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2860
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157154
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 10076
duration_micros: 401
attr: [name: "rf_id"
int64_val: 2860
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123157200
]
name: aten::mm
id: 10077
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2860
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157200
]
name: aten::_unsafe_view
id: 10079
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2861
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157217
]
name: aten::add
id: 10080
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2862
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157239
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 10081
duration_micros: 54
attr: [name: "rf_id"
int64_val: 2862
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123157261
]
name: aten::add
id: 10082
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2862
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157261
]
name: aten::view
id: 10084
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2863
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157298
]
name: aten::split_with_sizes
id: 10085
duration_micros: 32
attr: [name: "rf_id"
int64_val: 2864
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157323
]
name: aten::as_strided
id: 10086
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2865
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157330
]
name: aten::as_strided
id: 10087
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2866
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157330
]
name: aten::as_strided
id: 10088
duration_micros: 38
attr: [name: "rf_id"
int64_val: 2867
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157344
]
name: aten::view
id: 10089
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2868
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157420
]
name: aten::reshape
id: 10090
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2869
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157449
]
name: aten::_reshape_alias
id: 10091
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2870
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157457
]
name: aten::view
id: 10092
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2871
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157476
]
name: aten::slice
id: 10093
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2872
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157497
]
name: aten::as_strided
id: 10094
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2873
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157503
]
name: aten::view
id: 10095
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2874
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157528
]
name: aten::transpose
id: 10096
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2875
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157541
]
name: aten::as_strided
id: 10097
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2876
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157546
]
name: aten::transpose
id: 10098
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2877
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157564
]
name: aten::as_strided
id: 10099
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2878
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157569
]
name: aten::transpose
id: 10100
duration_micros: 35
attr: [name: "rf_id"
int64_val: 2879
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157584
]
name: aten::as_strided
id: 10101
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2880
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157589
]
name: aten::baddbmm
id: 10102
duration_micros: 3037
attr: [name: "rf_id"
int64_val: 2881
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123157644
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 10103
duration_micros: 293
attr: [name: "rf_id"
int64_val: 2881
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123163699
]
name: aten::baddbmm
id: 10104
duration_micros: 3037
attr: [name: "rf_id"
int64_val: 2881
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163699
]
name: aten::view
id: 10106
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2882
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163733
]
name: aten::view
id: 10107
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2883
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163733
]
name: ScaledUpperTriangMaskedSoftmax
id: 10108
duration_micros: 68
attr: [name: "rf_id"
int64_val: 2884
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1874
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163816
]
name: aten::empty
id: 10109
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2885
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163830
]
name: aten::to
id: 10110
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2886
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163847
]
name: aten::lift_fresh
id: 10111
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2887
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163858
]
name: aten::detach_
id: 10112
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2888
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163865
]
name: detach_
id: 10113
duration_micros: 2
attr: [name: "rf_id"
int64_val: 2889
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163867
]
name: aten::select
id: 10114
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2890
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163880
]
name: aten::as_strided
id: 10115
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2891
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163886
]
name: aten::item
id: 10116
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2892
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163905
]
name: aten::_local_scalar_dense
id: 10117
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2893
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163907
]
name: aten::empty
id: 10118
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2894
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163924
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 10119
duration_micros: 426
attr: [name: "rf_id"
int64_val: 2894
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123163965
]
name: aten::empty
id: 10120
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2894
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163965
]
name: aten::view
id: 10122
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2895
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123163988
]
name: aten::dropout
id: 10123
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2896
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164054
]
name: aten::view
id: 10124
duration_micros: 40
attr: [name: "rf_id"
int64_val: 2897
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164095
]
name: aten::view
id: 10125
duration_micros: 40
attr: [name: "rf_id"
int64_val: 2898
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164095
]
name: aten::transpose
id: 10126
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2899
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164161
]
name: aten::as_strided
id: 10127
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2900
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164167
]
name: aten::bmm
id: 10128
duration_micros: 23
attr: [name: "rf_id"
int64_val: 2901
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164186
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 10129
duration_micros: 186
attr: [name: "rf_id"
int64_val: 2901
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123164221
]
name: aten::bmm
id: 10130
duration_micros: 23
attr: [name: "rf_id"
int64_val: 2901
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164221
]
name: aten::view
id: 10132
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2902
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164243
]
name: aten::permute
id: 10133
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2903
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164257
]
name: aten::as_strided
id: 10134
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2904
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164264
]
name: aten::contiguous
id: 10135
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2905
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164287
]
name: aten::clone
id: 10136
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2906
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164289
]
name: aten::empty_like
id: 10137
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2907
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164293
]
name: aten::empty
id: 10138
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2908
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164297
]
name: aten::copy_
id: 10139
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2909
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164323
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 10140
duration_micros: 21
attr: [name: "rf_id"
int64_val: 2909
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123164340
]
name: aten::copy_
id: 10141
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2909
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164340
]
name: aten::view
id: 10143
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2910
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164380
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10144
duration_micros: 26
attr: [name: "rf_id"
int64_val: 2911
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1875
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164431
]
name: aten::t
id: 10145
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2912
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164440
]
name: aten::transpose
id: 10146
duration_micros: 40
attr: [name: "rf_id"
int64_val: 2913
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164444
]
name: aten::as_strided
id: 10147
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2914
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164449
]
name: aten::matmul
id: 10148
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2915
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164509
]
name: aten::reshape
id: 10149
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2916
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164514
]
name: aten::view
id: 10150
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2917
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164517
]
name: aten::mm
id: 10151
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2918
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164533
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 10152
duration_micros: 162
attr: [name: "rf_id"
int64_val: 2918
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123164576
]
name: aten::mm
id: 10153
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2918
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164576
]
name: aten::_unsafe_view
id: 10155
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2919
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164593
]
name: _ReduceFromModelParallelRegion
id: 10156
duration_micros: 58
attr: [name: "rf_id"
int64_val: 2920
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1876
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164630
]
name: c10d::allreduce_
id: 10157
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2921
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164656
]
name: record_param_comms
id: 10158
duration_micros: 29
attr: [name: "rf_id"
int64_val: 2922
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164668
]
name: nccl:all_reduce
id: 10159
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2923
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164687
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 10160
duration_micros: 662
attr: [name: "rf_id"
int64_val: 2923
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123164704
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 10161
duration_micros: 24
attr: [name: "rf_id"
int64_val: 2923
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164704
]
name: record_param_comms
id: 10163
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2924
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164771
]
name: aten::view_as
id: 10164
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2925
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164793
]
name: aten::view
id: 10165
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2926
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164798
]
name: aten::expand_as
id: 10166
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2927
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164841
]
name: aten::expand
id: 10167
duration_micros: 44
attr: [name: "rf_id"
int64_val: 2928
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164845
]
name: aten::as_strided
id: 10168
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2929
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164851
]
name: TorchDynamo Cache Lookup
id: 10169
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2930
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164930
]
name: Torch-Compiled Region
id: 10170
duration_micros: 71
attr: [name: "rf_id"
int64_val: 2931
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164943
]
name: aten::empty
id: 10171
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2932
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123164983
]
name: triton_poi_fused_add_0
id: 10172
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2933
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165014
]
name: triton__0d1d2d3d4de
id: 10173
duration_micros: 113
attr: [name: "rf_id"
int64_val: 2933
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123165031
]
name: triton_poi_fused_add_0
id: 10174
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2933
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165031
]
name: FusedLayerNormAffineFunction
id: 10176
duration_micros: 49
attr: [name: "rf_id"
int64_val: 2934
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1877
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165107
]
name: aten::empty_like
id: 10177
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2935
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165119
]
name: aten::empty_strided
id: 10178
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2936
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165125
]
name: aten::empty
id: 10179
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2937
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165156
]
name: aten::empty_like
id: 10180
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2938
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165172
]
name: aten::empty_strided
id: 10181
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2939
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165176
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 10182
duration_micros: 134
attr: [name: "rf_id"
int64_val: 2939
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123165207
]
name: aten::empty_strided
id: 10183
duration_micros: 5
attr: [name: "rf_id"
int64_val: 2939
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165207
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10185
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2940
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1878
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165273
]
name: aten::t
id: 10186
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2941
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165282
]
name: aten::transpose
id: 10187
duration_micros: 12
attr: [name: "rf_id"
int64_val: 2942
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165286
]
name: aten::as_strided
id: 10188
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2943
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165292
]
name: aten::matmul
id: 10189
duration_micros: 22
attr: [name: "rf_id"
int64_val: 2944
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165321
]
name: aten::reshape
id: 10190
duration_micros: 37
attr: [name: "rf_id"
int64_val: 2945
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165325
]
name: aten::view
id: 10191
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2946
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165328
]
name: aten::mm
id: 10192
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2947
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165375
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 10193
duration_micros: 522
attr: [name: "rf_id"
int64_val: 2947
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123165422
]
name: aten::mm
id: 10194
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2947
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165422
]
name: aten::_unsafe_view
id: 10196
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2948
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165442
]
name: GeLUFunction
id: 10197
duration_micros: 31
attr: [name: "rf_id"
int64_val: 2949
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1879
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165487
]
name: TorchDynamo Cache Lookup
id: 10198
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2950
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165507
]
name: Torch-Compiled Region
id: 10199
duration_micros: 68
attr: [name: "rf_id"
int64_val: 2951
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165517
]
name: aten::empty
id: 10200
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2952
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165555
]
name: triton_poi_fused_add_mul_tanh_0
id: 10201
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2953
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165585
]
name: triton__0d1d2d3de
id: 10202
duration_micros: 43
attr: [name: "rf_id"
int64_val: 2953
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123165601
]
name: triton_poi_fused_add_mul_tanh_0
id: 10203
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2953
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165601
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10205
duration_micros: 56
attr: [name: "rf_id"
int64_val: 2954
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1880
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165678
]
name: aten::t
id: 10206
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2955
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165687
]
name: aten::transpose
id: 10207
duration_micros: 2094
attr: [name: "rf_id"
int64_val: 2956
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123165691
]
name: aten::as_strided
id: 10208
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2957
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123167778
]
name: aten::matmul
id: 10209
duration_micros: 20
attr: [name: "rf_id"
int64_val: 2958
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123167813
]
name: aten::reshape
id: 10210
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2959
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123167818
]
name: aten::view
id: 10211
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2960
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123167821
]
name: aten::mm
id: 10212
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2961
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123167841
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 10213
duration_micros: 567
attr: [name: "rf_id"
int64_val: 2961
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123167891
]
name: aten::mm
id: 10214
duration_micros: 30
attr: [name: "rf_id"
int64_val: 2961
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123167891
]
name: aten::_unsafe_view
id: 10216
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2962
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123167908
]
name: _ReduceFromModelParallelRegion
id: 10217
duration_micros: 64
attr: [name: "rf_id"
int64_val: 2963
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1881
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123167980
]
name: c10d::allreduce_
id: 10218
duration_micros: 29
attr: [name: "rf_id"
int64_val: 2964
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168009
]
name: record_param_comms
id: 10219
duration_micros: 27
attr: [name: "rf_id"
int64_val: 2965
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168020
]
name: nccl:all_reduce
id: 10220
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2966
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168037
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 10221
duration_micros: 10129
attr: [name: "rf_id"
int64_val: 2966
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123168053
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 10222
duration_micros: 25
attr: [name: "rf_id"
int64_val: 2966
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168053
]
name: record_param_comms
id: 10224
duration_micros: 6
attr: [name: "rf_id"
int64_val: 2967
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168126
]
name: aten::view_as
id: 10225
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2968
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168149
]
name: aten::view
id: 10226
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2969
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168153
]
name: aten::expand_as
id: 10227
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2970
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168192
]
name: aten::expand
id: 10228
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2971
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168197
]
name: aten::as_strided
id: 10229
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2972
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168203
]
name: TorchDynamo Cache Lookup
id: 10230
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2973
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168246
]
name: Torch-Compiled Region
id: 10231
duration_micros: 68
attr: [name: "rf_id"
int64_val: 2974
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168257
]
name: aten::empty
id: 10232
duration_micros: 19
attr: [name: "rf_id"
int64_val: 2975
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168295
]
name: triton_poi_fused_add_0
id: 10233
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2976
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168326
]
name: triton__0d1d2d3d4de
id: 10234
duration_micros: 113
attr: [name: "rf_id"
int64_val: 2976
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123168342
]
name: triton_poi_fused_add_0
id: 10235
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2976
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168342
]
name: FusedLayerNormAffineFunction
id: 10237
duration_micros: 55
attr: [name: "rf_id"
int64_val: 2977
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1882
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168462
]
name: aten::empty_like
id: 10238
duration_micros: 15
attr: [name: "rf_id"
int64_val: 2978
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168475
]
name: aten::empty_strided
id: 10239
duration_micros: 22
attr: [name: "rf_id"
int64_val: 2979
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168481
]
name: aten::empty
id: 10240
duration_micros: 44
attr: [name: "rf_id"
int64_val: 2980
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168516
]
name: aten::empty_like
id: 10241
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2981
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168566
]
name: aten::empty_strided
id: 10242
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2982
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168571
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 10243
duration_micros: 135
attr: [name: "rf_id"
int64_val: 2982
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123168610
]
name: aten::empty_strided
id: 10244
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2982
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168610
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10246
duration_micros: 36
attr: [name: "rf_id"
int64_val: 2983
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1883
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168680
]
name: aten::t
id: 10247
duration_micros: 22
attr: [name: "rf_id"
int64_val: 2984
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168689
]
name: aten::transpose
id: 10248
duration_micros: 13
attr: [name: "rf_id"
int64_val: 2985
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168705
]
name: aten::as_strided
id: 10249
duration_micros: 11
attr: [name: "rf_id"
int64_val: 2986
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168712
]
name: aten::matmul
id: 10250
duration_micros: 18
attr: [name: "rf_id"
int64_val: 2987
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168741
]
name: aten::reshape
id: 10251
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2988
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168745
]
name: aten::view
id: 10252
duration_micros: 8
attr: [name: "rf_id"
int64_val: 2989
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168748
]
name: aten::mm
id: 10253
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2990
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168763
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 10254
duration_micros: 401
attr: [name: "rf_id"
int64_val: 2990
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123168809
]
name: aten::mm
id: 10255
duration_micros: 28
attr: [name: "rf_id"
int64_val: 2990
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168809
]
name: aten::_unsafe_view
id: 10257
duration_micros: 7
attr: [name: "rf_id"
int64_val: 2991
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168826
]
name: aten::add
id: 10258
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2992
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168848
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 10259
duration_micros: 54
attr: [name: "rf_id"
int64_val: 2992
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123168870
]
name: aten::add
id: 10260
duration_micros: 16
attr: [name: "rf_id"
int64_val: 2992
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168870
]
name: aten::view
id: 10262
duration_micros: 10
attr: [name: "rf_id"
int64_val: 2993
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168907
]
name: aten::split_with_sizes
id: 10263
duration_micros: 34
attr: [name: "rf_id"
int64_val: 2994
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168937
]
name: aten::as_strided
id: 10264
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2995
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168944
]
name: aten::as_strided
id: 10265
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2996
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168944
]
name: aten::as_strided
id: 10266
duration_micros: 38
attr: [name: "rf_id"
int64_val: 2997
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123168958
]
name: aten::view
id: 10267
duration_micros: 9
attr: [name: "rf_id"
int64_val: 2998
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169036
]
name: aten::reshape
id: 10268
duration_micros: 14
attr: [name: "rf_id"
int64_val: 2999
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169062
]
name: aten::_reshape_alias
id: 10269
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3000
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169070
]
name: aten::view
id: 10270
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3001
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169090
]
name: aten::slice
id: 10271
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3002
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169111
]
name: aten::as_strided
id: 10272
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3003
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169116
]
name: aten::view
id: 10273
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3004
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169141
]
name: aten::transpose
id: 10274
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3005
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169154
]
name: aten::as_strided
id: 10275
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3006
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169159
]
name: aten::transpose
id: 10276
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3007
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169177
]
name: aten::as_strided
id: 10277
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3008
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169181
]
name: aten::transpose
id: 10278
duration_micros: 35
attr: [name: "rf_id"
int64_val: 3009
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169200
]
name: aten::as_strided
id: 10279
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3010
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169204
]
name: aten::baddbmm
id: 10280
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3011
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169259
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 10281
duration_micros: 294
attr: [name: "rf_id"
int64_val: 3011
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123169313
]
name: aten::baddbmm
id: 10282
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3011
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169313
]
name: aten::view
id: 10284
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3012
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169339
]
name: aten::view
id: 10285
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3013
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169339
]
name: ScaledUpperTriangMaskedSoftmax
id: 10286
duration_micros: 65
attr: [name: "rf_id"
int64_val: 3014
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1884
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169394
]
name: aten::empty
id: 10287
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3015
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169407
]
name: aten::to
id: 10288
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3016
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169424
]
name: aten::lift_fresh
id: 10289
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3017
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169435
]
name: aten::detach_
id: 10290
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3018
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169442
]
name: detach_
id: 10291
duration_micros: 3
attr: [name: "rf_id"
int64_val: 3019
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169444
]
name: aten::select
id: 10292
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3020
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169457
]
name: aten::as_strided
id: 10293
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3021
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169466
]
name: aten::item
id: 10294
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3022
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169485
]
name: aten::_local_scalar_dense
id: 10295
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3023
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169487
]
name: aten::empty
id: 10296
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3024
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169503
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 10297
duration_micros: 426
attr: [name: "rf_id"
int64_val: 3024
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123169537
]
name: aten::empty
id: 10298
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3024
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169537
]
name: aten::view
id: 10300
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3025
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169560
]
name: aten::dropout
id: 10301
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3026
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169621
]
name: aten::view
id: 10302
duration_micros: 47
attr: [name: "rf_id"
int64_val: 3027
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169661
]
name: aten::view
id: 10303
duration_micros: 47
attr: [name: "rf_id"
int64_val: 3028
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169661
]
name: aten::transpose
id: 10304
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3029
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169734
]
name: aten::as_strided
id: 10305
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3030
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169740
]
name: aten::bmm
id: 10306
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3031
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169759
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 10307
duration_micros: 184
attr: [name: "rf_id"
int64_val: 3031
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123169797
]
name: aten::bmm
id: 10308
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3031
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169797
]
name: aten::view
id: 10310
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3032
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169817
]
name: aten::permute
id: 10311
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3033
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169832
]
name: aten::as_strided
id: 10312
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3034
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169841
]
name: aten::contiguous
id: 10313
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3035
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169861
]
name: aten::clone
id: 10314
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3036
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169866
]
name: aten::empty_like
id: 10315
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3037
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169870
]
name: aten::empty
id: 10316
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3038
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169874
]
name: aten::copy_
id: 10317
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3039
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169902
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 10318
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3039
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123169919
]
name: aten::copy_
id: 10319
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3039
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169919
]
name: aten::view
id: 10321
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3040
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123169959
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10322
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3041
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1885
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170010
]
name: aten::t
id: 10323
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3042
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170019
]
name: aten::transpose
id: 10324
duration_micros: 41
attr: [name: "rf_id"
int64_val: 3043
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170022
]
name: aten::as_strided
id: 10325
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3044
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170027
]
name: aten::matmul
id: 10326
duration_micros: 20
attr: [name: "rf_id"
int64_val: 3045
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170088
]
name: aten::reshape
id: 10327
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3046
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170093
]
name: aten::view
id: 10328
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3047
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170099
]
name: aten::mm
id: 10329
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3048
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170115
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 10330
duration_micros: 159
attr: [name: "rf_id"
int64_val: 3048
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123170159
]
name: aten::mm
id: 10331
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3048
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170159
]
name: aten::_unsafe_view
id: 10333
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3049
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170176
]
name: _ReduceFromModelParallelRegion
id: 10334
duration_micros: 67
attr: [name: "rf_id"
int64_val: 3050
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1886
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170214
]
name: c10d::allreduce_
id: 10335
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3051
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170247
]
name: record_param_comms
id: 10336
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3052
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170259
]
name: nccl:all_reduce
id: 10337
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3053
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170274
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 10338
duration_micros: 6760
attr: [name: "rf_id"
int64_val: 3053
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123170291
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 10339
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3053
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170291
]
name: record_param_comms
id: 10341
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3054
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170361
]
name: aten::view_as
id: 10342
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3055
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170385
]
name: aten::view
id: 10343
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3056
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170389
]
name: aten::expand_as
id: 10344
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3057
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170432
]
name: aten::expand
id: 10345
duration_micros: 45
attr: [name: "rf_id"
int64_val: 3058
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170436
]
name: aten::as_strided
id: 10346
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3059
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170443
]
name: TorchDynamo Cache Lookup
id: 10347
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3060
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170521
]
name: Torch-Compiled Region
id: 10348
duration_micros: 72
attr: [name: "rf_id"
int64_val: 3061
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170532
]
name: aten::empty
id: 10349
duration_micros: 22
attr: [name: "rf_id"
int64_val: 3062
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170572
]
name: triton_poi_fused_add_0
id: 10350
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3063
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170607
]
name: triton__0d1d2d3d4de
id: 10351
duration_micros: 113
attr: [name: "rf_id"
int64_val: 3063
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123170624
]
name: triton_poi_fused_add_0
id: 10352
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3063
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170624
]
name: FusedLayerNormAffineFunction
id: 10354
duration_micros: 50
attr: [name: "rf_id"
int64_val: 3064
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1887
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170702
]
name: aten::empty_like
id: 10355
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3065
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170715
]
name: aten::empty_strided
id: 10356
duration_micros: 22
attr: [name: "rf_id"
int64_val: 3066
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170721
]
name: aten::empty
id: 10357
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3067
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170755
]
name: aten::empty_like
id: 10358
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3068
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170772
]
name: aten::empty_strided
id: 10359
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3069
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170776
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 10360
duration_micros: 138
attr: [name: "rf_id"
int64_val: 3069
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123170808
]
name: aten::empty_strided
id: 10361
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3069
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170808
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10363
duration_micros: 48
attr: [name: "rf_id"
int64_val: 3070
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1888
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170872
]
name: aten::t
id: 10364
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3071
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170905
]
name: aten::transpose
id: 10365
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3072
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170909
]
name: aten::as_strided
id: 10366
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3073
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170915
]
name: aten::matmul
id: 10367
duration_micros: 22
attr: [name: "rf_id"
int64_val: 3074
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170944
]
name: aten::reshape
id: 10368
duration_micros: 39
attr: [name: "rf_id"
int64_val: 3075
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170948
]
name: aten::view
id: 10369
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3076
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123170951
]
name: aten::mm
id: 10370
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3077
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171000
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 10371
duration_micros: 522
attr: [name: "rf_id"
int64_val: 3077
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123171049
]
name: aten::mm
id: 10372
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3077
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171049
]
name: aten::_unsafe_view
id: 10374
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3078
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171069
]
name: GeLUFunction
id: 10375
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3079
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1889
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171114
]
name: TorchDynamo Cache Lookup
id: 10376
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3080
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171134
]
name: Torch-Compiled Region
id: 10377
duration_micros: 73
attr: [name: "rf_id"
int64_val: 3081
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171144
]
name: aten::empty
id: 10378
duration_micros: 22
attr: [name: "rf_id"
int64_val: 3082
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171182
]
name: triton_poi_fused_add_mul_tanh_0
id: 10379
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3083
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171221
]
name: triton__0d1d2d3de
id: 10380
duration_micros: 43
attr: [name: "rf_id"
int64_val: 3083
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123171237
]
name: triton_poi_fused_add_mul_tanh_0
id: 10381
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3083
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171237
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10383
duration_micros: 54
attr: [name: "rf_id"
int64_val: 3084
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1890
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171315
]
name: aten::t
id: 10384
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3085
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171324
]
name: aten::transpose
id: 10385
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3086
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171327
]
name: aten::as_strided
id: 10386
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3087
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171336
]
name: aten::matmul
id: 10387
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3088
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171365
]
name: aten::reshape
id: 10388
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3089
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171368
]
name: aten::view
id: 10389
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3090
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171372
]
name: aten::mm
id: 10390
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3091
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171387
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 10391
duration_micros: 568
attr: [name: "rf_id"
int64_val: 3091
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123171438
]
name: aten::mm
id: 10392
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3091
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171438
]
name: aten::_unsafe_view
id: 10394
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3092
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171455
]
name: _ReduceFromModelParallelRegion
id: 10395
duration_micros: 67
attr: [name: "rf_id"
int64_val: 3093
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1891
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171524
]
name: c10d::allreduce_
id: 10396
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3094
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171557
]
name: record_param_comms
id: 10397
duration_micros: 29
attr: [name: "rf_id"
int64_val: 3095
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171569
]
name: nccl:all_reduce
id: 10398
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3096
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171586
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 10399
duration_micros: 608
attr: [name: "rf_id"
int64_val: 3096
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123171602
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 10400
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3096
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171602
]
name: record_param_comms
id: 10402
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3097
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171674
]
name: aten::view_as
id: 10403
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3098
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171697
]
name: aten::view
id: 10404
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3099
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171701
]
name: aten::expand_as
id: 10405
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3100
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171740
]
name: aten::expand
id: 10406
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3101
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171744
]
name: aten::as_strided
id: 10407
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3102
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171751
]
name: TorchDynamo Cache Lookup
id: 10408
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3103
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171793
]
name: Torch-Compiled Region
id: 10409
duration_micros: 66
attr: [name: "rf_id"
int64_val: 3104
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171805
]
name: aten::empty
id: 10410
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3105
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171841
]
name: triton_poi_fused_add_0
id: 10411
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3106
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171874
]
name: triton__0d1d2d3d4de
id: 10412
duration_micros: 113
attr: [name: "rf_id"
int64_val: 3106
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123171891
]
name: triton_poi_fused_add_0
id: 10413
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3106
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171891
]
name: FusedLayerNormAffineFunction
id: 10415
duration_micros: 55
attr: [name: "rf_id"
int64_val: 3107
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1892
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123171994
]
name: aten::empty_like
id: 10416
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3108
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172006
]
name: aten::empty_strided
id: 10417
duration_micros: 20
attr: [name: "rf_id"
int64_val: 3109
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172013
]
name: aten::empty
id: 10418
duration_micros: 44
attr: [name: "rf_id"
int64_val: 3110
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172045
]
name: aten::empty_like
id: 10419
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3111
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172096
]
name: aten::empty_strided
id: 10420
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3112
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172100
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 10421
duration_micros: 134
attr: [name: "rf_id"
int64_val: 3112
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123172139
]
name: aten::empty_strided
id: 10422
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3112
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172139
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10424
duration_micros: 35
attr: [name: "rf_id"
int64_val: 3113
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1893
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172208
]
name: aten::t
id: 10425
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3114
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172217
]
name: aten::transpose
id: 10426
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3115
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172220
]
name: aten::as_strided
id: 10427
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3116
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172226
]
name: aten::matmul
id: 10428
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3117
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172255
]
name: aten::reshape
id: 10429
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3118
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172259
]
name: aten::view
id: 10430
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3119
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172262
]
name: aten::mm
id: 10431
duration_micros: 29
attr: [name: "rf_id"
int64_val: 3120
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172277
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 10432
duration_micros: 400
attr: [name: "rf_id"
int64_val: 3120
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123172325
]
name: aten::mm
id: 10433
duration_micros: 29
attr: [name: "rf_id"
int64_val: 3120
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172325
]
name: aten::_unsafe_view
id: 10435
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3121
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172343
]
name: aten::add
id: 10436
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3122
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172364
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 10437
duration_micros: 54
attr: [name: "rf_id"
int64_val: 3122
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123172387
]
name: aten::add
id: 10438
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3122
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172387
]
name: aten::view
id: 10440
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3123
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172424
]
name: aten::split_with_sizes
id: 10441
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3124
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172448
]
name: aten::as_strided
id: 10442
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3125
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172455
]
name: aten::as_strided
id: 10443
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3126
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172455
]
name: aten::as_strided
id: 10444
duration_micros: 38
attr: [name: "rf_id"
int64_val: 3127
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172469
]
name: aten::view
id: 10445
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3128
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172545
]
name: aten::reshape
id: 10446
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3129
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172571
]
name: aten::_reshape_alias
id: 10447
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3130
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172578
]
name: aten::view
id: 10448
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3131
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172597
]
name: aten::slice
id: 10449
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3132
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172618
]
name: aten::as_strided
id: 10450
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3133
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172623
]
name: aten::view
id: 10451
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3134
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172649
]
name: aten::transpose
id: 10452
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3135
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172669
]
name: aten::as_strided
id: 10453
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3136
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172675
]
name: aten::transpose
id: 10454
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3137
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172693
]
name: aten::as_strided
id: 10455
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3138
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172697
]
name: aten::transpose
id: 10456
duration_micros: 35
attr: [name: "rf_id"
int64_val: 3139
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172713
]
name: aten::as_strided
id: 10457
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3140
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172717
]
name: aten::baddbmm
id: 10458
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3141
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172770
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 10459
duration_micros: 295
attr: [name: "rf_id"
int64_val: 3141
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123172824
]
name: aten::baddbmm
id: 10460
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3141
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172824
]
name: aten::view
id: 10462
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3142
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172851
]
name: aten::view
id: 10463
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3143
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172851
]
name: ScaledUpperTriangMaskedSoftmax
id: 10464
duration_micros: 64
attr: [name: "rf_id"
int64_val: 3144
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1894
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172905
]
name: aten::empty
id: 10465
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3145
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172918
]
name: aten::to
id: 10466
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3146
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172938
]
name: aten::lift_fresh
id: 10467
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3147
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172949
]
name: aten::detach_
id: 10468
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3148
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172956
]
name: detach_
id: 10469
duration_micros: 2
attr: [name: "rf_id"
int64_val: 3149
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172958
]
name: aten::select
id: 10470
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3150
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172970
]
name: aten::as_strided
id: 10471
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3151
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172976
]
name: aten::item
id: 10472
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3152
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172995
]
name: aten::_local_scalar_dense
id: 10473
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3153
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123172997
]
name: aten::empty
id: 10474
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3154
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173013
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 10475
duration_micros: 426
attr: [name: "rf_id"
int64_val: 3154
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123173047
]
name: aten::empty
id: 10476
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3154
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173047
]
name: aten::view
id: 10478
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3155
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173069
]
name: aten::dropout
id: 10479
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3156
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173130
]
name: aten::view
id: 10480
duration_micros: 39
attr: [name: "rf_id"
int64_val: 3157
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173171
]
name: aten::view
id: 10481
duration_micros: 39
attr: [name: "rf_id"
int64_val: 3158
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173171
]
name: aten::transpose
id: 10482
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3159
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173236
]
name: aten::as_strided
id: 10483
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3160
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173242
]
name: aten::bmm
id: 10484
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3161
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173265
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 10485
duration_micros: 184
attr: [name: "rf_id"
int64_val: 3161
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123173302
]
name: aten::bmm
id: 10486
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3161
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173302
]
name: aten::view
id: 10488
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3162
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173323
]
name: aten::permute
id: 10489
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3163
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173338
]
name: aten::as_strided
id: 10490
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3164
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173344
]
name: aten::contiguous
id: 10491
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3165
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173364
]
name: aten::clone
id: 10492
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3166
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173366
]
name: aten::empty_like
id: 10493
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3167
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173370
]
name: aten::empty
id: 10494
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3168
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173374
]
name: aten::copy_
id: 10495
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3169
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173401
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 10496
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3169
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123173418
]
name: aten::copy_
id: 10497
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3169
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173418
]
name: aten::view
id: 10499
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3170
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173457
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10500
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3171
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1895
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173508
]
name: aten::t
id: 10501
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3172
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173517
]
name: aten::transpose
id: 10502
duration_micros: 44
attr: [name: "rf_id"
int64_val: 3173
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173520
]
name: aten::as_strided
id: 10503
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3174
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173529
]
name: aten::matmul
id: 10504
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3175
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173589
]
name: aten::reshape
id: 10505
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3176
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173594
]
name: aten::view
id: 10506
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3177
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173597
]
name: aten::mm
id: 10507
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3178
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173613
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 10508
duration_micros: 161
attr: [name: "rf_id"
int64_val: 3178
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123173658
]
name: aten::mm
id: 10509
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3178
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173658
]
name: aten::_unsafe_view
id: 10511
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3179
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173676
]
name: _ReduceFromModelParallelRegion
id: 10512
duration_micros: 67
attr: [name: "rf_id"
int64_val: 3180
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1896
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173721
]
name: c10d::allreduce_
id: 10513
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3181
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173754
]
name: record_param_comms
id: 10514
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3182
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173766
]
name: nccl:all_reduce
id: 10515
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3183
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173784
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 10516
duration_micros: 635
attr: [name: "rf_id"
int64_val: 3183
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123173802
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 10517
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3183
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173802
]
name: record_param_comms
id: 10519
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3184
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173874
]
name: aten::view_as
id: 10520
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3185
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173897
]
name: aten::view
id: 10521
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3186
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173902
]
name: aten::expand_as
id: 10522
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3187
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173945
]
name: aten::expand
id: 10523
duration_micros: 45
attr: [name: "rf_id"
int64_val: 3188
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173949
]
name: aten::as_strided
id: 10524
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3189
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123173956
]
name: TorchDynamo Cache Lookup
id: 10525
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3190
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174035
]
name: Torch-Compiled Region
id: 10526
duration_micros: 74
attr: [name: "rf_id"
int64_val: 3191
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174046
]
name: aten::empty
id: 10527
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3192
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174088
]
name: triton_poi_fused_add_0
id: 10528
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3193
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174122
]
name: triton__0d1d2d3d4de
id: 10529
duration_micros: 114
attr: [name: "rf_id"
int64_val: 3193
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123174139
]
name: triton_poi_fused_add_0
id: 10530
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3193
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174139
]
name: FusedLayerNormAffineFunction
id: 10532
duration_micros: 49
attr: [name: "rf_id"
int64_val: 3194
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1897
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174214
]
name: aten::empty_like
id: 10533
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3195
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174226
]
name: aten::empty_strided
id: 10534
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3196
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174232
]
name: aten::empty
id: 10535
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3197
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174266
]
name: aten::empty_like
id: 10536
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3198
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174283
]
name: aten::empty_strided
id: 10537
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3199
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174286
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 10538
duration_micros: 139
attr: [name: "rf_id"
int64_val: 3199
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123174318
]
name: aten::empty_strided
id: 10539
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3199
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174318
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10541
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3200
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1898
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174380
]
name: aten::t
id: 10542
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3201
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174389
]
name: aten::transpose
id: 10543
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3202
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174393
]
name: aten::as_strided
id: 10544
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3203
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174399
]
name: aten::matmul
id: 10545
duration_micros: 22
attr: [name: "rf_id"
int64_val: 3204
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174427
]
name: aten::reshape
id: 10546
duration_micros: 38
attr: [name: "rf_id"
int64_val: 3205
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174431
]
name: aten::view
id: 10547
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3206
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174434
]
name: aten::mm
id: 10548
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3207
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174482
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 10549
duration_micros: 523
attr: [name: "rf_id"
int64_val: 3207
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123174534
]
name: aten::mm
id: 10550
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3207
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174534
]
name: aten::_unsafe_view
id: 10552
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3208
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174554
]
name: GeLUFunction
id: 10553
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3209
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1899
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174600
]
name: TorchDynamo Cache Lookup
id: 10554
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3210
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174620
]
name: Torch-Compiled Region
id: 10555
duration_micros: 70
attr: [name: "rf_id"
int64_val: 3211
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174630
]
name: aten::empty
id: 10556
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3212
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174667
]
name: triton_poi_fused_add_mul_tanh_0
id: 10557
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3213
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174703
]
name: triton__0d1d2d3de
id: 10558
duration_micros: 43
attr: [name: "rf_id"
int64_val: 3213
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123174719
]
name: triton_poi_fused_add_mul_tanh_0
id: 10559
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3213
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174719
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10561
duration_micros: 53
attr: [name: "rf_id"
int64_val: 3214
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1900
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174798
]
name: aten::t
id: 10562
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3215
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174806
]
name: aten::transpose
id: 10563
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3216
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174810
]
name: aten::as_strided
id: 10564
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3217
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174816
]
name: aten::matmul
id: 10565
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3218
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174844
]
name: aten::reshape
id: 10566
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3219
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174848
]
name: aten::view
id: 10567
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3220
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174851
]
name: aten::mm
id: 10568
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3221
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174866
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 10569
duration_micros: 567
attr: [name: "rf_id"
int64_val: 3221
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123174917
]
name: aten::mm
id: 10570
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3221
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174917
]
name: aten::_unsafe_view
id: 10572
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3222
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123174935
]
name: _ReduceFromModelParallelRegion
id: 10573
duration_micros: 69
attr: [name: "rf_id"
int64_val: 3223
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1901
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175004
]
name: c10d::allreduce_
id: 10574
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3224
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175038
]
name: record_param_comms
id: 10575
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3225
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175050
]
name: nccl:all_reduce
id: 10576
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3226
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175066
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 10577
duration_micros: 605
attr: [name: "rf_id"
int64_val: 3226
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123175082
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 10578
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3226
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175082
]
name: record_param_comms
id: 10580
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3227
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175155
]
name: aten::view_as
id: 10581
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3228
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175177
]
name: aten::view
id: 10582
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3229
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175181
]
name: aten::expand_as
id: 10583
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3230
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175224
]
name: aten::expand
id: 10584
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3231
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175228
]
name: aten::as_strided
id: 10585
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3232
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175235
]
name: TorchDynamo Cache Lookup
id: 10586
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3233
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175278
]
name: Torch-Compiled Region
id: 10587
duration_micros: 66
attr: [name: "rf_id"
int64_val: 3234
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175289
]
name: aten::empty
id: 10588
duration_micros: 20
attr: [name: "rf_id"
int64_val: 3235
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175326
]
name: triton_poi_fused_add_0
id: 10589
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3236
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175358
]
name: triton__0d1d2d3d4de
id: 10590
duration_micros: 114
attr: [name: "rf_id"
int64_val: 3236
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123175375
]
name: triton_poi_fused_add_0
id: 10591
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3236
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175375
]
name: FusedLayerNormAffineFunction
id: 10593
duration_micros: 53
attr: [name: "rf_id"
int64_val: 3237
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1902
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175480
]
name: aten::empty_like
id: 10594
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3238
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175492
]
name: aten::empty_strided
id: 10595
duration_micros: 20
attr: [name: "rf_id"
int64_val: 3239
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175499
]
name: aten::empty
id: 10596
duration_micros: 46
attr: [name: "rf_id"
int64_val: 3240
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175531
]
name: aten::empty_like
id: 10597
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3241
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175583
]
name: aten::empty_strided
id: 10598
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3242
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175588
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 10599
duration_micros: 137
attr: [name: "rf_id"
int64_val: 3242
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123175626
]
name: aten::empty_strided
id: 10600
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3242
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175626
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10602
duration_micros: 36
attr: [name: "rf_id"
int64_val: 3243
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1903
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175693
]
name: aten::t
id: 10603
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3244
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175702
]
name: aten::transpose
id: 10604
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3245
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175706
]
name: aten::as_strided
id: 10605
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3246
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175715
]
name: aten::matmul
id: 10606
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3247
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175744
]
name: aten::reshape
id: 10607
duration_micros: 27544
attr: [name: "rf_id"
int64_val: 3248
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175748
]
name: aten::view
id: 10608
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3249
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123175751
]
name: aten::mm
id: 10609
duration_micros: 39
attr: [name: "rf_id"
int64_val: 3250
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203308
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 10610
duration_micros: 400
attr: [name: "rf_id"
int64_val: 3250
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123203374
]
name: aten::mm
id: 10611
duration_micros: 39
attr: [name: "rf_id"
int64_val: 3250
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203374
]
name: aten::_unsafe_view
id: 10613
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3251
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203393
]
name: aten::add
id: 10614
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3252
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203417
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 10615
duration_micros: 54
attr: [name: "rf_id"
int64_val: 3252
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123203439
]
name: aten::add
id: 10616
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3252
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203439
]
name: aten::view
id: 10618
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3253
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203478
]
name: aten::split_with_sizes
id: 10619
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3254
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203504
]
name: aten::as_strided
id: 10620
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3255
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203511
]
name: aten::as_strided
id: 10621
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3256
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203511
]
name: aten::as_strided
id: 10622
duration_micros: 39
attr: [name: "rf_id"
int64_val: 3257
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203525
]
name: aten::view
id: 10623
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3258
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203603
]
name: aten::reshape
id: 10624
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3259
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203631
]
name: aten::_reshape_alias
id: 10625
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3260
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203643
]
name: aten::view
id: 10626
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3261
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203664
]
name: aten::slice
id: 10627
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3262
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203686
]
name: aten::as_strided
id: 10628
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3263
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203691
]
name: aten::view
id: 10629
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3264
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203716
]
name: aten::transpose
id: 10630
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3265
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203730
]
name: aten::as_strided
id: 10631
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3266
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203735
]
name: aten::transpose
id: 10632
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3267
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203753
]
name: aten::as_strided
id: 10633
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3268
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203757
]
name: aten::transpose
id: 10634
duration_micros: 36
attr: [name: "rf_id"
int64_val: 3269
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203773
]
name: aten::as_strided
id: 10635
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3270
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203777
]
name: aten::baddbmm
id: 10636
duration_micros: 33
attr: [name: "rf_id"
int64_val: 3271
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203833
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 10637
duration_micros: 294
attr: [name: "rf_id"
int64_val: 3271
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123203885
]
name: aten::baddbmm
id: 10638
duration_micros: 33
attr: [name: "rf_id"
int64_val: 3271
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203885
]
name: aten::view
id: 10640
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3272
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203912
]
name: aten::view
id: 10641
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3273
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203912
]
name: ScaledUpperTriangMaskedSoftmax
id: 10642
duration_micros: 66
attr: [name: "rf_id"
int64_val: 3274
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1904
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203968
]
name: aten::empty
id: 10643
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3275
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203982
]
name: aten::to
id: 10644
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3276
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123203999
]
name: aten::lift_fresh
id: 10645
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3277
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204009
]
name: aten::detach_
id: 10646
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3278
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204017
]
name: detach_
id: 10647
duration_micros: 3
attr: [name: "rf_id"
int64_val: 3279
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204018
]
name: aten::select
id: 10648
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3280
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204031
]
name: aten::as_strided
id: 10649
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3281
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204037
]
name: aten::item
id: 10650
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3282
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204056
]
name: aten::_local_scalar_dense
id: 10651
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3283
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204058
]
name: aten::empty
id: 10652
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3284
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204075
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 10653
duration_micros: 425
attr: [name: "rf_id"
int64_val: 3284
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123204106
]
name: aten::empty
id: 10654
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3284
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204106
]
name: aten::view
id: 10656
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3285
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204129
]
name: aten::dropout
id: 10657
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3286
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204193
]
name: aten::view
id: 10658
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3287
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204238
]
name: aten::view
id: 10659
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3288
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204238
]
name: aten::transpose
id: 10660
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3289
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204303
]
name: aten::as_strided
id: 10661
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3290
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204312
]
name: aten::bmm
id: 10662
duration_micros: 23
attr: [name: "rf_id"
int64_val: 3291
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204333
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 10663
duration_micros: 184
attr: [name: "rf_id"
int64_val: 3291
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123204368
]
name: aten::bmm
id: 10664
duration_micros: 23
attr: [name: "rf_id"
int64_val: 3291
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204368
]
name: aten::view
id: 10666
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3292
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204389
]
name: aten::permute
id: 10667
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3293
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204404
]
name: aten::as_strided
id: 10668
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3294
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204410
]
name: aten::contiguous
id: 10669
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3295
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204430
]
name: aten::clone
id: 10670
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3296
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204433
]
name: aten::empty_like
id: 10671
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3297
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204437
]
name: aten::empty
id: 10672
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3298
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204441
]
name: aten::copy_
id: 10673
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3299
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204466
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 10674
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3299
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123204483
]
name: aten::copy_
id: 10675
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3299
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204483
]
name: aten::view
id: 10677
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3300
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204522
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10678
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3301
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1905
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204578
]
name: aten::t
id: 10679
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3302
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204587
]
name: aten::transpose
id: 10680
duration_micros: 41
attr: [name: "rf_id"
int64_val: 3303
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204591
]
name: aten::as_strided
id: 10681
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3304
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204596
]
name: aten::matmul
id: 10682
duration_micros: 20
attr: [name: "rf_id"
int64_val: 3305
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204657
]
name: aten::reshape
id: 10683
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3306
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204662
]
name: aten::view
id: 10684
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3307
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204665
]
name: aten::mm
id: 10685
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3308
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204681
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 10686
duration_micros: 161
attr: [name: "rf_id"
int64_val: 3308
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123204725
]
name: aten::mm
id: 10687
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3308
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204725
]
name: aten::_unsafe_view
id: 10689
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3309
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204742
]
name: _ReduceFromModelParallelRegion
id: 10690
duration_micros: 64
attr: [name: "rf_id"
int64_val: 3310
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1906
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204779
]
name: c10d::allreduce_
id: 10691
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3311
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204809
]
name: record_param_comms
id: 10692
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3312
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204821
]
name: nccl:all_reduce
id: 10693
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3313
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204836
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 10694
duration_micros: 2316
attr: [name: "rf_id"
int64_val: 3313
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123204854
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 10695
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3313
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204854
]
name: record_param_comms
id: 10697
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3314
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204927
]
name: aten::view_as
id: 10698
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3315
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204950
]
name: aten::view
id: 10699
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3316
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204954
]
name: aten::expand_as
id: 10700
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3317
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123204998
]
name: aten::expand
id: 10701
duration_micros: 43
attr: [name: "rf_id"
int64_val: 3318
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205002
]
name: aten::as_strided
id: 10702
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3319
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205008
]
name: TorchDynamo Cache Lookup
id: 10703
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3320
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205089
]
name: Torch-Compiled Region
id: 10704
duration_micros: 78
attr: [name: "rf_id"
int64_val: 3321
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205102
]
name: aten::empty
id: 10705
duration_micros: 20
attr: [name: "rf_id"
int64_val: 3322
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205147
]
name: triton_poi_fused_add_0
id: 10706
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3323
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205181
]
name: triton__0d1d2d3d4de
id: 10707
duration_micros: 114
attr: [name: "rf_id"
int64_val: 3323
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123205199
]
name: triton_poi_fused_add_0
id: 10708
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3323
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205199
]
name: FusedLayerNormAffineFunction
id: 10710
duration_micros: 49
attr: [name: "rf_id"
int64_val: 3324
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1907
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205278
]
name: aten::empty_like
id: 10711
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3325
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205291
]
name: aten::empty_strided
id: 10712
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3326
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205297
]
name: aten::empty
id: 10713
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3327
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205327
]
name: aten::empty_like
id: 10714
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3328
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205343
]
name: aten::empty_strided
id: 10715
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3329
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205347
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 10716
duration_micros: 136
attr: [name: "rf_id"
int64_val: 3329
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123205379
]
name: aten::empty_strided
id: 10717
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3329
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205379
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10719
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3330
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1908
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205442
]
name: aten::t
id: 10720
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3331
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205451
]
name: aten::transpose
id: 10721
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3332
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205455
]
name: aten::as_strided
id: 10722
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3333
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205466
]
name: aten::matmul
id: 10723
duration_micros: 22
attr: [name: "rf_id"
int64_val: 3334
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205495
]
name: aten::reshape
id: 10724
duration_micros: 37
attr: [name: "rf_id"
int64_val: 3335
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205499
]
name: aten::view
id: 10725
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3336
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205502
]
name: aten::mm
id: 10726
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3337
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205550
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 10727
duration_micros: 521
attr: [name: "rf_id"
int64_val: 3337
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123205598
]
name: aten::mm
id: 10728
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3337
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205598
]
name: aten::_unsafe_view
id: 10730
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3338
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205616
]
name: GeLUFunction
id: 10731
duration_micros: 33
attr: [name: "rf_id"
int64_val: 3339
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1909
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205660
]
name: TorchDynamo Cache Lookup
id: 10732
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3340
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205682
]
name: Torch-Compiled Region
id: 10733
duration_micros: 78
attr: [name: "rf_id"
int64_val: 3341
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205692
]
name: aten::empty
id: 10734
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3342
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205739
]
name: triton_poi_fused_add_mul_tanh_0
id: 10735
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3343
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205771
]
name: triton__0d1d2d3de
id: 10736
duration_micros: 43
attr: [name: "rf_id"
int64_val: 3343
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123205787
]
name: triton_poi_fused_add_mul_tanh_0
id: 10737
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3343
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205787
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10739
duration_micros: 54
attr: [name: "rf_id"
int64_val: 3344
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1910
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205865
]
name: aten::t
id: 10740
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3345
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205874
]
name: aten::transpose
id: 10741
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3346
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205878
]
name: aten::as_strided
id: 10742
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3347
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205884
]
name: aten::matmul
id: 10743
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3348
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205912
]
name: aten::reshape
id: 10744
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3349
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205916
]
name: aten::view
id: 10745
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3350
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205919
]
name: aten::mm
id: 10746
duration_micros: 1085
attr: [name: "rf_id"
int64_val: 3351
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123205935
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 10747
duration_micros: 574
attr: [name: "rf_id"
int64_val: 3351
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123208089
]
name: aten::mm
id: 10748
duration_micros: 1085
attr: [name: "rf_id"
int64_val: 3351
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208089
]
name: aten::_unsafe_view
id: 10750
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3352
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208113
]
name: _ReduceFromModelParallelRegion
id: 10751
duration_micros: 70
attr: [name: "rf_id"
int64_val: 3353
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1911
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208189
]
name: c10d::allreduce_
id: 10752
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3354
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208225
]
name: record_param_comms
id: 10753
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3355
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208237
]
name: nccl:all_reduce
id: 10754
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3356
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208254
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 10755
duration_micros: 628
attr: [name: "rf_id"
int64_val: 3356
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123208271
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 10756
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3356
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208271
]
name: record_param_comms
id: 10758
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3357
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208341
]
name: aten::view_as
id: 10759
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3358
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208363
]
name: aten::view
id: 10760
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3359
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208367
]
name: aten::expand_as
id: 10761
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3360
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208407
]
name: aten::expand
id: 10762
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3361
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208411
]
name: aten::as_strided
id: 10763
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3362
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208418
]
name: TorchDynamo Cache Lookup
id: 10764
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3363
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208462
]
name: Torch-Compiled Region
id: 10765
duration_micros: 67
attr: [name: "rf_id"
int64_val: 3364
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208474
]
name: aten::empty
id: 10766
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3365
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208511
]
name: triton_poi_fused_add_0
id: 10767
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3366
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208542
]
name: triton__0d1d2d3d4de
id: 10768
duration_micros: 114
attr: [name: "rf_id"
int64_val: 3366
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123208558
]
name: triton_poi_fused_add_0
id: 10769
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3366
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208558
]
name: FusedLayerNormAffineFunction
id: 10771
duration_micros: 55
attr: [name: "rf_id"
int64_val: 3367
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1912
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208668
]
name: aten::empty_like
id: 10772
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3368
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208680
]
name: aten::empty_strided
id: 10773
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3369
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208687
]
name: aten::empty
id: 10774
duration_micros: 46
attr: [name: "rf_id"
int64_val: 3370
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208721
]
name: aten::empty_like
id: 10775
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3371
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208773
]
name: aten::empty_strided
id: 10776
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3372
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208781
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 10777
duration_micros: 137
attr: [name: "rf_id"
int64_val: 3372
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123208822
]
name: aten::empty_strided
id: 10778
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3372
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208822
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10780
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3373
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1913
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208891
]
name: aten::t
id: 10781
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3374
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208900
]
name: aten::transpose
id: 10782
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3375
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208904
]
name: aten::as_strided
id: 10783
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3376
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208911
]
name: aten::matmul
id: 10784
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3377
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208939
]
name: aten::reshape
id: 10785
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3378
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208944
]
name: aten::view
id: 10786
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3379
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208947
]
name: aten::mm
id: 10787
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3380
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123208962
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 10788
duration_micros: 400
attr: [name: "rf_id"
int64_val: 3380
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123209007
]
name: aten::mm
id: 10789
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3380
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209007
]
name: aten::_unsafe_view
id: 10791
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3381
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209025
]
name: aten::add
id: 10792
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3382
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209046
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 10793
duration_micros: 54
attr: [name: "rf_id"
int64_val: 3382
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123209069
]
name: aten::add
id: 10794
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3382
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209069
]
name: aten::view
id: 10796
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3383
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209107
]
name: aten::split_with_sizes
id: 10797
duration_micros: 35
attr: [name: "rf_id"
int64_val: 3384
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209131
]
name: aten::as_strided
id: 10798
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3385
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209138
]
name: aten::as_strided
id: 10799
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3386
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209138
]
name: aten::as_strided
id: 10800
duration_micros: 37
attr: [name: "rf_id"
int64_val: 3387
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209152
]
name: aten::view
id: 10801
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3388
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209234
]
name: aten::reshape
id: 10802
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3389
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209260
]
name: aten::_reshape_alias
id: 10803
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3390
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209268
]
name: aten::view
id: 10804
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3391
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209288
]
name: aten::slice
id: 10805
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3392
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209309
]
name: aten::as_strided
id: 10806
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3393
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209314
]
name: aten::view
id: 10807
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3394
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209340
]
name: aten::transpose
id: 10808
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3395
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209353
]
name: aten::as_strided
id: 10809
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3396
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209358
]
name: aten::transpose
id: 10810
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3397
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209376
]
name: aten::as_strided
id: 10811
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3398
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209380
]
name: aten::transpose
id: 10812
duration_micros: 38
attr: [name: "rf_id"
int64_val: 3399
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209396
]
name: aten::as_strided
id: 10813
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3400
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209403
]
name: aten::baddbmm
id: 10814
duration_micros: 37
attr: [name: "rf_id"
int64_val: 3401
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209457
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 10815
duration_micros: 293
attr: [name: "rf_id"
int64_val: 3401
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123209516
]
name: aten::baddbmm
id: 10816
duration_micros: 37
attr: [name: "rf_id"
int64_val: 3401
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209516
]
name: aten::view
id: 10818
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3402
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209543
]
name: aten::view
id: 10819
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3403
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209543
]
name: ScaledUpperTriangMaskedSoftmax
id: 10820
duration_micros: 63
attr: [name: "rf_id"
int64_val: 3404
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1914
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209598
]
name: aten::empty
id: 10821
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3405
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209611
]
name: aten::to
id: 10822
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3406
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209627
]
name: aten::lift_fresh
id: 10823
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3407
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209638
]
name: aten::detach_
id: 10824
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3408
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209645
]
name: detach_
id: 10825
duration_micros: 2
attr: [name: "rf_id"
int64_val: 3409
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209647
]
name: aten::select
id: 10826
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3410
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209659
]
name: aten::as_strided
id: 10827
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3411
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209665
]
name: aten::item
id: 10828
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3412
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209683
]
name: aten::_local_scalar_dense
id: 10829
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3413
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209685
]
name: aten::empty
id: 10830
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3414
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209709
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 10831
duration_micros: 426
attr: [name: "rf_id"
int64_val: 3414
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123209744
]
name: aten::empty
id: 10832
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3414
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209744
]
name: aten::view
id: 10834
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3415
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209767
]
name: aten::dropout
id: 10835
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3416
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209828
]
name: aten::view
id: 10836
duration_micros: 39
attr: [name: "rf_id"
int64_val: 3417
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209868
]
name: aten::view
id: 10837
duration_micros: 39
attr: [name: "rf_id"
int64_val: 3418
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209868
]
name: aten::transpose
id: 10838
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3419
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209933
]
name: aten::as_strided
id: 10839
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3420
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209939
]
name: aten::bmm
id: 10840
duration_micros: 23
attr: [name: "rf_id"
int64_val: 3421
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209958
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 10841
duration_micros: 185
attr: [name: "rf_id"
int64_val: 3421
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123209993
]
name: aten::bmm
id: 10842
duration_micros: 23
attr: [name: "rf_id"
int64_val: 3421
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123209993
]
name: aten::view
id: 10844
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3422
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210014
]
name: aten::permute
id: 10845
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3423
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210029
]
name: aten::as_strided
id: 10846
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3424
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210035
]
name: aten::contiguous
id: 10847
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3425
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210058
]
name: aten::clone
id: 10848
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3426
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210060
]
name: aten::empty_like
id: 10849
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3427
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210064
]
name: aten::empty
id: 10850
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3428
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210068
]
name: aten::copy_
id: 10851
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3429
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210093
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 10852
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3429
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123210110
]
name: aten::copy_
id: 10853
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3429
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210110
]
name: aten::view
id: 10855
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3430
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210149
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10856
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3431
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1915
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210199
]
name: aten::t
id: 10857
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3432
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210208
]
name: aten::transpose
id: 10858
duration_micros: 41
attr: [name: "rf_id"
int64_val: 3433
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210211
]
name: aten::as_strided
id: 10859
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3434
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210216
]
name: aten::matmul
id: 10860
duration_micros: 20
attr: [name: "rf_id"
int64_val: 3435
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210277
]
name: aten::reshape
id: 10861
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3436
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210282
]
name: aten::view
id: 10862
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3437
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210285
]
name: aten::mm
id: 10863
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3438
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210302
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 10864
duration_micros: 162
attr: [name: "rf_id"
int64_val: 3438
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123210344
]
name: aten::mm
id: 10865
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3438
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210344
]
name: aten::_unsafe_view
id: 10867
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3439
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210361
]
name: _ReduceFromModelParallelRegion
id: 10868
duration_micros: 60
attr: [name: "rf_id"
int64_val: 3440
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1916
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210402
]
name: c10d::allreduce_
id: 10869
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3441
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210430
]
name: record_param_comms
id: 10870
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3442
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210441
]
name: nccl:all_reduce
id: 10871
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3443
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210456
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 10872
duration_micros: 17523
attr: [name: "rf_id"
int64_val: 3443
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123210473
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 10873
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3443
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210473
]
name: record_param_comms
id: 10875
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3444
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210540
]
name: aten::view_as
id: 10876
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3445
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210562
]
name: aten::view
id: 10877
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3446
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210566
]
name: aten::expand_as
id: 10878
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3447
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210609
]
name: aten::expand
id: 10879
duration_micros: 43
attr: [name: "rf_id"
int64_val: 3448
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210613
]
name: aten::as_strided
id: 10880
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3449
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210619
]
name: TorchDynamo Cache Lookup
id: 10881
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3450
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210697
]
name: Torch-Compiled Region
id: 10882
duration_micros: 72
attr: [name: "rf_id"
int64_val: 3451
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210711
]
name: aten::empty
id: 10883
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3452
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210752
]
name: triton_poi_fused_add_0
id: 10884
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3453
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210784
]
name: triton__0d1d2d3d4de
id: 10885
duration_micros: 113
attr: [name: "rf_id"
int64_val: 3453
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123210801
]
name: triton_poi_fused_add_0
id: 10886
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3453
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210801
]
name: FusedLayerNormAffineFunction
id: 10888
duration_micros: 50
attr: [name: "rf_id"
int64_val: 3454
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1917
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210877
]
name: aten::empty_like
id: 10889
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3455
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210889
]
name: aten::empty_strided
id: 10890
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3456
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210896
]
name: aten::empty
id: 10891
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3457
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210926
]
name: aten::empty_like
id: 10892
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3458
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210942
]
name: aten::empty_strided
id: 10893
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3459
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210945
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 10894
duration_micros: 134
attr: [name: "rf_id"
int64_val: 3459
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123210981
]
name: aten::empty_strided
id: 10895
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3459
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123210981
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10897
duration_micros: 22
attr: [name: "rf_id"
int64_val: 3460
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1918
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211044
]
name: aten::t
id: 10898
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3461
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211052
]
name: aten::transpose
id: 10899
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3462
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211056
]
name: aten::as_strided
id: 10900
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3463
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211062
]
name: aten::matmul
id: 10901
duration_micros: 22
attr: [name: "rf_id"
int64_val: 3464
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211090
]
name: aten::reshape
id: 10902
duration_micros: 38
attr: [name: "rf_id"
int64_val: 3465
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211094
]
name: aten::view
id: 10903
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3466
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211097
]
name: aten::mm
id: 10904
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3467
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211145
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 10905
duration_micros: 522
attr: [name: "rf_id"
int64_val: 3467
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123211193
]
name: aten::mm
id: 10906
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3467
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211193
]
name: aten::_unsafe_view
id: 10908
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3468
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211212
]
name: GeLUFunction
id: 10909
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3469
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1919
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211256
]
name: TorchDynamo Cache Lookup
id: 10910
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3470
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211277
]
name: Torch-Compiled Region
id: 10911
duration_micros: 66
attr: [name: "rf_id"
int64_val: 3471
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211287
]
name: aten::empty
id: 10912
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3472
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211324
]
name: triton_poi_fused_add_mul_tanh_0
id: 10913
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3473
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211354
]
name: triton__0d1d2d3de
id: 10914
duration_micros: 43
attr: [name: "rf_id"
int64_val: 3473
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123211370
]
name: triton_poi_fused_add_mul_tanh_0
id: 10915
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3473
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211370
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10917
duration_micros: 53
attr: [name: "rf_id"
int64_val: 3474
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1920
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211447
]
name: aten::t
id: 10918
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3475
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211456
]
name: aten::transpose
id: 10919
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3476
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211459
]
name: aten::as_strided
id: 10920
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3477
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211466
]
name: aten::matmul
id: 10921
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3478
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211497
]
name: aten::reshape
id: 10922
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3479
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211501
]
name: aten::view
id: 10923
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3480
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211504
]
name: aten::mm
id: 10924
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3481
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211520
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 10925
duration_micros: 565
attr: [name: "rf_id"
int64_val: 3481
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123211569
]
name: aten::mm
id: 10926
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3481
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211569
]
name: aten::_unsafe_view
id: 10928
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3482
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211586
]
name: _ReduceFromModelParallelRegion
id: 10929
duration_micros: 69
attr: [name: "rf_id"
int64_val: 3483
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1921
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211656
]
name: c10d::allreduce_
id: 10930
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3484
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211690
]
name: record_param_comms
id: 10931
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3485
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211702
]
name: nccl:all_reduce
id: 10932
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3486
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211718
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 10933
duration_micros: 609
attr: [name: "rf_id"
int64_val: 3486
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123211735
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 10934
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3486
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211735
]
name: record_param_comms
id: 10936
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3487
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211809
]
name: aten::view_as
id: 10937
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3488
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211832
]
name: aten::view
id: 10938
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3489
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211836
]
name: aten::expand_as
id: 10939
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3490
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211876
]
name: aten::expand
id: 10940
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3491
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211880
]
name: aten::as_strided
id: 10941
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3492
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211887
]
name: TorchDynamo Cache Lookup
id: 10942
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3493
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211930
]
name: Torch-Compiled Region
id: 10943
duration_micros: 67
attr: [name: "rf_id"
int64_val: 3494
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211941
]
name: aten::empty
id: 10944
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3495
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123211978
]
name: triton_poi_fused_add_0
id: 10945
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3496
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212008
]
name: triton__0d1d2d3d4de
id: 10946
duration_micros: 113
attr: [name: "rf_id"
int64_val: 3496
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123212024
]
name: triton_poi_fused_add_0
id: 10947
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3496
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212024
]
name: FusedLayerNormAffineFunction
id: 10949
duration_micros: 55
attr: [name: "rf_id"
int64_val: 3497
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1922
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212130
]
name: aten::empty_like
id: 10950
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3498
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212142
]
name: aten::empty_strided
id: 10951
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3499
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212149
]
name: aten::empty
id: 10952
duration_micros: 45
attr: [name: "rf_id"
int64_val: 3500
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212182
]
name: aten::empty_like
id: 10953
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3501
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212234
]
name: aten::empty_strided
id: 10954
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3502
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212238
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 10955
duration_micros: 135
attr: [name: "rf_id"
int64_val: 3502
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123212277
]
name: aten::empty_strided
id: 10956
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3502
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212277
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 10958
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3503
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1923
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212346
]
name: aten::t
id: 10959
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3504
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212355
]
name: aten::transpose
id: 10960
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3505
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212358
]
name: aten::as_strided
id: 10961
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3506
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212364
]
name: aten::matmul
id: 10962
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3507
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212393
]
name: aten::reshape
id: 10963
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3508
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212397
]
name: aten::view
id: 10964
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3509
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212400
]
name: aten::mm
id: 10965
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3510
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212416
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 10966
duration_micros: 400
attr: [name: "rf_id"
int64_val: 3510
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123212460
]
name: aten::mm
id: 10967
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3510
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212460
]
name: aten::_unsafe_view
id: 10969
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3511
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212477
]
name: aten::add
id: 10970
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3512
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212499
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 10971
duration_micros: 54
attr: [name: "rf_id"
int64_val: 3512
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123212521
]
name: aten::add
id: 10972
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3512
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212521
]
name: aten::view
id: 10974
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3513
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212558
]
name: aten::split_with_sizes
id: 10975
duration_micros: 37
attr: [name: "rf_id"
int64_val: 3514
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212582
]
name: aten::as_strided
id: 10976
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3515
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212588
]
name: aten::as_strided
id: 10977
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3516
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212588
]
name: aten::as_strided
id: 10978
duration_micros: 36
attr: [name: "rf_id"
int64_val: 3517
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212607
]
name: aten::view
id: 10979
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3518
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212683
]
name: aten::reshape
id: 10980
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3519
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212709
]
name: aten::_reshape_alias
id: 10981
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3520
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212716
]
name: aten::view
id: 10982
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3521
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212735
]
name: aten::slice
id: 10983
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3522
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212756
]
name: aten::as_strided
id: 10984
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3523
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212761
]
name: aten::view
id: 10985
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3524
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212786
]
name: aten::transpose
id: 10986
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3525
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212799
]
name: aten::as_strided
id: 10987
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3526
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212804
]
name: aten::transpose
id: 10988
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3527
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212825
]
name: aten::as_strided
id: 10989
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3528
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212829
]
name: aten::transpose
id: 10990
duration_micros: 36
attr: [name: "rf_id"
int64_val: 3529
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212845
]
name: aten::as_strided
id: 10991
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3530
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212850
]
name: aten::baddbmm
id: 10992
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3531
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212903
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 10993
duration_micros: 294
attr: [name: "rf_id"
int64_val: 3531
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123212957
]
name: aten::baddbmm
id: 10994
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3531
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212957
]
name: aten::view
id: 10996
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3532
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212983
]
name: aten::view
id: 10997
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3533
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123212983
]
name: ScaledUpperTriangMaskedSoftmax
id: 10998
duration_micros: 64
attr: [name: "rf_id"
int64_val: 3534
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1924
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213037
]
name: aten::empty
id: 10999
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3535
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213049
]
name: aten::to
id: 11000
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3536
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213066
]
name: aten::lift_fresh
id: 11001
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3537
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213076
]
name: aten::detach_
id: 11002
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3538
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213084
]
name: detach_
id: 11003
duration_micros: 2
attr: [name: "rf_id"
int64_val: 3539
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213086
]
name: aten::select
id: 11004
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3540
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213098
]
name: aten::as_strided
id: 11005
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3541
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213106
]
name: aten::item
id: 11006
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3542
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213126
]
name: aten::_local_scalar_dense
id: 11007
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3543
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213128
]
name: aten::empty
id: 11008
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3544
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213146
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 11009
duration_micros: 426
attr: [name: "rf_id"
int64_val: 3544
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123213179
]
name: aten::empty
id: 11010
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3544
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213179
]
name: aten::view
id: 11012
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3545
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213202
]
name: aten::dropout
id: 11013
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3546
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213262
]
name: aten::view
id: 11014
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3547
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213303
]
name: aten::view
id: 11015
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3548
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213303
]
name: aten::transpose
id: 11016
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3549
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213368
]
name: aten::as_strided
id: 11017
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3550
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213374
]
name: aten::bmm
id: 11018
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3551
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213394
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 11019
duration_micros: 185
attr: [name: "rf_id"
int64_val: 3551
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123213431
]
name: aten::bmm
id: 11020
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3551
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213431
]
name: aten::view
id: 11022
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3552
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213453
]
name: aten::permute
id: 11023
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3553
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213467
]
name: aten::as_strided
id: 11024
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3554
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213482
]
name: aten::contiguous
id: 11025
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3555
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213503
]
name: aten::clone
id: 11026
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3556
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213505
]
name: aten::empty_like
id: 11027
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3557
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213510
]
name: aten::empty
id: 11028
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3558
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213514
]
name: aten::copy_
id: 11029
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3559
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213541
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 11030
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3559
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123213559
]
name: aten::copy_
id: 11031
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3559
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213559
]
name: aten::view
id: 11033
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3560
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213598
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11034
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3561
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1925
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213649
]
name: aten::t
id: 11035
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3562
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213657
]
name: aten::transpose
id: 11036
duration_micros: 46
attr: [name: "rf_id"
int64_val: 3563
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213661
]
name: aten::as_strided
id: 11037
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3564
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213666
]
name: aten::matmul
id: 11038
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3565
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213733
]
name: aten::reshape
id: 11039
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3566
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213738
]
name: aten::view
id: 11040
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3567
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213744
]
name: aten::mm
id: 11041
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3568
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213761
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 11042
duration_micros: 158
attr: [name: "rf_id"
int64_val: 3568
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123213807
]
name: aten::mm
id: 11043
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3568
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213807
]
name: aten::_unsafe_view
id: 11045
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3569
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213823
]
name: _ReduceFromModelParallelRegion
id: 11046
duration_micros: 70
attr: [name: "rf_id"
int64_val: 3570
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1926
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213860
]
name: c10d::allreduce_
id: 11047
duration_micros: 29
attr: [name: "rf_id"
int64_val: 3571
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213896
]
name: record_param_comms
id: 11048
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3572
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213907
]
name: nccl:all_reduce
id: 11049
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3573
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213922
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 11050
duration_micros: 605
attr: [name: "rf_id"
int64_val: 3573
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123213939
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 11051
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3573
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123213939
]
name: record_param_comms
id: 11053
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3574
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214010
]
name: aten::view_as
id: 11054
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3575
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214033
]
name: aten::view
id: 11055
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3576
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214037
]
name: aten::expand_as
id: 11056
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3577
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214079
]
name: aten::expand
id: 11057
duration_micros: 44
attr: [name: "rf_id"
int64_val: 3578
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214087
]
name: aten::as_strided
id: 11058
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3579
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214093
]
name: TorchDynamo Cache Lookup
id: 11059
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3580
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214172
]
name: Torch-Compiled Region
id: 11060
duration_micros: 95
attr: [name: "rf_id"
int64_val: 3581
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214184
]
name: aten::empty
id: 11061
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3582
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214225
]
name: triton_poi_fused_add_0
id: 11062
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3583
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214281
]
name: triton__0d1d2d3d4de
id: 11063
duration_micros: 113
attr: [name: "rf_id"
int64_val: 3583
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123214298
]
name: triton_poi_fused_add_0
id: 11064
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3583
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214298
]
name: FusedLayerNormAffineFunction
id: 11066
duration_micros: 48
attr: [name: "rf_id"
int64_val: 3584
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1927
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214375
]
name: aten::empty_like
id: 11067
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3585
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214386
]
name: aten::empty_strided
id: 11068
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3586
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214393
]
name: aten::empty
id: 11069
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3587
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214426
]
name: aten::empty_like
id: 11070
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3588
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214443
]
name: aten::empty_strided
id: 11071
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3589
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214447
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 11072
duration_micros: 136
attr: [name: "rf_id"
int64_val: 3589
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123214483
]
name: aten::empty_strided
id: 11073
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3589
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214483
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11075
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3590
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1928
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214546
]
name: aten::t
id: 11076
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3591
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214555
]
name: aten::transpose
id: 11077
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3592
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214558
]
name: aten::as_strided
id: 11078
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3593
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214564
]
name: aten::matmul
id: 11079
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3594
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214593
]
name: aten::reshape
id: 11080
duration_micros: 37
attr: [name: "rf_id"
int64_val: 3595
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214597
]
name: aten::view
id: 11081
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3596
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214600
]
name: aten::mm
id: 11082
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3597
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214647
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 11083
duration_micros: 522
attr: [name: "rf_id"
int64_val: 3597
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123214698
]
name: aten::mm
id: 11084
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3597
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214698
]
name: aten::_unsafe_view
id: 11086
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3598
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214718
]
name: GeLUFunction
id: 11087
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3599
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1929
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214763
]
name: TorchDynamo Cache Lookup
id: 11088
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3600
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214783
]
name: Torch-Compiled Region
id: 11089
duration_micros: 67
attr: [name: "rf_id"
int64_val: 3601
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214793
]
name: aten::empty
id: 11090
duration_micros: 20
attr: [name: "rf_id"
int64_val: 3602
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214830
]
name: triton_poi_fused_add_mul_tanh_0
id: 11091
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3603
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214862
]
name: triton__0d1d2d3de
id: 11092
duration_micros: 43
attr: [name: "rf_id"
int64_val: 3603
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123214878
]
name: triton_poi_fused_add_mul_tanh_0
id: 11093
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3603
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214878
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11095
duration_micros: 56
attr: [name: "rf_id"
int64_val: 3604
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1930
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214955
]
name: aten::t
id: 11096
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3605
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214964
]
name: aten::transpose
id: 11097
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3606
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214967
]
name: aten::as_strided
id: 11098
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3607
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123214977
]
name: aten::matmul
id: 11099
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3608
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215006
]
name: aten::reshape
id: 11100
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3609
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215009
]
name: aten::view
id: 11101
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3610
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215013
]
name: aten::mm
id: 11102
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3611
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215028
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 11103
duration_micros: 567
attr: [name: "rf_id"
int64_val: 3611
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123215080
]
name: aten::mm
id: 11104
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3611
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215080
]
name: aten::_unsafe_view
id: 11106
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3612
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215097
]
name: _ReduceFromModelParallelRegion
id: 11107
duration_micros: 62
attr: [name: "rf_id"
int64_val: 3613
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1931
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215169
]
name: c10d::allreduce_
id: 11108
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3614
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215197
]
name: record_param_comms
id: 11109
duration_micros: 29
attr: [name: "rf_id"
int64_val: 3615
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215209
]
name: nccl:all_reduce
id: 11110
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3616
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215225
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 11111
duration_micros: 624
attr: [name: "rf_id"
int64_val: 3616
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123215242
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 11112
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3616
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215242
]
name: record_param_comms
id: 11114
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3617
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215314
]
name: aten::view_as
id: 11115
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3618
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215337
]
name: aten::view
id: 11116
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3619
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215341
]
name: aten::expand_as
id: 11117
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3620
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215381
]
name: aten::expand
id: 11118
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3621
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215385
]
name: aten::as_strided
id: 11119
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3622
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215392
]
name: TorchDynamo Cache Lookup
id: 11120
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3623
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215434
]
name: Torch-Compiled Region
id: 11121
duration_micros: 68
attr: [name: "rf_id"
int64_val: 3624
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215445
]
name: aten::empty
id: 11122
duration_micros: 20
attr: [name: "rf_id"
int64_val: 3625
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215483
]
name: triton_poi_fused_add_0
id: 11123
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3626
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215515
]
name: triton__0d1d2d3d4de
id: 11124
duration_micros: 113
attr: [name: "rf_id"
int64_val: 3626
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123215532
]
name: triton_poi_fused_add_0
id: 11125
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3626
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215532
]
name: FusedLayerNormAffineFunction
id: 11127
duration_micros: 54
attr: [name: "rf_id"
int64_val: 3627
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1932
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215637
]
name: aten::empty_like
id: 11128
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3628
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215649
]
name: aten::empty_strided
id: 11129
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3629
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215655
]
name: aten::empty
id: 11130
duration_micros: 45
attr: [name: "rf_id"
int64_val: 3630
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215688
]
name: aten::empty_like
id: 11131
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3631
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215739
]
name: aten::empty_strided
id: 11132
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3632
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215744
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 11133
duration_micros: 135
attr: [name: "rf_id"
int64_val: 3632
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123215784
]
name: aten::empty_strided
id: 11134
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3632
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215784
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11136
duration_micros: 29740
attr: [name: "rf_id"
int64_val: 3633
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1933
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215852
]
name: aten::t
id: 11137
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3634
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215862
]
name: aten::transpose
id: 11138
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3635
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215865
]
name: aten::as_strided
id: 11139
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3636
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215871
]
name: aten::matmul
id: 11140
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3637
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215899
]
name: aten::reshape
id: 11141
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3638
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215903
]
name: aten::view
id: 11142
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3639
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215910
]
name: aten::mm
id: 11143
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3640
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215926
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 11144
duration_micros: 400
attr: [name: "rf_id"
int64_val: 3640
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123215970
]
name: aten::mm
id: 11145
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3640
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215970
]
name: aten::_unsafe_view
id: 11147
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3641
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123215988
]
name: aten::add
id: 11148
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3642
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123245712
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 11149
duration_micros: 54
attr: [name: "rf_id"
int64_val: 3642
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123245752
]
name: aten::add
id: 11150
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3642
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123245752
]
name: aten::view
id: 11152
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3643
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123245795
]
name: aten::split_with_sizes
id: 11153
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3644
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123245822
]
name: aten::as_strided
id: 11154
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3645
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123245828
]
name: aten::as_strided
id: 11155
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3646
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123245828
]
name: aten::as_strided
id: 11156
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3647
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123245842
]
name: aten::view
id: 11157
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3648
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123245921
]
name: aten::reshape
id: 11158
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3649
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123245947
]
name: aten::_reshape_alias
id: 11159
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3650
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123245955
]
name: aten::view
id: 11160
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3651
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123245975
]
name: aten::slice
id: 11161
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3652
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123245997
]
name: aten::as_strided
id: 11162
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3653
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123246003
]
name: aten::view
id: 11163
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3654
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123246028
]
name: aten::transpose
id: 11164
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3655
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123246046
]
name: aten::as_strided
id: 11165
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3656
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123246051
]
name: aten::transpose
id: 11166
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3657
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123246069
]
name: aten::as_strided
id: 11167
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3658
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123246074
]
name: aten::transpose
id: 11168
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3659
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123246090
]
name: aten::as_strided
id: 11169
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3660
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123246094
]
name: aten::baddbmm
id: 11170
duration_micros: 1105
attr: [name: "rf_id"
int64_val: 3661
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123246148
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 11171
duration_micros: 294
attr: [name: "rf_id"
int64_val: 3661
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123248340
]
name: aten::baddbmm
id: 11172
duration_micros: 1105
attr: [name: "rf_id"
int64_val: 3661
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248340
]
name: aten::view
id: 11174
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3662
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248373
]
name: aten::view
id: 11175
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3663
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248373
]
name: ScaledUpperTriangMaskedSoftmax
id: 11176
duration_micros: 65
attr: [name: "rf_id"
int64_val: 3664
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1934
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248435
]
name: aten::empty
id: 11177
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3665
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248448
]
name: aten::to
id: 11178
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3666
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248466
]
name: aten::lift_fresh
id: 11179
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3667
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248477
]
name: aten::detach_
id: 11180
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3668
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248484
]
name: detach_
id: 11181
duration_micros: 3
attr: [name: "rf_id"
int64_val: 3669
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248486
]
name: aten::select
id: 11182
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3670
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248499
]
name: aten::as_strided
id: 11183
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3671
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248504
]
name: aten::item
id: 11184
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3672
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248524
]
name: aten::_local_scalar_dense
id: 11185
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3673
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248526
]
name: aten::empty
id: 11186
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3674
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248542
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 11187
duration_micros: 425
attr: [name: "rf_id"
int64_val: 3674
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123248575
]
name: aten::empty
id: 11188
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3674
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248575
]
name: aten::view
id: 11190
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3675
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248597
]
name: aten::dropout
id: 11191
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3676
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248662
]
name: aten::view
id: 11192
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3677
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248703
]
name: aten::view
id: 11193
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3678
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248703
]
name: aten::transpose
id: 11194
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3679
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248769
]
name: aten::as_strided
id: 11195
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3680
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248775
]
name: aten::bmm
id: 11196
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3681
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248798
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 11197
duration_micros: 186
attr: [name: "rf_id"
int64_val: 3681
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123248836
]
name: aten::bmm
id: 11198
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3681
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248836
]
name: aten::view
id: 11200
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3682
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248857
]
name: aten::permute
id: 11201
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3683
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248872
]
name: aten::as_strided
id: 11202
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3684
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248878
]
name: aten::contiguous
id: 11203
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3685
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248898
]
name: aten::clone
id: 11204
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3686
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248901
]
name: aten::empty_like
id: 11205
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3687
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248905
]
name: aten::empty
id: 11206
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3688
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248909
]
name: aten::copy_
id: 11207
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3689
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248934
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 11208
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3689
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123248951
]
name: aten::copy_
id: 11209
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3689
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248951
]
name: aten::view
id: 11211
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3690
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123248991
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11212
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3691
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1935
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249044
]
name: aten::t
id: 11213
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3692
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249053
]
name: aten::transpose
id: 11214
duration_micros: 45
attr: [name: "rf_id"
int64_val: 3693
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249056
]
name: aten::as_strided
id: 11215
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3694
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249065
]
name: aten::matmul
id: 11216
duration_micros: 20
attr: [name: "rf_id"
int64_val: 3695
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249126
]
name: aten::reshape
id: 11217
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3696
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249131
]
name: aten::view
id: 11218
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3697
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249135
]
name: aten::mm
id: 11219
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3698
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249151
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 11220
duration_micros: 161
attr: [name: "rf_id"
int64_val: 3698
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123249195
]
name: aten::mm
id: 11221
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3698
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249195
]
name: aten::_unsafe_view
id: 11223
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3699
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249212
]
name: _ReduceFromModelParallelRegion
id: 11224
duration_micros: 73
attr: [name: "rf_id"
int64_val: 3700
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1936
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249248
]
name: c10d::allreduce_
id: 11225
duration_micros: 29
attr: [name: "rf_id"
int64_val: 3701
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249286
]
name: record_param_comms
id: 11226
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3702
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249299
]
name: nccl:all_reduce
id: 11227
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3703
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249314
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 11228
duration_micros: 645
attr: [name: "rf_id"
int64_val: 3703
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123249332
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 11229
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3703
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249332
]
name: record_param_comms
id: 11231
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3704
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249404
]
name: aten::view_as
id: 11232
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3705
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249427
]
name: aten::view
id: 11233
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3706
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249431
]
name: aten::expand_as
id: 11234
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3707
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249475
]
name: aten::expand
id: 11235
duration_micros: 45
attr: [name: "rf_id"
int64_val: 3708
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249479
]
name: aten::as_strided
id: 11236
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3709
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249486
]
name: TorchDynamo Cache Lookup
id: 11237
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3710
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249570
]
name: Torch-Compiled Region
id: 11238
duration_micros: 87
attr: [name: "rf_id"
int64_val: 3711
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249583
]
name: aten::empty
id: 11239
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3712
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249628
]
name: triton_poi_fused_add_0
id: 11240
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3713
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249660
]
name: triton__0d1d2d3d4de
id: 11241
duration_micros: 113
attr: [name: "rf_id"
int64_val: 3713
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123249679
]
name: triton_poi_fused_add_0
id: 11242
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3713
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249679
]
name: FusedLayerNormAffineFunction
id: 11244
duration_micros: 52
attr: [name: "rf_id"
int64_val: 3714
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1937
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249767
]
name: aten::empty_like
id: 11245
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3715
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249780
]
name: aten::empty_strided
id: 11246
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3716
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249786
]
name: aten::empty
id: 11247
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3717
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249817
]
name: aten::empty_like
id: 11248
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3718
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249833
]
name: aten::empty_strided
id: 11249
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3719
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249836
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 11250
duration_micros: 137
attr: [name: "rf_id"
int64_val: 3719
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123249868
]
name: aten::empty_strided
id: 11251
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3719
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249868
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11253
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3720
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1938
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249932
]
name: aten::t
id: 11254
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3721
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249941
]
name: aten::transpose
id: 11255
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3722
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249944
]
name: aten::as_strided
id: 11256
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3723
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249951
]
name: aten::matmul
id: 11257
duration_micros: 22
attr: [name: "rf_id"
int64_val: 3724
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249979
]
name: aten::reshape
id: 11258
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3725
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249983
]
name: aten::view
id: 11259
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3726
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123249986
]
name: aten::mm
id: 11260
duration_micros: 33
attr: [name: "rf_id"
int64_val: 3727
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250036
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 11261
duration_micros: 522
attr: [name: "rf_id"
int64_val: 3727
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123250089
]
name: aten::mm
id: 11262
duration_micros: 33
attr: [name: "rf_id"
int64_val: 3727
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250089
]
name: aten::_unsafe_view
id: 11264
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3728
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250110
]
name: GeLUFunction
id: 11265
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3729
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1939
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250157
]
name: TorchDynamo Cache Lookup
id: 11266
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3730
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250178
]
name: Torch-Compiled Region
id: 11267
duration_micros: 69
attr: [name: "rf_id"
int64_val: 3731
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250188
]
name: aten::empty
id: 11268
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3732
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250226
]
name: triton_poi_fused_add_mul_tanh_0
id: 11269
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3733
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250257
]
name: triton__0d1d2d3de
id: 11270
duration_micros: 43
attr: [name: "rf_id"
int64_val: 3733
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123250273
]
name: triton_poi_fused_add_mul_tanh_0
id: 11271
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3733
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250273
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11273
duration_micros: 55
attr: [name: "rf_id"
int64_val: 3734
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1940
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250351
]
name: aten::t
id: 11274
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3735
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250360
]
name: aten::transpose
id: 11275
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3736
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250363
]
name: aten::as_strided
id: 11276
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3737
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250369
]
name: aten::matmul
id: 11277
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3738
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250398
]
name: aten::reshape
id: 11278
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3739
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250401
]
name: aten::view
id: 11279
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3740
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250405
]
name: aten::mm
id: 11280
duration_micros: 29
attr: [name: "rf_id"
int64_val: 3741
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250420
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 11281
duration_micros: 566
attr: [name: "rf_id"
int64_val: 3741
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123250468
]
name: aten::mm
id: 11282
duration_micros: 29
attr: [name: "rf_id"
int64_val: 3741
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250468
]
name: aten::_unsafe_view
id: 11284
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3742
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250486
]
name: _ReduceFromModelParallelRegion
id: 11285
duration_micros: 70
attr: [name: "rf_id"
int64_val: 3743
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1941
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250556
]
name: c10d::allreduce_
id: 11286
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3744
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250591
]
name: record_param_comms
id: 11287
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3745
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250603
]
name: nccl:all_reduce
id: 11288
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3746
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250620
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 11289
duration_micros: 617
attr: [name: "rf_id"
int64_val: 3746
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123250637
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 11290
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3746
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250637
]
name: record_param_comms
id: 11292
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3747
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250714
]
name: aten::view_as
id: 11293
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3748
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250737
]
name: aten::view
id: 11294
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3749
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250741
]
name: aten::expand_as
id: 11295
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3750
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250781
]
name: aten::expand
id: 11296
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3751
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250785
]
name: aten::as_strided
id: 11297
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3752
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250791
]
name: TorchDynamo Cache Lookup
id: 11298
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3753
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250833
]
name: Torch-Compiled Region
id: 11299
duration_micros: 66
attr: [name: "rf_id"
int64_val: 3754
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250845
]
name: aten::empty
id: 11300
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3755
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250882
]
name: triton_poi_fused_add_0
id: 11301
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3756
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250913
]
name: triton__0d1d2d3d4de
id: 11302
duration_micros: 114
attr: [name: "rf_id"
int64_val: 3756
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123250928
]
name: triton_poi_fused_add_0
id: 11303
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3756
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123250928
]
name: FusedLayerNormAffineFunction
id: 11305
duration_micros: 56
attr: [name: "rf_id"
int64_val: 3757
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1942
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251035
]
name: aten::empty_like
id: 11306
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3758
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251047
]
name: aten::empty_strided
id: 11307
duration_micros: 22
attr: [name: "rf_id"
int64_val: 3759
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251053
]
name: aten::empty
id: 11308
duration_micros: 45
attr: [name: "rf_id"
int64_val: 3760
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251087
]
name: aten::empty_like
id: 11309
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3761
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251139
]
name: aten::empty_strided
id: 11310
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3762
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251144
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 11311
duration_micros: 134
attr: [name: "rf_id"
int64_val: 3762
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123251183
]
name: aten::empty_strided
id: 11312
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3762
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251183
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11314
duration_micros: 35
attr: [name: "rf_id"
int64_val: 3763
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1943
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251251
]
name: aten::t
id: 11315
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3764
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251260
]
name: aten::transpose
id: 11316
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3765
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251264
]
name: aten::as_strided
id: 11317
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3766
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251274
]
name: aten::matmul
id: 11318
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3767
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251303
]
name: aten::reshape
id: 11319
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3768
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251307
]
name: aten::view
id: 11320
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3769
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251310
]
name: aten::mm
id: 11321
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3770
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251325
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 11322
duration_micros: 401
attr: [name: "rf_id"
int64_val: 3770
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123251370
]
name: aten::mm
id: 11323
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3770
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251370
]
name: aten::_unsafe_view
id: 11325
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3771
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251388
]
name: aten::add
id: 11326
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3772
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251410
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 11327
duration_micros: 54
attr: [name: "rf_id"
int64_val: 3772
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123251432
]
name: aten::add
id: 11328
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3772
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251432
]
name: aten::view
id: 11330
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3773
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251470
]
name: aten::split_with_sizes
id: 11331
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3774
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251494
]
name: aten::as_strided
id: 11332
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3775
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251501
]
name: aten::as_strided
id: 11333
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3776
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251501
]
name: aten::as_strided
id: 11334
duration_micros: 39
attr: [name: "rf_id"
int64_val: 3777
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251515
]
name: aten::view
id: 11335
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3778
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251593
]
name: aten::reshape
id: 11336
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3779
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251619
]
name: aten::_reshape_alias
id: 11337
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3780
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251626
]
name: aten::view
id: 11338
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3781
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251649
]
name: aten::slice
id: 11339
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3782
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251671
]
name: aten::as_strided
id: 11340
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3783
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251680
]
name: aten::view
id: 11341
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3784
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251706
]
name: aten::transpose
id: 11342
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3785
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251719
]
name: aten::as_strided
id: 11343
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3786
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251725
]
name: aten::transpose
id: 11344
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3787
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251742
]
name: aten::as_strided
id: 11345
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3788
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251747
]
name: aten::transpose
id: 11346
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3789
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251763
]
name: aten::as_strided
id: 11347
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3790
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251767
]
name: aten::baddbmm
id: 11348
duration_micros: 37
attr: [name: "rf_id"
int64_val: 3791
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251821
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 11349
duration_micros: 295
attr: [name: "rf_id"
int64_val: 3791
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123251879
]
name: aten::baddbmm
id: 11350
duration_micros: 37
attr: [name: "rf_id"
int64_val: 3791
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251879
]
name: aten::view
id: 11352
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3792
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251908
]
name: aten::view
id: 11353
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3793
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251908
]
name: ScaledUpperTriangMaskedSoftmax
id: 11354
duration_micros: 66
attr: [name: "rf_id"
int64_val: 3794
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1944
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251962
]
name: aten::empty
id: 11355
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3795
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251975
]
name: aten::to
id: 11356
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3796
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123251992
]
name: aten::lift_fresh
id: 11357
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3797
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252006
]
name: aten::detach_
id: 11358
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3798
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252013
]
name: detach_
id: 11359
duration_micros: 2
attr: [name: "rf_id"
int64_val: 3799
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252015
]
name: aten::select
id: 11360
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3800
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252027
]
name: aten::as_strided
id: 11361
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3801
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252033
]
name: aten::item
id: 11362
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3802
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252052
]
name: aten::_local_scalar_dense
id: 11363
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3803
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252054
]
name: aten::empty
id: 11364
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3804
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252070
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 11365
duration_micros: 426
attr: [name: "rf_id"
int64_val: 3804
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123252104
]
name: aten::empty
id: 11366
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3804
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252104
]
name: aten::view
id: 11368
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3805
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252126
]
name: aten::dropout
id: 11369
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3806
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252188
]
name: aten::view
id: 11370
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3807
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252232
]
name: aten::view
id: 11371
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3808
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252232
]
name: aten::transpose
id: 11372
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3809
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252297
]
name: aten::as_strided
id: 11373
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3810
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252303
]
name: aten::bmm
id: 11374
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3811
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252322
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 11375
duration_micros: 185
attr: [name: "rf_id"
int64_val: 3811
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123252365
]
name: aten::bmm
id: 11376
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3811
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252365
]
name: aten::view
id: 11378
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3812
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252386
]
name: aten::permute
id: 11379
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3813
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252401
]
name: aten::as_strided
id: 11380
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3814
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252407
]
name: aten::contiguous
id: 11381
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3815
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252427
]
name: aten::clone
id: 11382
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3816
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252429
]
name: aten::empty_like
id: 11383
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3817
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252433
]
name: aten::empty
id: 11384
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3818
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252437
]
name: aten::copy_
id: 11385
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3819
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252463
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 11386
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3819
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123252480
]
name: aten::copy_
id: 11387
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3819
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252480
]
name: aten::view
id: 11389
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3820
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252523
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11390
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3821
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1945
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252574
]
name: aten::t
id: 11391
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3822
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252582
]
name: aten::transpose
id: 11392
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3823
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252585
]
name: aten::as_strided
id: 11393
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3824
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252591
]
name: aten::matmul
id: 11394
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3825
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252650
]
name: aten::reshape
id: 11395
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3826
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252655
]
name: aten::view
id: 11396
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3827
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252658
]
name: aten::mm
id: 11397
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3828
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252674
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 11398
duration_micros: 160
attr: [name: "rf_id"
int64_val: 3828
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123252717
]
name: aten::mm
id: 11399
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3828
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252717
]
name: aten::_unsafe_view
id: 11401
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3829
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252734
]
name: _ReduceFromModelParallelRegion
id: 11402
duration_micros: 60
attr: [name: "rf_id"
int64_val: 3830
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1946
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252770
]
name: c10d::allreduce_
id: 11403
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3831
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252797
]
name: record_param_comms
id: 11404
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3832
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252808
]
name: nccl:all_reduce
id: 11405
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3833
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252823
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 11406
duration_micros: 9107
attr: [name: "rf_id"
int64_val: 3833
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123252840
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 11407
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3833
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252840
]
name: record_param_comms
id: 11409
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3834
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252912
]
name: aten::view_as
id: 11410
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3835
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252934
]
name: aten::view
id: 11411
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3836
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252938
]
name: aten::expand_as
id: 11412
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3837
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252981
]
name: aten::expand
id: 11413
duration_micros: 45
attr: [name: "rf_id"
int64_val: 3838
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252985
]
name: aten::as_strided
id: 11414
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3839
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123252992
]
name: TorchDynamo Cache Lookup
id: 11415
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3840
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253069
]
name: Torch-Compiled Region
id: 11416
duration_micros: 71
attr: [name: "rf_id"
int64_val: 3841
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253081
]
name: aten::empty
id: 11417
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3842
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253121
]
name: triton_poi_fused_add_0
id: 11418
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3843
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253152
]
name: triton__0d1d2d3d4de
id: 11419
duration_micros: 114
attr: [name: "rf_id"
int64_val: 3843
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123253168
]
name: triton_poi_fused_add_0
id: 11420
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3843
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253168
]
name: FusedLayerNormAffineFunction
id: 11422
duration_micros: 48
attr: [name: "rf_id"
int64_val: 3844
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1947
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253243
]
name: aten::empty_like
id: 11423
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3845
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253255
]
name: aten::empty_strided
id: 11424
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3846
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253261
]
name: aten::empty
id: 11425
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3847
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253291
]
name: aten::empty_like
id: 11426
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3848
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253306
]
name: aten::empty_strided
id: 11427
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3849
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253310
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 11428
duration_micros: 136
attr: [name: "rf_id"
int64_val: 3849
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123253341
]
name: aten::empty_strided
id: 11429
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3849
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253341
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11431
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3850
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1948
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253403
]
name: aten::t
id: 11432
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3851
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253412
]
name: aten::transpose
id: 11433
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3852
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253415
]
name: aten::as_strided
id: 11434
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3853
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253425
]
name: aten::matmul
id: 11435
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3854
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253453
]
name: aten::reshape
id: 11436
duration_micros: 37
attr: [name: "rf_id"
int64_val: 3855
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253457
]
name: aten::view
id: 11437
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3856
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253460
]
name: aten::mm
id: 11438
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3857
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253507
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 11439
duration_micros: 522
attr: [name: "rf_id"
int64_val: 3857
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123253554
]
name: aten::mm
id: 11440
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3857
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253554
]
name: aten::_unsafe_view
id: 11442
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3858
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253574
]
name: GeLUFunction
id: 11443
duration_micros: 31
attr: [name: "rf_id"
int64_val: 3859
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1949
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253619
]
name: TorchDynamo Cache Lookup
id: 11444
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3860
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253639
]
name: Torch-Compiled Region
id: 11445
duration_micros: 68
attr: [name: "rf_id"
int64_val: 3861
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253649
]
name: aten::empty
id: 11446
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3862
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253686
]
name: triton_poi_fused_add_mul_tanh_0
id: 11447
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3863
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253725
]
name: triton__0d1d2d3de
id: 11448
duration_micros: 43
attr: [name: "rf_id"
int64_val: 3863
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123253740
]
name: triton_poi_fused_add_mul_tanh_0
id: 11449
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3863
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253740
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11451
duration_micros: 53
attr: [name: "rf_id"
int64_val: 3864
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1950
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253817
]
name: aten::t
id: 11452
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3865
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253826
]
name: aten::transpose
id: 11453
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3866
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253829
]
name: aten::as_strided
id: 11454
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3867
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253836
]
name: aten::matmul
id: 11455
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3868
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253864
]
name: aten::reshape
id: 11456
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3869
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253868
]
name: aten::view
id: 11457
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3870
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253871
]
name: aten::mm
id: 11458
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3871
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253887
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 11459
duration_micros: 567
attr: [name: "rf_id"
int64_val: 3871
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123253936
]
name: aten::mm
id: 11460
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3871
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253936
]
name: aten::_unsafe_view
id: 11462
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3872
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123253957
]
name: _ReduceFromModelParallelRegion
id: 11463
duration_micros: 61
attr: [name: "rf_id"
int64_val: 3873
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1951
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254026
]
name: c10d::allreduce_
id: 11464
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3874
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254053
]
name: record_param_comms
id: 11465
duration_micros: 26
attr: [name: "rf_id"
int64_val: 3875
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254065
]
name: nccl:all_reduce
id: 11466
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3876
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254081
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 11467
duration_micros: 604
attr: [name: "rf_id"
int64_val: 3876
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123254098
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 11468
duration_micros: 25
attr: [name: "rf_id"
int64_val: 3876
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254098
]
name: record_param_comms
id: 11470
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3877
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254170
]
name: aten::view_as
id: 11471
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3878
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254193
]
name: aten::view
id: 11472
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3879
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254198
]
name: aten::expand_as
id: 11473
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3880
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254237
]
name: aten::expand
id: 11474
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3881
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254241
]
name: aten::as_strided
id: 11475
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3882
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254248
]
name: TorchDynamo Cache Lookup
id: 11476
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3883
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254290
]
name: Torch-Compiled Region
id: 11477
duration_micros: 66
attr: [name: "rf_id"
int64_val: 3884
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254302
]
name: aten::empty
id: 11478
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3885
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254339
]
name: triton_poi_fused_add_0
id: 11479
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3886
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254368
]
name: triton__0d1d2d3d4de
id: 11480
duration_micros: 113
attr: [name: "rf_id"
int64_val: 3886
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123254384
]
name: triton_poi_fused_add_0
id: 11481
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3886
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254384
]
name: FusedLayerNormAffineFunction
id: 11483
duration_micros: 54
attr: [name: "rf_id"
int64_val: 3887
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1952
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254489
]
name: aten::empty_like
id: 11484
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3888
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254501
]
name: aten::empty_strided
id: 11485
duration_micros: 22
attr: [name: "rf_id"
int64_val: 3889
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254507
]
name: aten::empty
id: 11486
duration_micros: 46
attr: [name: "rf_id"
int64_val: 3890
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254541
]
name: aten::empty_like
id: 11487
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3891
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254593
]
name: aten::empty_strided
id: 11488
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3892
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254598
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 11489
duration_micros: 136
attr: [name: "rf_id"
int64_val: 3892
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123254637
]
name: aten::empty_strided
id: 11490
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3892
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254637
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11492
duration_micros: 36
attr: [name: "rf_id"
int64_val: 3893
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1953
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254709
]
name: aten::t
id: 11493
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3894
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254719
]
name: aten::transpose
id: 11494
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3895
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254722
]
name: aten::as_strided
id: 11495
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3896
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254728
]
name: aten::matmul
id: 11496
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3897
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254757
]
name: aten::reshape
id: 11497
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3898
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254761
]
name: aten::view
id: 11498
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3899
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254764
]
name: aten::mm
id: 11499
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3900
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254779
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 11500
duration_micros: 400
attr: [name: "rf_id"
int64_val: 3900
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123254824
]
name: aten::mm
id: 11501
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3900
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254824
]
name: aten::_unsafe_view
id: 11503
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3901
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254842
]
name: aten::add
id: 11504
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3902
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254863
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 11505
duration_micros: 54
attr: [name: "rf_id"
int64_val: 3902
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123254886
]
name: aten::add
id: 11506
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3902
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254886
]
name: aten::view
id: 11508
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3903
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254923
]
name: aten::split_with_sizes
id: 11509
duration_micros: 32
attr: [name: "rf_id"
int64_val: 3904
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254948
]
name: aten::as_strided
id: 11510
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3905
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254955
]
name: aten::as_strided
id: 11511
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3906
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254955
]
name: aten::as_strided
id: 11512
duration_micros: 37
attr: [name: "rf_id"
int64_val: 3907
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123254969
]
name: aten::view
id: 11513
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3908
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255048
]
name: aten::reshape
id: 11514
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3909
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255074
]
name: aten::_reshape_alias
id: 11515
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3910
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255081
]
name: aten::view
id: 11516
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3911
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255101
]
name: aten::slice
id: 11517
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3912
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255121
]
name: aten::as_strided
id: 11518
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3913
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255127
]
name: aten::view
id: 11519
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3914
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255151
]
name: aten::transpose
id: 11520
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3915
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255164
]
name: aten::as_strided
id: 11521
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3916
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255169
]
name: aten::transpose
id: 11522
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3917
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255187
]
name: aten::as_strided
id: 11523
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3918
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255191
]
name: aten::transpose
id: 11524
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3919
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255210
]
name: aten::as_strided
id: 11525
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3920
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255214
]
name: aten::baddbmm
id: 11526
duration_micros: 33
attr: [name: "rf_id"
int64_val: 3921
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255268
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 11527
duration_micros: 294
attr: [name: "rf_id"
int64_val: 3921
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123255321
]
name: aten::baddbmm
id: 11528
duration_micros: 33
attr: [name: "rf_id"
int64_val: 3921
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255321
]
name: aten::view
id: 11530
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3922
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255348
]
name: aten::view
id: 11531
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3923
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255348
]
name: ScaledUpperTriangMaskedSoftmax
id: 11532
duration_micros: 62
attr: [name: "rf_id"
int64_val: 3924
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1954
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255401
]
name: aten::empty
id: 11533
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3925
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255414
]
name: aten::to
id: 11534
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3926
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255430
]
name: aten::lift_fresh
id: 11535
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3927
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255441
]
name: aten::detach_
id: 11536
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3928
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255448
]
name: detach_
id: 11537
duration_micros: 2
attr: [name: "rf_id"
int64_val: 3929
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255450
]
name: aten::select
id: 11538
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3930
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255462
]
name: aten::as_strided
id: 11539
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3931
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255467
]
name: aten::item
id: 11540
duration_micros: 6
attr: [name: "rf_id"
int64_val: 3932
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255486
]
name: aten::_local_scalar_dense
id: 11541
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3933
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255488
]
name: aten::empty
id: 11542
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3934
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255504
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 11543
duration_micros: 426
attr: [name: "rf_id"
int64_val: 3934
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123255541
]
name: aten::empty
id: 11544
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3934
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255541
]
name: aten::view
id: 11546
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3935
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255564
]
name: aten::dropout
id: 11547
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3936
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255625
]
name: aten::view
id: 11548
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3937
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255665
]
name: aten::view
id: 11549
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3938
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255665
]
name: aten::transpose
id: 11550
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3939
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255730
]
name: aten::as_strided
id: 11551
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3940
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255736
]
name: aten::bmm
id: 11552
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3941
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255755
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 11553
duration_micros: 185
attr: [name: "rf_id"
int64_val: 3941
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123255792
]
name: aten::bmm
id: 11554
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3941
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255792
]
name: aten::view
id: 11556
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3942
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255813
]
name: aten::permute
id: 11557
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3943
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255828
]
name: aten::as_strided
id: 11558
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3944
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255834
]
name: aten::contiguous
id: 11559
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3945
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255857
]
name: aten::clone
id: 11560
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3946
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255860
]
name: aten::empty_like
id: 11561
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3947
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255864
]
name: aten::empty
id: 11562
duration_micros: 16
attr: [name: "rf_id"
int64_val: 3948
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255868
]
name: aten::copy_
id: 11563
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3949
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255895
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 11564
duration_micros: 21
attr: [name: "rf_id"
int64_val: 3949
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123255912
]
name: aten::copy_
id: 11565
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3949
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255912
]
name: aten::view
id: 11567
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3950
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123255951
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11568
duration_micros: 24
attr: [name: "rf_id"
int64_val: 3951
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1955
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256002
]
name: aten::t
id: 11569
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3952
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256010
]
name: aten::transpose
id: 11570
duration_micros: 41
attr: [name: "rf_id"
int64_val: 3953
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256013
]
name: aten::as_strided
id: 11571
duration_micros: 9
attr: [name: "rf_id"
int64_val: 3954
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256019
]
name: aten::matmul
id: 11572
duration_micros: 20
attr: [name: "rf_id"
int64_val: 3955
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256078
]
name: aten::reshape
id: 11573
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3956
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256083
]
name: aten::view
id: 11574
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3957
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256086
]
name: aten::mm
id: 11575
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3958
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256102
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 11576
duration_micros: 158
attr: [name: "rf_id"
int64_val: 3958
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123256147
]
name: aten::mm
id: 11577
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3958
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256147
]
name: aten::_unsafe_view
id: 11579
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3959
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256165
]
name: _ReduceFromModelParallelRegion
id: 11580
duration_micros: 81
attr: [name: "rf_id"
int64_val: 3960
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1956
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256205
]
name: c10d::allreduce_
id: 11581
duration_micros: 28
attr: [name: "rf_id"
int64_val: 3961
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256232
]
name: record_param_comms
id: 11582
duration_micros: 22318
attr: [name: "rf_id"
int64_val: 3962
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123256244
]
name: nccl:all_reduce
id: 11583
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3963
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278553
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 11584
duration_micros: 648
attr: [name: "rf_id"
int64_val: 3963
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123278572
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 11585
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3963
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278572
]
name: record_param_comms
id: 11587
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3964
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278644
]
name: aten::view_as
id: 11588
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3965
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278686
]
name: aten::view
id: 11589
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3966
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278690
]
name: aten::expand_as
id: 11590
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3967
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278740
]
name: aten::expand
id: 11591
duration_micros: 46
attr: [name: "rf_id"
int64_val: 3968
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278744
]
name: aten::as_strided
id: 11592
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3969
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278751
]
name: TorchDynamo Cache Lookup
id: 11593
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3970
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278834
]
name: Torch-Compiled Region
id: 11594
duration_micros: 75
attr: [name: "rf_id"
int64_val: 3971
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278847
]
name: aten::empty
id: 11595
duration_micros: 27
attr: [name: "rf_id"
int64_val: 3972
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278890
]
name: triton_poi_fused_add_0
id: 11596
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3973
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278931
]
name: triton__0d1d2d3d4de
id: 11597
duration_micros: 113
attr: [name: "rf_id"
int64_val: 3973
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123278949
]
name: triton_poi_fused_add_0
id: 11598
duration_micros: 17
attr: [name: "rf_id"
int64_val: 3973
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123278949
]
name: FusedLayerNormAffineFunction
id: 11600
duration_micros: 50
attr: [name: "rf_id"
int64_val: 3974
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1957
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279027
]
name: aten::empty_like
id: 11601
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3975
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279039
]
name: aten::empty_strided
id: 11602
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3976
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279045
]
name: aten::empty
id: 11603
duration_micros: 12
attr: [name: "rf_id"
int64_val: 3977
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279076
]
name: aten::empty_like
id: 11604
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3978
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279092
]
name: aten::empty_strided
id: 11605
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3979
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279096
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 11606
duration_micros: 135
attr: [name: "rf_id"
int64_val: 3979
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123279127
]
name: aten::empty_strided
id: 11607
duration_micros: 5
attr: [name: "rf_id"
int64_val: 3979
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279127
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11609
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3980
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1958
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279191
]
name: aten::t
id: 11610
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3981
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279209
]
name: aten::transpose
id: 11611
duration_micros: 14
attr: [name: "rf_id"
int64_val: 3982
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279213
]
name: aten::as_strided
id: 11612
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3983
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279221
]
name: aten::matmul
id: 11613
duration_micros: 23
attr: [name: "rf_id"
int64_val: 3984
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279249
]
name: aten::reshape
id: 11614
duration_micros: 40
attr: [name: "rf_id"
int64_val: 3985
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279254
]
name: aten::view
id: 11615
duration_micros: 7
attr: [name: "rf_id"
int64_val: 3986
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279257
]
name: aten::mm
id: 11616
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3987
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279306
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 11617
duration_micros: 522
attr: [name: "rf_id"
int64_val: 3987
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123279355
]
name: aten::mm
id: 11618
duration_micros: 30
attr: [name: "rf_id"
int64_val: 3987
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279355
]
name: aten::_unsafe_view
id: 11620
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3988
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279374
]
name: GeLUFunction
id: 11621
duration_micros: 34
attr: [name: "rf_id"
int64_val: 3989
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1959
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279420
]
name: TorchDynamo Cache Lookup
id: 11622
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3990
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279442
]
name: Torch-Compiled Region
id: 11623
duration_micros: 67
attr: [name: "rf_id"
int64_val: 3991
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279452
]
name: aten::empty
id: 11624
duration_micros: 19
attr: [name: "rf_id"
int64_val: 3992
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279490
]
name: triton_poi_fused_add_mul_tanh_0
id: 11625
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3993
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279521
]
name: triton__0d1d2d3de
id: 11626
duration_micros: 43
attr: [name: "rf_id"
int64_val: 3993
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123279536
]
name: triton_poi_fused_add_mul_tanh_0
id: 11627
duration_micros: 15
attr: [name: "rf_id"
int64_val: 3993
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279536
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11629
duration_micros: 53
attr: [name: "rf_id"
int64_val: 3994
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1960
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279615
]
name: aten::t
id: 11630
duration_micros: 10
attr: [name: "rf_id"
int64_val: 3995
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279623
]
name: aten::transpose
id: 11631
duration_micros: 13
attr: [name: "rf_id"
int64_val: 3996
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279627
]
name: aten::as_strided
id: 11632
duration_micros: 11
attr: [name: "rf_id"
int64_val: 3997
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279633
]
name: aten::matmul
id: 11633
duration_micros: 18
attr: [name: "rf_id"
int64_val: 3998
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279662
]
name: aten::reshape
id: 11634
duration_micros: 8
attr: [name: "rf_id"
int64_val: 3999
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279666
]
name: aten::view
id: 11635
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4000
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279669
]
name: aten::mm
id: 11636
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4001
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279688
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 11637
duration_micros: 566
attr: [name: "rf_id"
int64_val: 4001
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123279737
]
name: aten::mm
id: 11638
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4001
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279737
]
name: aten::_unsafe_view
id: 11640
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4002
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279754
]
name: _ReduceFromModelParallelRegion
id: 11641
duration_micros: 66
attr: [name: "rf_id"
int64_val: 4003
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1961
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279824
]
name: c10d::allreduce_
id: 11642
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4004
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279855
]
name: record_param_comms
id: 11643
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4005
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279866
]
name: nccl:all_reduce
id: 11644
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4006
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279883
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 11645
duration_micros: 15238
attr: [name: "rf_id"
int64_val: 4006
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123279900
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 11646
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4006
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279900
]
name: record_param_comms
id: 11648
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4007
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279973
]
name: aten::view_as
id: 11649
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4008
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123279996
]
name: aten::view
id: 11650
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4009
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280000
]
name: aten::expand_as
id: 11651
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4010
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280040
]
name: aten::expand
id: 11652
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4011
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280044
]
name: aten::as_strided
id: 11653
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4012
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280050
]
name: TorchDynamo Cache Lookup
id: 11654
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4013
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280093
]
name: Torch-Compiled Region
id: 11655
duration_micros: 67
attr: [name: "rf_id"
int64_val: 4014
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280104
]
name: aten::empty
id: 11656
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4015
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280141
]
name: triton_poi_fused_add_0
id: 11657
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4016
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280172
]
name: triton__0d1d2d3d4de
id: 11658
duration_micros: 113
attr: [name: "rf_id"
int64_val: 4016
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123280188
]
name: triton_poi_fused_add_0
id: 11659
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4016
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280188
]
name: FusedLayerNormAffineFunction
id: 11661
duration_micros: 55
attr: [name: "rf_id"
int64_val: 4017
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1962
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280295
]
name: aten::empty_like
id: 11662
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4018
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280308
]
name: aten::empty_strided
id: 11663
duration_micros: 21
attr: [name: "rf_id"
int64_val: 4019
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280314
]
name: aten::empty
id: 11664
duration_micros: 44
attr: [name: "rf_id"
int64_val: 4020
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280348
]
name: aten::empty_like
id: 11665
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4021
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280398
]
name: aten::empty_strided
id: 11666
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4022
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280403
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 11667
duration_micros: 138
attr: [name: "rf_id"
int64_val: 4022
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123280443
]
name: aten::empty_strided
id: 11668
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4022
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280443
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11670
duration_micros: 35
attr: [name: "rf_id"
int64_val: 4023
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1963
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280511
]
name: aten::t
id: 11671
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4024
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280520
]
name: aten::transpose
id: 11672
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4025
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280523
]
name: aten::as_strided
id: 11673
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4026
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280529
]
name: aten::matmul
id: 11674
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4027
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280558
]
name: aten::reshape
id: 11675
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4028
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280562
]
name: aten::view
id: 11676
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4029
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280565
]
name: aten::mm
id: 11677
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4030
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280581
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 11678
duration_micros: 400
attr: [name: "rf_id"
int64_val: 4030
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123280625
]
name: aten::mm
id: 11679
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4030
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280625
]
name: aten::_unsafe_view
id: 11681
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4031
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280644
]
name: aten::add
id: 11682
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4032
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280666
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 11683
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4032
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123280688
]
name: aten::add
id: 11684
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4032
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280688
]
name: aten::view
id: 11686
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4033
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280725
]
name: aten::split_with_sizes
id: 11687
duration_micros: 37
attr: [name: "rf_id"
int64_val: 4034
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280749
]
name: aten::as_strided
id: 11688
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4035
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280756
]
name: aten::as_strided
id: 11689
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4036
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280756
]
name: aten::as_strided
id: 11690
duration_micros: 36
attr: [name: "rf_id"
int64_val: 4037
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280774
]
name: aten::view
id: 11691
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4038
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280849
]
name: aten::reshape
id: 11692
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4039
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280875
]
name: aten::_reshape_alias
id: 11693
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4040
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280883
]
name: aten::view
id: 11694
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4041
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280902
]
name: aten::slice
id: 11695
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4042
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280925
]
name: aten::as_strided
id: 11696
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4043
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280930
]
name: aten::view
id: 11697
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4044
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280955
]
name: aten::transpose
id: 11698
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4045
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280968
]
name: aten::as_strided
id: 11699
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4046
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280974
]
name: aten::transpose
id: 11700
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4047
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280991
]
name: aten::as_strided
id: 11701
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4048
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123280998
]
name: aten::transpose
id: 11702
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4049
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281015
]
name: aten::as_strided
id: 11703
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4050
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281019
]
name: aten::baddbmm
id: 11704
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4051
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281073
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 11705
duration_micros: 290
attr: [name: "rf_id"
int64_val: 4051
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123281127
]
name: aten::baddbmm
id: 11706
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4051
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281127
]
name: aten::view
id: 11708
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4052
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281158
]
name: aten::view
id: 11709
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4053
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281158
]
name: ScaledUpperTriangMaskedSoftmax
id: 11710
duration_micros: 63
attr: [name: "rf_id"
int64_val: 4054
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1964
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281215
]
name: aten::empty
id: 11711
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4055
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281228
]
name: aten::to
id: 11712
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4056
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281245
]
name: aten::lift_fresh
id: 11713
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4057
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281255
]
name: aten::detach_
id: 11714
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4058
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281263
]
name: detach_
id: 11715
duration_micros: 3
attr: [name: "rf_id"
int64_val: 4059
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281264
]
name: aten::select
id: 11716
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4060
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281277
]
name: aten::as_strided
id: 11717
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4061
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281286
]
name: aten::item
id: 11718
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4062
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281305
]
name: aten::_local_scalar_dense
id: 11719
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4063
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281308
]
name: aten::empty
id: 11720
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4064
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281324
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 11721
duration_micros: 425
attr: [name: "rf_id"
int64_val: 4064
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123281358
]
name: aten::empty
id: 11722
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4064
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281358
]
name: aten::view
id: 11724
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4065
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281381
]
name: aten::dropout
id: 11725
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4066
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281444
]
name: aten::view
id: 11726
duration_micros: 40
attr: [name: "rf_id"
int64_val: 4067
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281485
]
name: aten::view
id: 11727
duration_micros: 40
attr: [name: "rf_id"
int64_val: 4068
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281485
]
name: aten::transpose
id: 11728
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4069
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281550
]
name: aten::as_strided
id: 11729
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4070
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281556
]
name: aten::bmm
id: 11730
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4071
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281575
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 11731
duration_micros: 185
attr: [name: "rf_id"
int64_val: 4071
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123281613
]
name: aten::bmm
id: 11732
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4071
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281613
]
name: aten::view
id: 11734
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4072
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281635
]
name: aten::permute
id: 11735
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4073
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281650
]
name: aten::as_strided
id: 11736
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4074
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281660
]
name: aten::contiguous
id: 11737
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4075
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281681
]
name: aten::clone
id: 11738
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4076
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281683
]
name: aten::empty_like
id: 11739
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4077
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281687
]
name: aten::empty
id: 11740
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4078
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281691
]
name: aten::copy_
id: 11741
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4079
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281727
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 11742
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4079
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123281744
]
name: aten::copy_
id: 11743
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4079
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281744
]
name: aten::view
id: 11745
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4080
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281783
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11746
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4081
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1965
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281834
]
name: aten::t
id: 11747
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4082
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281843
]
name: aten::transpose
id: 11748
duration_micros: 42
attr: [name: "rf_id"
int64_val: 4083
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281846
]
name: aten::as_strided
id: 11749
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4084
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281852
]
name: aten::matmul
id: 11750
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4085
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281913
]
name: aten::reshape
id: 11751
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4086
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281918
]
name: aten::view
id: 11752
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4087
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281921
]
name: aten::mm
id: 11753
duration_micros: 29
attr: [name: "rf_id"
int64_val: 4088
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281940
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 11754
duration_micros: 161
attr: [name: "rf_id"
int64_val: 4088
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123281986
]
name: aten::mm
id: 11755
duration_micros: 29
attr: [name: "rf_id"
int64_val: 4088
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123281986
]
name: aten::_unsafe_view
id: 11757
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4089
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282004
]
name: _ReduceFromModelParallelRegion
id: 11758
duration_micros: 81
attr: [name: "rf_id"
int64_val: 4090
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1966
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282041
]
name: c10d::allreduce_
id: 11759
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4091
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282069
]
name: record_param_comms
id: 11760
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4092
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282080
]
name: nccl:all_reduce
id: 11761
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4093
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282095
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 11762
duration_micros: 620
attr: [name: "rf_id"
int64_val: 4093
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123282112
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 11763
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4093
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282112
]
name: record_param_comms
id: 11765
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4094
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282185
]
name: aten::view_as
id: 11766
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4095
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282226
]
name: aten::view
id: 11767
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4096
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282231
]
name: aten::expand_as
id: 11768
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4097
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282275
]
name: aten::expand
id: 11769
duration_micros: 44
attr: [name: "rf_id"
int64_val: 4098
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282279
]
name: aten::as_strided
id: 11770
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4099
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282285
]
name: TorchDynamo Cache Lookup
id: 11771
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4100
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282364
]
name: Torch-Compiled Region
id: 11772
duration_micros: 70
attr: [name: "rf_id"
int64_val: 4101
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282376
]
name: aten::empty
id: 11773
duration_micros: 21
attr: [name: "rf_id"
int64_val: 4102
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282416
]
name: triton_poi_fused_add_0
id: 11774
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4103
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282449
]
name: triton__0d1d2d3d4de
id: 11775
duration_micros: 113
attr: [name: "rf_id"
int64_val: 4103
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123282466
]
name: triton_poi_fused_add_0
id: 11776
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4103
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282466
]
name: FusedLayerNormAffineFunction
id: 11778
duration_micros: 49
attr: [name: "rf_id"
int64_val: 4104
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1967
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282541
]
name: aten::empty_like
id: 11779
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4105
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282553
]
name: aten::empty_strided
id: 11780
duration_micros: 21
attr: [name: "rf_id"
int64_val: 4106
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282560
]
name: aten::empty
id: 11781
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4107
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282593
]
name: aten::empty_like
id: 11782
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4108
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282613
]
name: aten::empty_strided
id: 11783
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4109
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282617
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 11784
duration_micros: 136
attr: [name: "rf_id"
int64_val: 4109
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123282650
]
name: aten::empty_strided
id: 11785
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4109
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282650
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11787
duration_micros: 23
attr: [name: "rf_id"
int64_val: 4110
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1968
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282717
]
name: aten::t
id: 11788
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4111
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282725
]
name: aten::transpose
id: 11789
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4112
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282729
]
name: aten::as_strided
id: 11790
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4113
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282735
]
name: aten::matmul
id: 11791
duration_micros: 22
attr: [name: "rf_id"
int64_val: 4114
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282763
]
name: aten::reshape
id: 11792
duration_micros: 40
attr: [name: "rf_id"
int64_val: 4115
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282767
]
name: aten::view
id: 11793
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4116
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282770
]
name: aten::mm
id: 11794
duration_micros: 31
attr: [name: "rf_id"
int64_val: 4117
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282820
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 11795
duration_micros: 521
attr: [name: "rf_id"
int64_val: 4117
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123282870
]
name: aten::mm
id: 11796
duration_micros: 31
attr: [name: "rf_id"
int64_val: 4117
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282870
]
name: aten::_unsafe_view
id: 11798
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4118
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282889
]
name: GeLUFunction
id: 11799
duration_micros: 31
attr: [name: "rf_id"
int64_val: 4119
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1969
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282934
]
name: TorchDynamo Cache Lookup
id: 11800
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4120
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282954
]
name: Torch-Compiled Region
id: 11801
duration_micros: 67
attr: [name: "rf_id"
int64_val: 4121
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123282964
]
name: aten::empty
id: 11802
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4122
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283002
]
name: triton_poi_fused_add_mul_tanh_0
id: 11803
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4123
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283034
]
name: triton__0d1d2d3de
id: 11804
duration_micros: 43
attr: [name: "rf_id"
int64_val: 4123
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123283049
]
name: triton_poi_fused_add_mul_tanh_0
id: 11805
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4123
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283049
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11807
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4124
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1970
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283125
]
name: aten::t
id: 11808
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4125
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283134
]
name: aten::transpose
id: 11809
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4126
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283137
]
name: aten::as_strided
id: 11810
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4127
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283147
]
name: aten::matmul
id: 11811
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4128
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283176
]
name: aten::reshape
id: 11812
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4129
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283179
]
name: aten::view
id: 11813
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4130
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283183
]
name: aten::mm
id: 11814
duration_micros: 31
attr: [name: "rf_id"
int64_val: 4131
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283198
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 11815
duration_micros: 568
attr: [name: "rf_id"
int64_val: 4131
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123283250
]
name: aten::mm
id: 11816
duration_micros: 31
attr: [name: "rf_id"
int64_val: 4131
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283250
]
name: aten::_unsafe_view
id: 11818
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4132
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283267
]
name: _ReduceFromModelParallelRegion
id: 11819
duration_micros: 61
attr: [name: "rf_id"
int64_val: 4133
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1971
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283337
]
name: c10d::allreduce_
id: 11820
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4134
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283365
]
name: record_param_comms
id: 11821
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4135
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283376
]
name: nccl:all_reduce
id: 11822
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4136
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283393
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 11823
duration_micros: 606
attr: [name: "rf_id"
int64_val: 4136
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123283410
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 11824
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4136
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283410
]
name: record_param_comms
id: 11826
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4137
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283482
]
name: aten::view_as
id: 11827
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4138
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283505
]
name: aten::view
id: 11828
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4139
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283510
]
name: aten::expand_as
id: 11829
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4140
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283554
]
name: aten::expand
id: 11830
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4141
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283558
]
name: aten::as_strided
id: 11831
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4142
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283565
]
name: TorchDynamo Cache Lookup
id: 11832
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4143
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283608
]
name: Torch-Compiled Region
id: 11833
duration_micros: 67
attr: [name: "rf_id"
int64_val: 4144
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283620
]
name: aten::empty
id: 11834
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4145
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283658
]
name: triton_poi_fused_add_0
id: 11835
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4146
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283690
]
name: triton__0d1d2d3d4de
id: 11836
duration_micros: 113
attr: [name: "rf_id"
int64_val: 4146
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123283706
]
name: triton_poi_fused_add_0
id: 11837
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4146
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283706
]
name: FusedLayerNormAffineFunction
id: 11839
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4147
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1972
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283810
]
name: aten::empty_like
id: 11840
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4148
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283822
]
name: aten::empty_strided
id: 11841
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4149
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283829
]
name: aten::empty
id: 11842
duration_micros: 47
attr: [name: "rf_id"
int64_val: 4150
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283861
]
name: aten::empty_like
id: 11843
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4151
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283914
]
name: aten::empty_strided
id: 11844
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4152
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283918
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 11845
duration_micros: 138
attr: [name: "rf_id"
int64_val: 4152
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123283958
]
name: aten::empty_strided
id: 11846
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4152
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123283958
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11848
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4153
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1973
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284026
]
name: aten::t
id: 11849
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4154
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284035
]
name: aten::transpose
id: 11850
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4155
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284039
]
name: aten::as_strided
id: 11851
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4156
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284045
]
name: aten::matmul
id: 11852
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4157
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284073
]
name: aten::reshape
id: 11853
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4158
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284078
]
name: aten::view
id: 11854
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4159
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284081
]
name: aten::mm
id: 11855
duration_micros: 33
attr: [name: "rf_id"
int64_val: 4160
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284097
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 11856
duration_micros: 399
attr: [name: "rf_id"
int64_val: 4160
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123284151
]
name: aten::mm
id: 11857
duration_micros: 33
attr: [name: "rf_id"
int64_val: 4160
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284151
]
name: aten::_unsafe_view
id: 11859
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4161
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284169
]
name: aten::add
id: 11860
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4162
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284191
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 11861
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4162
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123284214
]
name: aten::add
id: 11862
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4162
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284214
]
name: aten::view
id: 11864
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4163
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284251
]
name: aten::split_with_sizes
id: 11865
duration_micros: 31
attr: [name: "rf_id"
int64_val: 4164
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284276
]
name: aten::as_strided
id: 11866
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4165
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284283
]
name: aten::as_strided
id: 11867
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4166
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284283
]
name: aten::as_strided
id: 11868
duration_micros: 37
attr: [name: "rf_id"
int64_val: 4167
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284297
]
name: aten::view
id: 11869
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4168
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284373
]
name: aten::reshape
id: 11870
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4169
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284399
]
name: aten::_reshape_alias
id: 11871
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4170
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284407
]
name: aten::view
id: 11872
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4171
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284426
]
name: aten::slice
id: 11873
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4172
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284447
]
name: aten::as_strided
id: 11874
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4173
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284453
]
name: aten::view
id: 11875
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4174
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284481
]
name: aten::transpose
id: 11876
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4175
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284494
]
name: aten::as_strided
id: 11877
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4176
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284500
]
name: aten::transpose
id: 11878
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4177
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284517
]
name: aten::as_strided
id: 11879
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4178
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284522
]
name: aten::transpose
id: 11880
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4179
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284542
]
name: aten::as_strided
id: 11881
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4180
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284546
]
name: aten::baddbmm
id: 11882
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4181
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284600
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 11883
duration_micros: 294
attr: [name: "rf_id"
int64_val: 4181
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123284654
]
name: aten::baddbmm
id: 11884
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4181
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284654
]
name: aten::view
id: 11886
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4182
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284681
]
name: aten::view
id: 11887
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4183
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284681
]
name: ScaledUpperTriangMaskedSoftmax
id: 11888
duration_micros: 65
attr: [name: "rf_id"
int64_val: 4184
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1974
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284739
]
name: aten::empty
id: 11889
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4185
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284752
]
name: aten::to
id: 11890
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4186
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284769
]
name: aten::lift_fresh
id: 11891
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4187
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284780
]
name: aten::detach_
id: 11892
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4188
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284787
]
name: detach_
id: 11893
duration_micros: 2
attr: [name: "rf_id"
int64_val: 4189
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284789
]
name: aten::select
id: 11894
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4190
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284800
]
name: aten::as_strided
id: 11895
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4191
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284806
]
name: aten::item
id: 11896
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4192
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284825
]
name: aten::_local_scalar_dense
id: 11897
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4193
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284827
]
name: aten::empty
id: 11898
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4194
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284843
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 11899
duration_micros: 426
attr: [name: "rf_id"
int64_val: 4194
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123284877
]
name: aten::empty
id: 11900
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4194
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284877
]
name: aten::view
id: 11902
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4195
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284899
]
name: aten::dropout
id: 11903
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4196
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123284960
]
name: aten::view
id: 11904
duration_micros: 39
attr: [name: "rf_id"
int64_val: 4197
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285000
]
name: aten::view
id: 11905
duration_micros: 39
attr: [name: "rf_id"
int64_val: 4198
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285000
]
name: aten::transpose
id: 11906
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4199
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285065
]
name: aten::as_strided
id: 11907
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4200
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285073
]
name: aten::bmm
id: 11908
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4201
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285093
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 11909
duration_micros: 186
attr: [name: "rf_id"
int64_val: 4201
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123285130
]
name: aten::bmm
id: 11910
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4201
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285130
]
name: aten::view
id: 11912
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4202
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285152
]
name: aten::permute
id: 11913
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4203
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285166
]
name: aten::as_strided
id: 11914
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4204
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285173
]
name: aten::contiguous
id: 11915
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4205
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285192
]
name: aten::clone
id: 11916
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4206
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285194
]
name: aten::empty_like
id: 11917
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4207
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285198
]
name: aten::empty
id: 11918
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4208
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285202
]
name: aten::copy_
id: 11919
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4209
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285230
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 11920
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4209
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123285246
]
name: aten::copy_
id: 11921
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4209
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285246
]
name: aten::view
id: 11923
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4210
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285286
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11924
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4211
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1975
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285336
]
name: aten::t
id: 11925
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4212
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285345
]
name: aten::transpose
id: 11926
duration_micros: 43
attr: [name: "rf_id"
int64_val: 4213
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285348
]
name: aten::as_strided
id: 11927
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4214
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285357
]
name: aten::matmul
id: 11928
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4215
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285416
]
name: aten::reshape
id: 11929
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4216
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285421
]
name: aten::view
id: 11930
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4217
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285424
]
name: aten::mm
id: 11931
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4218
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285441
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 11932
duration_micros: 161
attr: [name: "rf_id"
int64_val: 4218
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123285486
]
name: aten::mm
id: 11933
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4218
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285486
]
name: aten::_unsafe_view
id: 11935
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4219
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285503
]
name: _ReduceFromModelParallelRegion
id: 11936
duration_micros: 20949
attr: [name: "rf_id"
int64_val: 4220
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1976
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285539
]
name: c10d::allreduce_
id: 11937
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4221
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285572
]
name: record_param_comms
id: 11938
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4222
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285583
]
name: nccl:all_reduce
id: 11939
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4223
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285598
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 11940
duration_micros: 593
attr: [name: "rf_id"
int64_val: 4223
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123285615
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 11941
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4223
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285615
]
name: record_param_comms
id: 11943
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4224
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123285686
]
name: aten::view_as
id: 11944
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4225
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306591
]
name: aten::view
id: 11945
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4226
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306596
]
name: aten::expand_as
id: 11946
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4227
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306637
]
name: aten::expand
id: 11947
duration_micros: 44
attr: [name: "rf_id"
int64_val: 4228
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306641
]
name: aten::as_strided
id: 11948
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4229
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306647
]
name: TorchDynamo Cache Lookup
id: 11949
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4230
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306732
]
name: Torch-Compiled Region
id: 11950
duration_micros: 74
attr: [name: "rf_id"
int64_val: 4231
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306744
]
name: aten::empty
id: 11951
duration_micros: 33
attr: [name: "rf_id"
int64_val: 4232
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306786
]
name: triton_poi_fused_add_0
id: 11952
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4233
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306832
]
name: triton__0d1d2d3d4de
id: 11953
duration_micros: 113
attr: [name: "rf_id"
int64_val: 4233
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123306849
]
name: triton_poi_fused_add_0
id: 11954
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4233
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306849
]
name: FusedLayerNormAffineFunction
id: 11956
duration_micros: 48
attr: [name: "rf_id"
int64_val: 4234
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1977
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306927
]
name: aten::empty_like
id: 11957
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4235
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306939
]
name: aten::empty_strided
id: 11958
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4236
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306946
]
name: aten::empty
id: 11959
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4237
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306976
]
name: aten::empty_like
id: 11960
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4238
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306992
]
name: aten::empty_strided
id: 11961
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4239
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123306996
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 11962
duration_micros: 136
attr: [name: "rf_id"
int64_val: 4239
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123307027
]
name: aten::empty_strided
id: 11963
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4239
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307027
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11965
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4240
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1978
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307090
]
name: aten::t
id: 11966
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4241
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307099
]
name: aten::transpose
id: 11967
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4242
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307102
]
name: aten::as_strided
id: 11968
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4243
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307109
]
name: aten::matmul
id: 11969
duration_micros: 23
attr: [name: "rf_id"
int64_val: 4244
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307136
]
name: aten::reshape
id: 11970
duration_micros: 37
attr: [name: "rf_id"
int64_val: 4245
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307141
]
name: aten::view
id: 11971
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4246
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307143
]
name: aten::mm
id: 11972
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4247
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307195
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 11973
duration_micros: 522
attr: [name: "rf_id"
int64_val: 4247
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123307242
]
name: aten::mm
id: 11974
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4247
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307242
]
name: aten::_unsafe_view
id: 11976
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4248
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307262
]
name: GeLUFunction
id: 11977
duration_micros: 32
attr: [name: "rf_id"
int64_val: 4249
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1979
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307308
]
name: TorchDynamo Cache Lookup
id: 11978
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4250
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307329
]
name: Torch-Compiled Region
id: 11979
duration_micros: 68
attr: [name: "rf_id"
int64_val: 4251
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307339
]
name: aten::empty
id: 11980
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4252
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307377
]
name: triton_poi_fused_add_mul_tanh_0
id: 11981
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4253
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307407
]
name: triton__0d1d2d3de
id: 11982
duration_micros: 43
attr: [name: "rf_id"
int64_val: 4253
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123307423
]
name: triton_poi_fused_add_mul_tanh_0
id: 11983
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4253
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307423
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 11985
duration_micros: 53
attr: [name: "rf_id"
int64_val: 4254
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1980
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307500
]
name: aten::t
id: 11986
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4255
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307509
]
name: aten::transpose
id: 11987
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4256
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307512
]
name: aten::as_strided
id: 11988
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4257
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307518
]
name: aten::matmul
id: 11989
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4258
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307547
]
name: aten::reshape
id: 11990
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4259
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307551
]
name: aten::view
id: 11991
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4260
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307554
]
name: aten::mm
id: 11992
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4261
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307570
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 11993
duration_micros: 566
attr: [name: "rf_id"
int64_val: 4261
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123307619
]
name: aten::mm
id: 11994
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4261
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307619
]
name: aten::_unsafe_view
id: 11996
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4262
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307636
]
name: _ReduceFromModelParallelRegion
id: 11997
duration_micros: 63
attr: [name: "rf_id"
int64_val: 4263
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1981
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307705
]
name: c10d::allreduce_
id: 11998
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4264
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307735
]
name: record_param_comms
id: 11999
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4265
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307747
]
name: nccl:all_reduce
id: 12000
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4266
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307763
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 12001
duration_micros: 582
attr: [name: "rf_id"
int64_val: 4266
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123307784
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 12002
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4266
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307784
]
name: record_param_comms
id: 12004
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4267
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307854
]
name: aten::view_as
id: 12005
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4268
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307877
]
name: aten::view
id: 12006
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4269
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307882
]
name: aten::expand_as
id: 12007
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4270
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307922
]
name: aten::expand
id: 12008
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4271
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307926
]
name: aten::as_strided
id: 12009
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4272
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307932
]
name: TorchDynamo Cache Lookup
id: 12010
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4273
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307975
]
name: Torch-Compiled Region
id: 12011
duration_micros: 68
attr: [name: "rf_id"
int64_val: 4274
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123307986
]
name: aten::empty
id: 12012
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4275
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308024
]
name: triton_poi_fused_add_0
id: 12013
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4276
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308055
]
name: triton__0d1d2d3d4de
id: 12014
duration_micros: 113
attr: [name: "rf_id"
int64_val: 4276
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123308071
]
name: triton_poi_fused_add_0
id: 12015
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4276
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308071
]
name: FusedLayerNormAffineFunction
id: 12017
duration_micros: 53
attr: [name: "rf_id"
int64_val: 4277
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1982
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308177
]
name: aten::empty_like
id: 12018
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4278
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308189
]
name: aten::empty_strided
id: 12019
duration_micros: 22
attr: [name: "rf_id"
int64_val: 4279
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308195
]
name: aten::empty
id: 12020
duration_micros: 45
attr: [name: "rf_id"
int64_val: 4280
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308229
]
name: aten::empty_like
id: 12021
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4281
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308280
]
name: aten::empty_strided
id: 12022
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4282
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308285
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 12023
duration_micros: 135
attr: [name: "rf_id"
int64_val: 4282
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123308323
]
name: aten::empty_strided
id: 12024
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4282
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308323
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12026
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4283
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1983
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308392
]
name: aten::t
id: 12027
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4284
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308401
]
name: aten::transpose
id: 12028
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4285
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308409
]
name: aten::as_strided
id: 12029
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4286
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308415
]
name: aten::matmul
id: 12030
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4287
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308443
]
name: aten::reshape
id: 12031
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4288
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308447
]
name: aten::view
id: 12032
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4289
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308450
]
name: aten::mm
id: 12033
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4290
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308466
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 12034
duration_micros: 400
attr: [name: "rf_id"
int64_val: 4290
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123308510
]
name: aten::mm
id: 12035
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4290
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308510
]
name: aten::_unsafe_view
id: 12037
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4291
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308528
]
name: aten::add
id: 12038
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4292
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308550
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 12039
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4292
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123308572
]
name: aten::add
id: 12040
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4292
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308572
]
name: aten::view
id: 12042
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4293
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308610
]
name: aten::split_with_sizes
id: 12043
duration_micros: 3328
attr: [name: "rf_id"
int64_val: 4294
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308635
]
name: aten::as_strided
id: 12044
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4295
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308642
]
name: aten::as_strided
id: 12045
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4296
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308642
]
name: aten::as_strided
id: 12046
duration_micros: 36
attr: [name: "rf_id"
int64_val: 4297
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123308656
]
name: aten::view
id: 12047
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4298
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312032
]
name: aten::reshape
id: 12048
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4299
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312059
]
name: aten::_reshape_alias
id: 12049
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4300
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312069
]
name: aten::view
id: 12050
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4301
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312089
]
name: aten::slice
id: 12051
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4302
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312112
]
name: aten::as_strided
id: 12052
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4303
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312118
]
name: aten::view
id: 12053
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4304
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312143
]
name: aten::transpose
id: 12054
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4305
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312156
]
name: aten::as_strided
id: 12055
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4306
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312162
]
name: aten::transpose
id: 12056
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4307
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312182
]
name: aten::as_strided
id: 12057
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4308
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312187
]
name: aten::transpose
id: 12058
duration_micros: 39
attr: [name: "rf_id"
int64_val: 4309
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312203
]
name: aten::as_strided
id: 12059
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4310
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312208
]
name: aten::baddbmm
id: 12060
duration_micros: 39
attr: [name: "rf_id"
int64_val: 4311
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312266
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 12061
duration_micros: 295
attr: [name: "rf_id"
int64_val: 4311
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123312329
]
name: aten::baddbmm
id: 12062
duration_micros: 39
attr: [name: "rf_id"
int64_val: 4311
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312329
]
name: aten::view
id: 12064
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4312
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312357
]
name: aten::view
id: 12065
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4313
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312357
]
name: ScaledUpperTriangMaskedSoftmax
id: 12066
duration_micros: 64
attr: [name: "rf_id"
int64_val: 4314
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1984
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312412
]
name: aten::empty
id: 12067
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4315
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312425
]
name: aten::to
id: 12068
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4316
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312442
]
name: aten::lift_fresh
id: 12069
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4317
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312452
]
name: aten::detach_
id: 12070
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4318
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312460
]
name: detach_
id: 12071
duration_micros: 3
attr: [name: "rf_id"
int64_val: 4319
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312461
]
name: aten::select
id: 12072
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4320
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312474
]
name: aten::as_strided
id: 12073
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4321
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312479
]
name: aten::item
id: 12074
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4322
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312498
]
name: aten::_local_scalar_dense
id: 12075
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4323
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312500
]
name: aten::empty
id: 12076
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4324
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312516
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 12077
duration_micros: 425
attr: [name: "rf_id"
int64_val: 4324
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123312549
]
name: aten::empty
id: 12078
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4324
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312549
]
name: aten::view
id: 12080
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4325
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312571
]
name: aten::dropout
id: 12081
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4326
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312634
]
name: aten::view
id: 12082
duration_micros: 41
attr: [name: "rf_id"
int64_val: 4327
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312680
]
name: aten::view
id: 12083
duration_micros: 41
attr: [name: "rf_id"
int64_val: 4328
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312680
]
name: aten::transpose
id: 12084
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4329
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312746
]
name: aten::as_strided
id: 12085
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4330
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312752
]
name: aten::bmm
id: 12086
duration_micros: 22
attr: [name: "rf_id"
int64_val: 4331
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312772
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 12087
duration_micros: 184
attr: [name: "rf_id"
int64_val: 4331
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123312806
]
name: aten::bmm
id: 12088
duration_micros: 22
attr: [name: "rf_id"
int64_val: 4331
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312806
]
name: aten::view
id: 12090
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4332
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312827
]
name: aten::permute
id: 12091
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4333
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312842
]
name: aten::as_strided
id: 12092
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4334
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312849
]
name: aten::contiguous
id: 12093
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4335
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312868
]
name: aten::clone
id: 12094
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4336
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312871
]
name: aten::empty_like
id: 12095
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4337
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312875
]
name: aten::empty
id: 12096
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4338
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312879
]
name: aten::copy_
id: 12097
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4339
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312908
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 12098
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4339
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123312926
]
name: aten::copy_
id: 12099
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4339
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312926
]
name: aten::view
id: 12101
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4340
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123312964
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12102
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4341
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1985
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313016
]
name: aten::t
id: 12103
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4342
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313024
]
name: aten::transpose
id: 12104
duration_micros: 41
attr: [name: "rf_id"
int64_val: 4343
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313028
]
name: aten::as_strided
id: 12105
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4344
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313033
]
name: aten::matmul
id: 12106
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4345
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313094
]
name: aten::reshape
id: 12107
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4346
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313099
]
name: aten::view
id: 12108
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4347
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313102
]
name: aten::mm
id: 12109
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4348
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313118
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 12110
duration_micros: 161
attr: [name: "rf_id"
int64_val: 4348
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123313161
]
name: aten::mm
id: 12111
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4348
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313161
]
name: aten::_unsafe_view
id: 12113
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4349
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313179
]
name: _ReduceFromModelParallelRegion
id: 12114
duration_micros: 62
attr: [name: "rf_id"
int64_val: 4350
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1986
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313216
]
name: c10d::allreduce_
id: 12115
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4351
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313244
]
name: record_param_comms
id: 12116
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4352
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313256
]
name: nccl:all_reduce
id: 12117
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4353
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313271
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 12118
duration_micros: 622
attr: [name: "rf_id"
int64_val: 4353
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123313287
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 12119
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4353
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313287
]
name: record_param_comms
id: 12121
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4354
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313360
]
name: aten::view_as
id: 12122
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4355
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313382
]
name: aten::view
id: 12123
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4356
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313387
]
name: aten::expand_as
id: 12124
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4357
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313430
]
name: aten::expand
id: 12125
duration_micros: 44
attr: [name: "rf_id"
int64_val: 4358
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313435
]
name: aten::as_strided
id: 12126
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4359
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313441
]
name: TorchDynamo Cache Lookup
id: 12127
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4360
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313519
]
name: Torch-Compiled Region
id: 12128
duration_micros: 72
attr: [name: "rf_id"
int64_val: 4361
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313531
]
name: aten::empty
id: 12129
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4362
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313572
]
name: triton_poi_fused_add_0
id: 12130
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4363
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313604
]
name: triton__0d1d2d3d4de
id: 12131
duration_micros: 114
attr: [name: "rf_id"
int64_val: 4363
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123313620
]
name: triton_poi_fused_add_0
id: 12132
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4363
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313620
]
name: FusedLayerNormAffineFunction
id: 12134
duration_micros: 50
attr: [name: "rf_id"
int64_val: 4364
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1987
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313704
]
name: aten::empty_like
id: 12135
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4365
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313717
]
name: aten::empty_strided
id: 12136
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4366
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313723
]
name: aten::empty
id: 12137
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4367
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313754
]
name: aten::empty_like
id: 12138
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4368
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313770
]
name: aten::empty_strided
id: 12139
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4369
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313774
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 12140
duration_micros: 137
attr: [name: "rf_id"
int64_val: 4369
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123313805
]
name: aten::empty_strided
id: 12141
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4369
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313805
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12143
duration_micros: 23
attr: [name: "rf_id"
int64_val: 4370
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1988
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313869
]
name: aten::t
id: 12144
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4371
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313877
]
name: aten::transpose
id: 12145
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4372
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313881
]
name: aten::as_strided
id: 12146
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4373
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313891
]
name: aten::matmul
id: 12147
duration_micros: 22
attr: [name: "rf_id"
int64_val: 4374
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313919
]
name: aten::reshape
id: 12148
duration_micros: 41
attr: [name: "rf_id"
int64_val: 4375
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313923
]
name: aten::view
id: 12149
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4376
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313929
]
name: aten::mm
id: 12150
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4377
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123313978
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 12151
duration_micros: 521
attr: [name: "rf_id"
int64_val: 4377
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123314025
]
name: aten::mm
id: 12152
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4377
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314025
]
name: aten::_unsafe_view
id: 12154
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4378
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314045
]
name: GeLUFunction
id: 12155
duration_micros: 32
attr: [name: "rf_id"
int64_val: 4379
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1989
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314090
]
name: TorchDynamo Cache Lookup
id: 12156
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4380
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314111
]
name: Torch-Compiled Region
id: 12157
duration_micros: 67
attr: [name: "rf_id"
int64_val: 4381
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314120
]
name: aten::empty
id: 12158
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4382
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314157
]
name: triton_poi_fused_add_mul_tanh_0
id: 12159
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4383
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314188
]
name: triton__0d1d2d3de
id: 12160
duration_micros: 43
attr: [name: "rf_id"
int64_val: 4383
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123314203
]
name: triton_poi_fused_add_mul_tanh_0
id: 12161
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4383
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314203
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12163
duration_micros: 51
attr: [name: "rf_id"
int64_val: 4384
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1990
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314281
]
name: aten::t
id: 12164
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4385
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314289
]
name: aten::transpose
id: 12165
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4386
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314293
]
name: aten::as_strided
id: 12166
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4387
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314299
]
name: aten::matmul
id: 12167
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4388
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314327
]
name: aten::reshape
id: 12168
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4389
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314331
]
name: aten::view
id: 12169
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4390
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314334
]
name: aten::mm
id: 12170
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4391
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314349
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 12171
duration_micros: 565
attr: [name: "rf_id"
int64_val: 4391
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123314398
]
name: aten::mm
id: 12172
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4391
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314398
]
name: aten::_unsafe_view
id: 12174
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4392
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314416
]
name: _ReduceFromModelParallelRegion
id: 12175
duration_micros: 67
attr: [name: "rf_id"
int64_val: 4393
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1991
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314485
]
name: c10d::allreduce_
id: 12176
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4394
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314518
]
name: record_param_comms
id: 12177
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4395
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314530
]
name: nccl:all_reduce
id: 12178
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4396
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314548
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 12179
duration_micros: 624
attr: [name: "rf_id"
int64_val: 4396
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123314565
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 12180
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4396
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314565
]
name: record_param_comms
id: 12182
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4397
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314635
]
name: aten::view_as
id: 12183
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4398
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314658
]
name: aten::view
id: 12184
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4399
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314662
]
name: aten::expand_as
id: 12185
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4400
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314704
]
name: aten::expand
id: 12186
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4401
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314709
]
name: aten::as_strided
id: 12187
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4402
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314715
]
name: TorchDynamo Cache Lookup
id: 12188
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4403
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314758
]
name: Torch-Compiled Region
id: 12189
duration_micros: 67
attr: [name: "rf_id"
int64_val: 4404
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314770
]
name: aten::empty
id: 12190
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4405
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314807
]
name: triton_poi_fused_add_0
id: 12191
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4406
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314837
]
name: triton__0d1d2d3d4de
id: 12192
duration_micros: 113
attr: [name: "rf_id"
int64_val: 4406
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123314853
]
name: triton_poi_fused_add_0
id: 12193
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4406
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314853
]
name: FusedLayerNormAffineFunction
id: 12195
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4407
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1992
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314960
]
name: aten::empty_like
id: 12196
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4408
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314972
]
name: aten::empty_strided
id: 12197
duration_micros: 21
attr: [name: "rf_id"
int64_val: 4409
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123314978
]
name: aten::empty
id: 12198
duration_micros: 45
attr: [name: "rf_id"
int64_val: 4410
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315012
]
name: aten::empty_like
id: 12199
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4411
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315064
]
name: aten::empty_strided
id: 12200
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4412
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315071
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 12201
duration_micros: 135
attr: [name: "rf_id"
int64_val: 4412
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123315111
]
name: aten::empty_strided
id: 12202
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4412
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315111
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12204
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4413
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1993
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315180
]
name: aten::t
id: 12205
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4414
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315189
]
name: aten::transpose
id: 12206
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4415
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315193
]
name: aten::as_strided
id: 12207
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4416
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315199
]
name: aten::matmul
id: 12208
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4417
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315227
]
name: aten::reshape
id: 12209
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4418
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315231
]
name: aten::view
id: 12210
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4419
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315235
]
name: aten::mm
id: 12211
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4420
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315250
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 12212
duration_micros: 400
attr: [name: "rf_id"
int64_val: 4420
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123315294
]
name: aten::mm
id: 12213
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4420
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315294
]
name: aten::_unsafe_view
id: 12215
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4421
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315312
]
name: aten::add
id: 12216
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4422
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315333
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 12217
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4422
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123315355
]
name: aten::add
id: 12218
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4422
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315355
]
name: aten::view
id: 12220
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4423
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315393
]
name: aten::split_with_sizes
id: 12221
duration_micros: 31
attr: [name: "rf_id"
int64_val: 4424
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315417
]
name: aten::as_strided
id: 12222
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4425
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315424
]
name: aten::as_strided
id: 12223
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4426
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315424
]
name: aten::as_strided
id: 12224
duration_micros: 38
attr: [name: "rf_id"
int64_val: 4427
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315438
]
name: aten::view
id: 12225
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4428
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315517
]
name: aten::reshape
id: 12226
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4429
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315543
]
name: aten::_reshape_alias
id: 12227
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4430
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315550
]
name: aten::view
id: 12228
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4431
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315570
]
name: aten::slice
id: 12229
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4432
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315591
]
name: aten::as_strided
id: 12230
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4433
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315597
]
name: aten::view
id: 12231
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4434
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315622
]
name: aten::transpose
id: 12232
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4435
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315635
]
name: aten::as_strided
id: 12233
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4436
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315640
]
name: aten::transpose
id: 12234
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4437
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315658
]
name: aten::as_strided
id: 12235
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4438
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315662
]
name: aten::transpose
id: 12236
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4439
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315681
]
name: aten::as_strided
id: 12237
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4440
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315685
]
name: aten::baddbmm
id: 12238
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4441
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315738
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 12239
duration_micros: 295
attr: [name: "rf_id"
int64_val: 4441
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123315792
]
name: aten::baddbmm
id: 12240
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4441
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315792
]
name: aten::view
id: 12242
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4442
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315819
]
name: aten::view
id: 12243
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4443
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315819
]
name: ScaledUpperTriangMaskedSoftmax
id: 12244
duration_micros: 65
attr: [name: "rf_id"
int64_val: 4444
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1994
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315874
]
name: aten::empty
id: 12245
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4445
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315887
]
name: aten::to
id: 12246
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4446
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315904
]
name: aten::lift_fresh
id: 12247
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4447
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315915
]
name: aten::detach_
id: 12248
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4448
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315922
]
name: detach_
id: 12249
duration_micros: 2
attr: [name: "rf_id"
int64_val: 4449
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315924
]
name: aten::select
id: 12250
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4450
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315936
]
name: aten::as_strided
id: 12251
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4451
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315942
]
name: aten::item
id: 12252
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4452
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315961
]
name: aten::_local_scalar_dense
id: 12253
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4453
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315963
]
name: aten::empty
id: 12254
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4454
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123315984
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 12255
duration_micros: 427
attr: [name: "rf_id"
int64_val: 4454
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123316019
]
name: aten::empty
id: 12256
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4454
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316019
]
name: aten::view
id: 12258
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4455
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316041
]
name: aten::dropout
id: 12259
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4456
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316104
]
name: aten::view
id: 12260
duration_micros: 40
attr: [name: "rf_id"
int64_val: 4457
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316144
]
name: aten::view
id: 12261
duration_micros: 40
attr: [name: "rf_id"
int64_val: 4458
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316144
]
name: aten::transpose
id: 12262
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4459
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316209
]
name: aten::as_strided
id: 12263
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4460
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316215
]
name: aten::bmm
id: 12264
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4461
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316235
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 12265
duration_micros: 185
attr: [name: "rf_id"
int64_val: 4461
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123316276
]
name: aten::bmm
id: 12266
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4461
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316276
]
name: aten::view
id: 12268
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4462
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316298
]
name: aten::permute
id: 12269
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4463
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316313
]
name: aten::as_strided
id: 12270
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4464
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316319
]
name: aten::contiguous
id: 12271
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4465
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316343
]
name: aten::clone
id: 12272
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4466
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316345
]
name: aten::empty_like
id: 12273
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4467
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316349
]
name: aten::empty
id: 12274
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4468
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316353
]
name: aten::copy_
id: 12275
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4469
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316380
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 12276
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4469
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123316396
]
name: aten::copy_
id: 12277
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4469
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316396
]
name: aten::view
id: 12279
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4470
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316436
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12280
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4471
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1995
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316487
]
name: aten::t
id: 12281
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4472
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316496
]
name: aten::transpose
id: 12282
duration_micros: 41
attr: [name: "rf_id"
int64_val: 4473
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316499
]
name: aten::as_strided
id: 12283
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4474
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316505
]
name: aten::matmul
id: 12284
duration_micros: 23
attr: [name: "rf_id"
int64_val: 4475
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316564
]
name: aten::reshape
id: 12285
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4476
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316570
]
name: aten::view
id: 12286
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4477
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316573
]
name: aten::mm
id: 12287
duration_micros: 10102
attr: [name: "rf_id"
int64_val: 4478
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123316589
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 12288
duration_micros: 161
attr: [name: "rf_id"
int64_val: 4478
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123336775
]
name: aten::mm
id: 12289
duration_micros: 10102
attr: [name: "rf_id"
int64_val: 4478
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123336775
]
name: aten::_unsafe_view
id: 12291
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4479
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123336802
]
name: _ReduceFromModelParallelRegion
id: 12292
duration_micros: 62
attr: [name: "rf_id"
int64_val: 4480
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1996
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123336840
]
name: c10d::allreduce_
id: 12293
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4481
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123336869
]
name: record_param_comms
id: 12294
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4482
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123336881
]
name: nccl:all_reduce
id: 12295
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4483
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123336897
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 12296
duration_micros: 644
attr: [name: "rf_id"
int64_val: 4483
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123336914
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 12297
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4483
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123336914
]
name: record_param_comms
id: 12299
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4484
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123336981
]
name: aten::view_as
id: 12300
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4485
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337003
]
name: aten::view
id: 12301
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4486
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337008
]
name: aten::expand_as
id: 12302
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4487
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337052
]
name: aten::expand
id: 12303
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4488
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337057
]
name: aten::as_strided
id: 12304
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4489
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337071
]
name: TorchDynamo Cache Lookup
id: 12305
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4490
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337153
]
name: Torch-Compiled Region
id: 12306
duration_micros: 74
attr: [name: "rf_id"
int64_val: 4491
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337166
]
name: aten::empty
id: 12307
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4492
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337209
]
name: triton_poi_fused_add_0
id: 12308
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4493
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337241
]
name: triton__0d1d2d3d4de
id: 12309
duration_micros: 114
attr: [name: "rf_id"
int64_val: 4493
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123337259
]
name: triton_poi_fused_add_0
id: 12310
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4493
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337259
]
name: FusedLayerNormAffineFunction
id: 12312
duration_micros: 49
attr: [name: "rf_id"
int64_val: 4494
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1997
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337336
]
name: aten::empty_like
id: 12313
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4495
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337348
]
name: aten::empty_strided
id: 12314
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4496
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337355
]
name: aten::empty
id: 12315
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4497
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337385
]
name: aten::empty_like
id: 12316
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4498
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337401
]
name: aten::empty_strided
id: 12317
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4499
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337405
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 12318
duration_micros: 137
attr: [name: "rf_id"
int64_val: 4499
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123337437
]
name: aten::empty_strided
id: 12319
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4499
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337437
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12321
duration_micros: 37
attr: [name: "rf_id"
int64_val: 4500
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1998
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337501
]
name: aten::t
id: 12322
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4501
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337510
]
name: aten::transpose
id: 12323
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4502
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337514
]
name: aten::as_strided
id: 12324
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4503
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337525
]
name: aten::matmul
id: 12325
duration_micros: 21
attr: [name: "rf_id"
int64_val: 4504
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337554
]
name: aten::reshape
id: 12326
duration_micros: 38
attr: [name: "rf_id"
int64_val: 4505
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337558
]
name: aten::view
id: 12327
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4506
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337561
]
name: aten::mm
id: 12328
duration_micros: 31
attr: [name: "rf_id"
int64_val: 4507
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337609
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 12329
duration_micros: 522
attr: [name: "rf_id"
int64_val: 4507
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123337658
]
name: aten::mm
id: 12330
duration_micros: 31
attr: [name: "rf_id"
int64_val: 4507
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337658
]
name: aten::_unsafe_view
id: 12332
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4508
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337678
]
name: GeLUFunction
id: 12333
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4509
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 1999
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337735
]
name: TorchDynamo Cache Lookup
id: 12334
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4510
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337757
]
name: Torch-Compiled Region
id: 12335
duration_micros: 69
attr: [name: "rf_id"
int64_val: 4511
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337767
]
name: aten::empty
id: 12336
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4512
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337805
]
name: triton_poi_fused_add_mul_tanh_0
id: 12337
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4513
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337837
]
name: triton__0d1d2d3de
id: 12338
duration_micros: 43
attr: [name: "rf_id"
int64_val: 4513
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123337853
]
name: triton_poi_fused_add_mul_tanh_0
id: 12339
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4513
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337853
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12341
duration_micros: 55
attr: [name: "rf_id"
int64_val: 4514
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2000
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337931
]
name: aten::t
id: 12342
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4515
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337940
]
name: aten::transpose
id: 12343
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4516
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337944
]
name: aten::as_strided
id: 12344
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4517
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337950
]
name: aten::matmul
id: 12345
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4518
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337980
]
name: aten::reshape
id: 12346
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4519
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337984
]
name: aten::view
id: 12347
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4520
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123337987
]
name: aten::mm
id: 12348
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4521
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338007
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 12349
duration_micros: 566
attr: [name: "rf_id"
int64_val: 4521
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123338056
]
name: aten::mm
id: 12350
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4521
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338056
]
name: aten::_unsafe_view
id: 12352
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4522
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338074
]
name: _ReduceFromModelParallelRegion
id: 12353
duration_micros: 63
attr: [name: "rf_id"
int64_val: 4523
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2001
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338145
]
name: c10d::allreduce_
id: 12354
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4524
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338173
]
name: record_param_comms
id: 12355
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4525
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338184
]
name: nccl:all_reduce
id: 12356
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4526
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338201
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 12357
duration_micros: 614
attr: [name: "rf_id"
int64_val: 4526
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123338218
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 12358
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4526
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338218
]
name: record_param_comms
id: 12360
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4527
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338295
]
name: aten::view_as
id: 12361
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4528
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338319
]
name: aten::view
id: 12362
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4529
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338323
]
name: aten::expand_as
id: 12363
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4530
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338364
]
name: aten::expand
id: 12364
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4531
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338368
]
name: aten::as_strided
id: 12365
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4532
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338374
]
name: TorchDynamo Cache Lookup
id: 12366
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4533
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338417
]
name: Torch-Compiled Region
id: 12367
duration_micros: 67
attr: [name: "rf_id"
int64_val: 4534
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338429
]
name: aten::empty
id: 12368
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4535
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338466
]
name: triton_poi_fused_add_0
id: 12369
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4536
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338496
]
name: triton__0d1d2d3d4de
id: 12370
duration_micros: 113
attr: [name: "rf_id"
int64_val: 4536
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123338512
]
name: triton_poi_fused_add_0
id: 12371
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4536
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338512
]
name: FusedLayerNormAffineFunction
id: 12373
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4537
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2002
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338618
]
name: aten::empty_like
id: 12374
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4538
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338630
]
name: aten::empty_strided
id: 12375
duration_micros: 21
attr: [name: "rf_id"
int64_val: 4539
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338637
]
name: aten::empty
id: 12376
duration_micros: 48
attr: [name: "rf_id"
int64_val: 4540
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338670
]
name: aten::empty_like
id: 12377
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4541
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338724
]
name: aten::empty_strided
id: 12378
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4542
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338729
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 12379
duration_micros: 137
attr: [name: "rf_id"
int64_val: 4542
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123338770
]
name: aten::empty_strided
id: 12380
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4542
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338770
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12382
duration_micros: 36
attr: [name: "rf_id"
int64_val: 4543
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2003
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338838
]
name: aten::t
id: 12383
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4544
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338847
]
name: aten::transpose
id: 12384
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4545
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338851
]
name: aten::as_strided
id: 12385
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4546
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338857
]
name: aten::matmul
id: 12386
duration_micros: 2872
attr: [name: "rf_id"
int64_val: 4547
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338885
]
name: aten::reshape
id: 12387
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4548
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338890
]
name: aten::view
id: 12388
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4549
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123338893
]
name: aten::mm
id: 12389
duration_micros: 43
attr: [name: "rf_id"
int64_val: 4550
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123341758
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 12390
duration_micros: 399
attr: [name: "rf_id"
int64_val: 4550
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123341831
]
name: aten::mm
id: 12391
duration_micros: 43
attr: [name: "rf_id"
int64_val: 4550
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123341831
]
name: aten::_unsafe_view
id: 12393
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4551
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123341853
]
name: aten::add
id: 12394
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4552
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123341877
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 12395
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4552
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123341899
]
name: aten::add
id: 12396
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4552
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123341899
]
name: aten::view
id: 12398
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4553
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123341937
]
name: aten::split_with_sizes
id: 12399
duration_micros: 31
attr: [name: "rf_id"
int64_val: 4554
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123341963
]
name: aten::as_strided
id: 12400
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4555
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123341969
]
name: aten::as_strided
id: 12401
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4556
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123341969
]
name: aten::as_strided
id: 12402
duration_micros: 37
attr: [name: "rf_id"
int64_val: 4557
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123341987
]
name: aten::view
id: 12403
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4558
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342062
]
name: aten::reshape
id: 12404
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4559
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342088
]
name: aten::_reshape_alias
id: 12405
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4560
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342096
]
name: aten::view
id: 12406
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4561
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342116
]
name: aten::slice
id: 12407
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4562
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342140
]
name: aten::as_strided
id: 12408
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4563
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342146
]
name: aten::view
id: 12409
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4564
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342172
]
name: aten::transpose
id: 12410
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4565
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342185
]
name: aten::as_strided
id: 12411
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4566
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342191
]
name: aten::transpose
id: 12412
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4567
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342211
]
name: aten::as_strided
id: 12413
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4568
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342216
]
name: aten::transpose
id: 12414
duration_micros: 35
attr: [name: "rf_id"
int64_val: 4569
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342231
]
name: aten::as_strided
id: 12415
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4570
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342236
]
name: aten::baddbmm
id: 12416
duration_micros: 32
attr: [name: "rf_id"
int64_val: 4571
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342289
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 12417
duration_micros: 296
attr: [name: "rf_id"
int64_val: 4571
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123342340
]
name: aten::baddbmm
id: 12418
duration_micros: 32
attr: [name: "rf_id"
int64_val: 4571
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342340
]
name: aten::view
id: 12420
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4572
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342366
]
name: aten::view
id: 12421
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4573
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342366
]
name: ScaledUpperTriangMaskedSoftmax
id: 12422
duration_micros: 63
attr: [name: "rf_id"
int64_val: 4574
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2004
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342427
]
name: aten::empty
id: 12423
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4575
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342440
]
name: aten::to
id: 12424
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4576
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342456
]
name: aten::lift_fresh
id: 12425
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4577
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342467
]
name: aten::detach_
id: 12426
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4578
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342474
]
name: detach_
id: 12427
duration_micros: 4
attr: [name: "rf_id"
int64_val: 4579
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342476
]
name: aten::select
id: 12428
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4580
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342491
]
name: aten::as_strided
id: 12429
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4581
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342496
]
name: aten::item
id: 12430
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4582
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342515
]
name: aten::_local_scalar_dense
id: 12431
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4583
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342517
]
name: aten::empty
id: 12432
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4584
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342533
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 12433
duration_micros: 425
attr: [name: "rf_id"
int64_val: 4584
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123342565
]
name: aten::empty
id: 12434
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4584
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342565
]
name: aten::view
id: 12436
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4585
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342587
]
name: aten::dropout
id: 12437
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4586
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342649
]
name: aten::view
id: 12438
duration_micros: 41
attr: [name: "rf_id"
int64_val: 4587
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342688
]
name: aten::view
id: 12439
duration_micros: 41
attr: [name: "rf_id"
int64_val: 4588
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342688
]
name: aten::transpose
id: 12440
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4589
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342756
]
name: aten::as_strided
id: 12441
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4590
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342761
]
name: aten::bmm
id: 12442
duration_micros: 22
attr: [name: "rf_id"
int64_val: 4591
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342781
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 12443
duration_micros: 184
attr: [name: "rf_id"
int64_val: 4591
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123342816
]
name: aten::bmm
id: 12444
duration_micros: 22
attr: [name: "rf_id"
int64_val: 4591
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342816
]
name: aten::view
id: 12446
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4592
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342836
]
name: aten::permute
id: 12447
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4593
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342857
]
name: aten::as_strided
id: 12448
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4594
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342863
]
name: aten::contiguous
id: 12449
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4595
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342883
]
name: aten::clone
id: 12450
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4596
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342886
]
name: aten::empty_like
id: 12451
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4597
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342890
]
name: aten::empty
id: 12452
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4598
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342894
]
name: aten::copy_
id: 12453
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4599
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342920
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 12454
duration_micros: 21
attr: [name: "rf_id"
int64_val: 4599
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123342937
]
name: aten::copy_
id: 12455
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4599
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342937
]
name: aten::view
id: 12457
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4600
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123342977
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12458
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4601
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2005
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343029
]
name: aten::t
id: 12459
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4602
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343038
]
name: aten::transpose
id: 12460
duration_micros: 40
attr: [name: "rf_id"
int64_val: 4603
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343041
]
name: aten::as_strided
id: 12461
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4604
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343047
]
name: aten::matmul
id: 12462
duration_micros: 22
attr: [name: "rf_id"
int64_val: 4605
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343106
]
name: aten::reshape
id: 12463
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4606
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343113
]
name: aten::view
id: 12464
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4607
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343137
]
name: aten::mm
id: 12465
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4608
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343154
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 12466
duration_micros: 161
attr: [name: "rf_id"
int64_val: 4608
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123343198
]
name: aten::mm
id: 12467
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4608
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343198
]
name: aten::_unsafe_view
id: 12469
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4609
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343215
]
name: _ReduceFromModelParallelRegion
id: 12470
duration_micros: 61
attr: [name: "rf_id"
int64_val: 4610
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2006
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343253
]
name: c10d::allreduce_
id: 12471
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4611
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343280
]
name: record_param_comms
id: 12472
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4612
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343291
]
name: nccl:all_reduce
id: 12473
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4613
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343306
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 12474
duration_micros: 600
attr: [name: "rf_id"
int64_val: 4613
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123343323
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 12475
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4613
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343323
]
name: record_param_comms
id: 12477
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4614
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343394
]
name: aten::view_as
id: 12478
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4615
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343417
]
name: aten::view
id: 12479
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4616
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343421
]
name: aten::expand_as
id: 12480
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4617
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343463
]
name: aten::expand
id: 12481
duration_micros: 45
attr: [name: "rf_id"
int64_val: 4618
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343467
]
name: aten::as_strided
id: 12482
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4619
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343474
]
name: TorchDynamo Cache Lookup
id: 12483
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4620
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343552
]
name: Torch-Compiled Region
id: 12484
duration_micros: 72
attr: [name: "rf_id"
int64_val: 4621
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343564
]
name: aten::empty
id: 12485
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4622
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343605
]
name: triton_poi_fused_add_0
id: 12486
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4623
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343636
]
name: triton__0d1d2d3d4de
id: 12487
duration_micros: 113
attr: [name: "rf_id"
int64_val: 4623
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123343654
]
name: triton_poi_fused_add_0
id: 12488
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4623
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343654
]
name: FusedLayerNormAffineFunction
id: 12490
duration_micros: 49
attr: [name: "rf_id"
int64_val: 4624
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2007
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343730
]
name: aten::empty_like
id: 12491
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4625
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343742
]
name: aten::empty_strided
id: 12492
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4626
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343748
]
name: aten::empty
id: 12493
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4627
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343779
]
name: aten::empty_like
id: 12494
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4628
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343795
]
name: aten::empty_strided
id: 12495
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4629
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343798
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 12496
duration_micros: 136
attr: [name: "rf_id"
int64_val: 4629
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123343830
]
name: aten::empty_strided
id: 12497
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4629
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343830
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12499
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4630
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2008
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343892
]
name: aten::t
id: 12500
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4631
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343901
]
name: aten::transpose
id: 12501
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4632
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343905
]
name: aten::as_strided
id: 12502
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4633
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343911
]
name: aten::matmul
id: 12503
duration_micros: 22
attr: [name: "rf_id"
int64_val: 4634
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343939
]
name: aten::reshape
id: 12504
duration_micros: 38
attr: [name: "rf_id"
int64_val: 4635
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343943
]
name: aten::view
id: 12505
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4636
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343946
]
name: aten::mm
id: 12506
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4637
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123343994
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 12507
duration_micros: 521
attr: [name: "rf_id"
int64_val: 4637
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123344041
]
name: aten::mm
id: 12508
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4637
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344041
]
name: aten::_unsafe_view
id: 12510
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4638
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344061
]
name: GeLUFunction
id: 12511
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4639
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2009
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344107
]
name: TorchDynamo Cache Lookup
id: 12512
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4640
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344127
]
name: Torch-Compiled Region
id: 12513
duration_micros: 70
attr: [name: "rf_id"
int64_val: 4641
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344137
]
name: aten::empty
id: 12514
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4642
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344175
]
name: triton_poi_fused_add_mul_tanh_0
id: 12515
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4643
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344207
]
name: triton__0d1d2d3de
id: 12516
duration_micros: 43
attr: [name: "rf_id"
int64_val: 4643
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123344223
]
name: triton_poi_fused_add_mul_tanh_0
id: 12517
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4643
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344223
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12519
duration_micros: 55
attr: [name: "rf_id"
int64_val: 4644
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2010
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344305
]
name: aten::t
id: 12520
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4645
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344314
]
name: aten::transpose
id: 12521
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4646
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344318
]
name: aten::as_strided
id: 12522
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4647
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344324
]
name: aten::matmul
id: 12523
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4648
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344352
]
name: aten::reshape
id: 12524
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4649
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344356
]
name: aten::view
id: 12525
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4650
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344359
]
name: aten::mm
id: 12526
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4651
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344375
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 12527
duration_micros: 566
attr: [name: "rf_id"
int64_val: 4651
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123344423
]
name: aten::mm
id: 12528
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4651
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344423
]
name: aten::_unsafe_view
id: 12530
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4652
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344440
]
name: _ReduceFromModelParallelRegion
id: 12531
duration_micros: 63
attr: [name: "rf_id"
int64_val: 4653
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2011
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344511
]
name: c10d::allreduce_
id: 12532
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4654
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344540
]
name: record_param_comms
id: 12533
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4655
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344552
]
name: nccl:all_reduce
id: 12534
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4656
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344568
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 12535
duration_micros: 628
attr: [name: "rf_id"
int64_val: 4656
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123344585
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 12536
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4656
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344585
]
name: record_param_comms
id: 12538
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4657
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344658
]
name: aten::view_as
id: 12539
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4658
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344681
]
name: aten::view
id: 12540
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4659
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344686
]
name: aten::expand_as
id: 12541
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4660
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344725
]
name: aten::expand
id: 12542
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4661
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344729
]
name: aten::as_strided
id: 12543
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4662
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344735
]
name: TorchDynamo Cache Lookup
id: 12544
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4663
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344778
]
name: Torch-Compiled Region
id: 12545
duration_micros: 66
attr: [name: "rf_id"
int64_val: 4664
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344789
]
name: aten::empty
id: 12546
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4665
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344826
]
name: triton_poi_fused_add_0
id: 12547
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4666
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344855
]
name: triton__0d1d2d3d4de
id: 12548
duration_micros: 114
attr: [name: "rf_id"
int64_val: 4666
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123344871
]
name: triton_poi_fused_add_0
id: 12549
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4666
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344871
]
name: FusedLayerNormAffineFunction
id: 12551
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4667
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2012
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344976
]
name: aten::empty_like
id: 12552
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4668
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344988
]
name: aten::empty_strided
id: 12553
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4669
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123344995
]
name: aten::empty
id: 12554
duration_micros: 44
attr: [name: "rf_id"
int64_val: 4670
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345027
]
name: aten::empty_like
id: 12555
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4671
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345078
]
name: aten::empty_strided
id: 12556
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4672
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345083
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 12557
duration_micros: 134
attr: [name: "rf_id"
int64_val: 4672
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123345122
]
name: aten::empty_strided
id: 12558
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4672
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345122
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12560
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4673
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2013
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345190
]
name: aten::t
id: 12561
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4674
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345199
]
name: aten::transpose
id: 12562
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4675
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345202
]
name: aten::as_strided
id: 12563
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4676
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345208
]
name: aten::matmul
id: 12564
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4677
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345236
]
name: aten::reshape
id: 12565
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4678
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345241
]
name: aten::view
id: 12566
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4679
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345247
]
name: aten::mm
id: 12567
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4680
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345263
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 12568
duration_micros: 400
attr: [name: "rf_id"
int64_val: 4680
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123345308
]
name: aten::mm
id: 12569
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4680
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345308
]
name: aten::_unsafe_view
id: 12571
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4681
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345326
]
name: aten::add
id: 12572
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4682
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345347
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 12573
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4682
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123345370
]
name: aten::add
id: 12574
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4682
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345370
]
name: aten::view
id: 12576
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4683
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345407
]
name: aten::split_with_sizes
id: 12577
duration_micros: 32
attr: [name: "rf_id"
int64_val: 4684
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345432
]
name: aten::as_strided
id: 12578
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4685
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345439
]
name: aten::as_strided
id: 12579
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4686
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345439
]
name: aten::as_strided
id: 12580
duration_micros: 36
attr: [name: "rf_id"
int64_val: 4687
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345453
]
name: aten::view
id: 12581
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4688
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345527
]
name: aten::reshape
id: 12582
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4689
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345553
]
name: aten::_reshape_alias
id: 12583
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4690
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345560
]
name: aten::view
id: 12584
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4691
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345580
]
name: aten::slice
id: 12585
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4692
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345601
]
name: aten::as_strided
id: 12586
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4693
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345606
]
name: aten::view
id: 12587
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4694
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345640
]
name: aten::transpose
id: 12588
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4695
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345654
]
name: aten::as_strided
id: 12589
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4696
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345659
]
name: aten::transpose
id: 12590
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4697
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345677
]
name: aten::as_strided
id: 12591
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4698
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345681
]
name: aten::transpose
id: 12592
duration_micros: 37
attr: [name: "rf_id"
int64_val: 4699
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345704
]
name: aten::as_strided
id: 12593
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4700
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345708
]
name: aten::baddbmm
id: 12594
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4701
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345765
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 12595
duration_micros: 294
attr: [name: "rf_id"
int64_val: 4701
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123345819
]
name: aten::baddbmm
id: 12596
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4701
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345819
]
name: aten::view
id: 12598
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4702
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345845
]
name: aten::view
id: 12599
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4703
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345845
]
name: ScaledUpperTriangMaskedSoftmax
id: 12600
duration_micros: 62
attr: [name: "rf_id"
int64_val: 4704
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2014
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345903
]
name: aten::empty
id: 12601
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4705
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345916
]
name: aten::to
id: 12602
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4706
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345933
]
name: aten::lift_fresh
id: 12603
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4707
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345943
]
name: aten::detach_
id: 12604
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4708
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345950
]
name: detach_
id: 12605
duration_micros: 2
attr: [name: "rf_id"
int64_val: 4709
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345952
]
name: aten::select
id: 12606
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4710
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345964
]
name: aten::as_strided
id: 12607
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4711
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345970
]
name: aten::item
id: 12608
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4712
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345988
]
name: aten::_local_scalar_dense
id: 12609
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4713
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123345990
]
name: aten::empty
id: 12610
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4714
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346007
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 12611
duration_micros: 425
attr: [name: "rf_id"
int64_val: 4714
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123346040
]
name: aten::empty
id: 12612
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4714
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346040
]
name: aten::view
id: 12614
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4715
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346062
]
name: aten::dropout
id: 12615
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4716
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346123
]
name: aten::view
id: 12616
duration_micros: 41
attr: [name: "rf_id"
int64_val: 4717
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346163
]
name: aten::view
id: 12617
duration_micros: 41
attr: [name: "rf_id"
int64_val: 4718
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346163
]
name: aten::transpose
id: 12618
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4719
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346229
]
name: aten::as_strided
id: 12619
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4720
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346239
]
name: aten::bmm
id: 12620
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4721
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346259
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 12621
duration_micros: 184
attr: [name: "rf_id"
int64_val: 4721
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123346302
]
name: aten::bmm
id: 12622
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4721
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346302
]
name: aten::view
id: 12624
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4722
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346323
]
name: aten::permute
id: 12625
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4723
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346338
]
name: aten::as_strided
id: 12626
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4724
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346344
]
name: aten::contiguous
id: 12627
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4725
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346363
]
name: aten::clone
id: 12628
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4726
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346366
]
name: aten::empty_like
id: 12629
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4727
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346370
]
name: aten::empty
id: 12630
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4728
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346373
]
name: aten::copy_
id: 12631
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4729
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346399
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 12632
duration_micros: 21
attr: [name: "rf_id"
int64_val: 4729
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123346417
]
name: aten::copy_
id: 12633
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4729
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346417
]
name: aten::view
id: 12635
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4730
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346455
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12636
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4731
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2015
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346507
]
name: aten::t
id: 12637
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4732
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346515
]
name: aten::transpose
id: 12638
duration_micros: 43
attr: [name: "rf_id"
int64_val: 4733
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346518
]
name: aten::as_strided
id: 12639
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4734
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346528
]
name: aten::matmul
id: 12640
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4735
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346586
]
name: aten::reshape
id: 12641
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4736
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346591
]
name: aten::view
id: 12642
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4737
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346594
]
name: aten::mm
id: 12643
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4738
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346611
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 12644
duration_micros: 161
attr: [name: "rf_id"
int64_val: 4738
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123346654
]
name: aten::mm
id: 12645
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4738
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346654
]
name: aten::_unsafe_view
id: 12647
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4739
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346671
]
name: _ReduceFromModelParallelRegion
id: 12648
duration_micros: 69
attr: [name: "rf_id"
int64_val: 4740
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2016
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346711
]
name: c10d::allreduce_
id: 12649
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4741
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346745
]
name: record_param_comms
id: 12650
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4742
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346756
]
name: nccl:all_reduce
id: 12651
duration_micros: 9395
attr: [name: "rf_id"
int64_val: 4743
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346772
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 12652
duration_micros: 19142
attr: [name: "rf_id"
int64_val: 4743
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123346789
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 12653
duration_micros: 9395
attr: [name: "rf_id"
int64_val: 4743
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123346789
]
name: record_param_comms
id: 12655
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4744
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365598
]
name: aten::view_as
id: 12656
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4745
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365622
]
name: aten::view
id: 12657
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4746
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365627
]
name: aten::expand_as
id: 12658
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4747
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365669
]
name: aten::expand
id: 12659
duration_micros: 49
attr: [name: "rf_id"
int64_val: 4748
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365674
]
name: aten::as_strided
id: 12660
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4749
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365680
]
name: TorchDynamo Cache Lookup
id: 12661
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4750
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365764
]
name: Torch-Compiled Region
id: 12662
duration_micros: 73
attr: [name: "rf_id"
int64_val: 4751
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365776
]
name: aten::empty
id: 12663
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4752
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365817
]
name: triton_poi_fused_add_0
id: 12664
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4753
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365849
]
name: triton__0d1d2d3d4de
id: 12665
duration_micros: 114
attr: [name: "rf_id"
int64_val: 4753
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123365866
]
name: triton_poi_fused_add_0
id: 12666
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4753
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365866
]
name: FusedLayerNormAffineFunction
id: 12668
duration_micros: 47
attr: [name: "rf_id"
int64_val: 4754
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2017
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365942
]
name: aten::empty_like
id: 12669
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4755
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365954
]
name: aten::empty_strided
id: 12670
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4756
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365961
]
name: aten::empty
id: 12671
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4757
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123365991
]
name: aten::empty_like
id: 12672
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4758
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366007
]
name: aten::empty_strided
id: 12673
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4759
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366011
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 12674
duration_micros: 137
attr: [name: "rf_id"
int64_val: 4759
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123366042
]
name: aten::empty_strided
id: 12675
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4759
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366042
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12677
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4760
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2018
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366105
]
name: aten::t
id: 12678
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4761
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366114
]
name: aten::transpose
id: 12679
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4762
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366117
]
name: aten::as_strided
id: 12680
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4763
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366124
]
name: aten::matmul
id: 12681
duration_micros: 22
attr: [name: "rf_id"
int64_val: 4764
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366152
]
name: aten::reshape
id: 12682
duration_micros: 37
attr: [name: "rf_id"
int64_val: 4765
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366156
]
name: aten::view
id: 12683
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4766
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366159
]
name: aten::mm
id: 12684
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4767
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366209
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 12685
duration_micros: 521
attr: [name: "rf_id"
int64_val: 4767
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123366256
]
name: aten::mm
id: 12686
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4767
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366256
]
name: aten::_unsafe_view
id: 12688
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4768
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366277
]
name: GeLUFunction
id: 12689
duration_micros: 32
attr: [name: "rf_id"
int64_val: 4769
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2019
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366323
]
name: TorchDynamo Cache Lookup
id: 12690
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4770
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366344
]
name: Torch-Compiled Region
id: 12691
duration_micros: 69
attr: [name: "rf_id"
int64_val: 4771
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366354
]
name: aten::empty
id: 12692
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4772
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366392
]
name: triton_poi_fused_add_mul_tanh_0
id: 12693
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4773
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366423
]
name: triton__0d1d2d3de
id: 12694
duration_micros: 43
attr: [name: "rf_id"
int64_val: 4773
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123366438
]
name: triton_poi_fused_add_mul_tanh_0
id: 12695
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4773
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366438
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12697
duration_micros: 62
attr: [name: "rf_id"
int64_val: 4774
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2020
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366514
]
name: aten::t
id: 12698
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4775
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366528
]
name: aten::transpose
id: 12699
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4776
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366532
]
name: aten::as_strided
id: 12700
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4777
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366538
]
name: aten::matmul
id: 12701
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4778
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366568
]
name: aten::reshape
id: 12702
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4779
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366572
]
name: aten::view
id: 12703
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4780
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366575
]
name: aten::mm
id: 12704
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4781
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366591
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 12705
duration_micros: 566
attr: [name: "rf_id"
int64_val: 4781
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123366640
]
name: aten::mm
id: 12706
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4781
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366640
]
name: aten::_unsafe_view
id: 12708
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4782
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366657
]
name: _ReduceFromModelParallelRegion
id: 12709
duration_micros: 2307
attr: [name: "rf_id"
int64_val: 4783
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2021
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366729
]
name: c10d::allreduce_
id: 12710
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4784
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366759
]
name: record_param_comms
id: 12711
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4785
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366771
]
name: nccl:all_reduce
id: 12712
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4786
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366787
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 12713
duration_micros: 593
attr: [name: "rf_id"
int64_val: 4786
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123366805
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 12714
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4786
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366805
]
name: record_param_comms
id: 12716
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4787
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366878
]
name: aten::view_as
id: 12717
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4788
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366900
]
name: aten::view
id: 12718
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4789
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123366905
]
name: aten::expand_as
id: 12719
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4790
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369187
]
name: aten::expand
id: 12720
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4791
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369192
]
name: aten::as_strided
id: 12721
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4792
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369198
]
name: TorchDynamo Cache Lookup
id: 12722
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4793
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369241
]
name: Torch-Compiled Region
id: 12723
duration_micros: 67
attr: [name: "rf_id"
int64_val: 4794
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369252
]
name: aten::empty
id: 12724
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4795
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369290
]
name: triton_poi_fused_add_0
id: 12725
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4796
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369319
]
name: triton__0d1d2d3d4de
id: 12726
duration_micros: 113
attr: [name: "rf_id"
int64_val: 4796
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123369335
]
name: triton_poi_fused_add_0
id: 12727
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4796
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369335
]
name: FusedLayerNormAffineFunction
id: 12729
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4797
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2022
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369441
]
name: aten::empty_like
id: 12730
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4798
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369453
]
name: aten::empty_strided
id: 12731
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4799
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369459
]
name: aten::empty
id: 12732
duration_micros: 44
attr: [name: "rf_id"
int64_val: 4800
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369498
]
name: aten::empty_like
id: 12733
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4801
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369548
]
name: aten::empty_strided
id: 12734
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4802
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369553
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 12735
duration_micros: 135
attr: [name: "rf_id"
int64_val: 4802
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123369591
]
name: aten::empty_strided
id: 12736
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4802
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369591
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12738
duration_micros: 35
attr: [name: "rf_id"
int64_val: 4803
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2023
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369660
]
name: aten::t
id: 12739
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4804
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369669
]
name: aten::transpose
id: 12740
duration_micros: 22
attr: [name: "rf_id"
int64_val: 4805
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369673
]
name: aten::as_strided
id: 12741
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4806
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369682
]
name: aten::matmul
id: 12742
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4807
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369718
]
name: aten::reshape
id: 12743
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4808
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369722
]
name: aten::view
id: 12744
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4809
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369725
]
name: aten::mm
id: 12745
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4810
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369741
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 12746
duration_micros: 400
attr: [name: "rf_id"
int64_val: 4810
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123369785
]
name: aten::mm
id: 12747
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4810
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369785
]
name: aten::_unsafe_view
id: 12749
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4811
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369802
]
name: aten::add
id: 12750
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4812
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369824
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 12751
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4812
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123369845
]
name: aten::add
id: 12752
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4812
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369845
]
name: aten::view
id: 12754
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4813
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369884
]
name: aten::split_with_sizes
id: 12755
duration_micros: 35
attr: [name: "rf_id"
int64_val: 4814
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369909
]
name: aten::as_strided
id: 12756
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4815
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369916
]
name: aten::as_strided
id: 12757
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4816
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369916
]
name: aten::as_strided
id: 12758
duration_micros: 37
attr: [name: "rf_id"
int64_val: 4817
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123369930
]
name: aten::view
id: 12759
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4818
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370010
]
name: aten::reshape
id: 12760
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4819
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370036
]
name: aten::_reshape_alias
id: 12761
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4820
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370043
]
name: aten::view
id: 12762
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4821
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370067
]
name: aten::slice
id: 12763
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4822
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370088
]
name: aten::as_strided
id: 12764
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4823
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370094
]
name: aten::view
id: 12765
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4824
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370119
]
name: aten::transpose
id: 12766
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4825
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370133
]
name: aten::as_strided
id: 12767
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4826
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370138
]
name: aten::transpose
id: 12768
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4827
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370156
]
name: aten::as_strided
id: 12769
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4828
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370160
]
name: aten::transpose
id: 12770
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4829
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370176
]
name: aten::as_strided
id: 12771
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4830
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370180
]
name: aten::baddbmm
id: 12772
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4831
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370235
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 12773
duration_micros: 293
attr: [name: "rf_id"
int64_val: 4831
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123370286
]
name: aten::baddbmm
id: 12774
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4831
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370286
]
name: aten::view
id: 12776
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4832
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370316
]
name: aten::view
id: 12777
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4833
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370316
]
name: ScaledUpperTriangMaskedSoftmax
id: 12778
duration_micros: 65
attr: [name: "rf_id"
int64_val: 4834
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2024
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370370
]
name: aten::empty
id: 12779
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4835
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370383
]
name: aten::to
id: 12780
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4836
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370400
]
name: aten::lift_fresh
id: 12781
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4837
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370410
]
name: aten::detach_
id: 12782
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4838
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370418
]
name: detach_
id: 12783
duration_micros: 3
attr: [name: "rf_id"
int64_val: 4839
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370419
]
name: aten::select
id: 12784
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4840
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370432
]
name: aten::as_strided
id: 12785
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4841
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370437
]
name: aten::item
id: 12786
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4842
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370456
]
name: aten::_local_scalar_dense
id: 12787
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4843
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370458
]
name: aten::empty
id: 12788
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4844
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370474
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 12789
duration_micros: 425
attr: [name: "rf_id"
int64_val: 4844
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123370505
]
name: aten::empty
id: 12790
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4844
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370505
]
name: aten::view
id: 12792
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4845
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370528
]
name: aten::dropout
id: 12793
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4846
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370589
]
name: aten::view
id: 12794
duration_micros: 39
attr: [name: "rf_id"
int64_val: 4847
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370635
]
name: aten::view
id: 12795
duration_micros: 39
attr: [name: "rf_id"
int64_val: 4848
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370635
]
name: aten::transpose
id: 12796
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4849
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370703
]
name: aten::as_strided
id: 12797
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4850
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370709
]
name: aten::bmm
id: 12798
duration_micros: 23
attr: [name: "rf_id"
int64_val: 4851
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370729
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 12799
duration_micros: 184
attr: [name: "rf_id"
int64_val: 4851
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123370764
]
name: aten::bmm
id: 12800
duration_micros: 23
attr: [name: "rf_id"
int64_val: 4851
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370764
]
name: aten::view
id: 12802
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4852
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370785
]
name: aten::permute
id: 12803
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4853
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370800
]
name: aten::as_strided
id: 12804
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4854
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370806
]
name: aten::contiguous
id: 12805
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4855
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370826
]
name: aten::clone
id: 12806
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4856
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370829
]
name: aten::empty_like
id: 12807
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4857
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370833
]
name: aten::empty
id: 12808
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4858
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370837
]
name: aten::copy_
id: 12809
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4859
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370862
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 12810
duration_micros: 21
attr: [name: "rf_id"
int64_val: 4859
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123370880
]
name: aten::copy_
id: 12811
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4859
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370880
]
name: aten::view
id: 12813
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4860
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370924
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12814
duration_micros: 24
attr: [name: "rf_id"
int64_val: 4861
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2025
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370974
]
name: aten::t
id: 12815
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4862
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370982
]
name: aten::transpose
id: 12816
duration_micros: 41
attr: [name: "rf_id"
int64_val: 4863
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370986
]
name: aten::as_strided
id: 12817
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4864
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123370992
]
name: aten::matmul
id: 12818
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4865
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371051
]
name: aten::reshape
id: 12819
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4866
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371056
]
name: aten::view
id: 12820
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4867
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371059
]
name: aten::mm
id: 12821
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4868
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371076
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 12822
duration_micros: 159
attr: [name: "rf_id"
int64_val: 4868
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123371118
]
name: aten::mm
id: 12823
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4868
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371118
]
name: aten::_unsafe_view
id: 12825
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4869
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371136
]
name: _ReduceFromModelParallelRegion
id: 12826
duration_micros: 69
attr: [name: "rf_id"
int64_val: 4870
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2026
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371173
]
name: c10d::allreduce_
id: 12827
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4871
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371207
]
name: record_param_comms
id: 12828
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4872
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371219
]
name: nccl:all_reduce
id: 12829
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4873
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371234
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 12830
duration_micros: 593
attr: [name: "rf_id"
int64_val: 4873
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123371251
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 12831
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4873
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371251
]
name: record_param_comms
id: 12833
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4874
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371321
]
name: aten::view_as
id: 12834
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4875
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371344
]
name: aten::view
id: 12835
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4876
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371348
]
name: aten::expand_as
id: 12836
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4877
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371391
]
name: aten::expand
id: 12837
duration_micros: 44
attr: [name: "rf_id"
int64_val: 4878
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371395
]
name: aten::as_strided
id: 12838
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4879
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371402
]
name: TorchDynamo Cache Lookup
id: 12839
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4880
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371481
]
name: Torch-Compiled Region
id: 12840
duration_micros: 70
attr: [name: "rf_id"
int64_val: 4881
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371493
]
name: aten::empty
id: 12841
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4882
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371533
]
name: triton_poi_fused_add_0
id: 12842
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4883
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371563
]
name: triton__0d1d2d3d4de
id: 12843
duration_micros: 114
attr: [name: "rf_id"
int64_val: 4883
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123371581
]
name: triton_poi_fused_add_0
id: 12844
duration_micros: 17
attr: [name: "rf_id"
int64_val: 4883
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371581
]
name: FusedLayerNormAffineFunction
id: 12846
duration_micros: 48
attr: [name: "rf_id"
int64_val: 4884
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2027
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371657
]
name: aten::empty_like
id: 12847
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4885
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371669
]
name: aten::empty_strided
id: 12848
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4886
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371675
]
name: aten::empty
id: 12849
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4887
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371705
]
name: aten::empty_like
id: 12850
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4888
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371721
]
name: aten::empty_strided
id: 12851
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4889
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371725
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 12852
duration_micros: 136
attr: [name: "rf_id"
int64_val: 4889
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123371756
]
name: aten::empty_strided
id: 12853
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4889
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371756
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12855
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4890
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2028
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371817
]
name: aten::t
id: 12856
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4891
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371826
]
name: aten::transpose
id: 12857
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4892
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371830
]
name: aten::as_strided
id: 12858
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4893
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371839
]
name: aten::matmul
id: 12859
duration_micros: 23
attr: [name: "rf_id"
int64_val: 4894
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371868
]
name: aten::reshape
id: 12860
duration_micros: 39
attr: [name: "rf_id"
int64_val: 4895
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371873
]
name: aten::view
id: 12861
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4896
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371876
]
name: aten::mm
id: 12862
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4897
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371926
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 12863
duration_micros: 522
attr: [name: "rf_id"
int64_val: 4897
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123371973
]
name: aten::mm
id: 12864
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4897
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371973
]
name: aten::_unsafe_view
id: 12866
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4898
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123371993
]
name: GeLUFunction
id: 12867
duration_micros: 32
attr: [name: "rf_id"
int64_val: 4899
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2029
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372038
]
name: TorchDynamo Cache Lookup
id: 12868
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4900
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372059
]
name: Torch-Compiled Region
id: 12869
duration_micros: 65
attr: [name: "rf_id"
int64_val: 4901
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372069
]
name: aten::empty
id: 12870
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4902
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372106
]
name: triton_poi_fused_add_mul_tanh_0
id: 12871
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4903
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372136
]
name: triton__0d1d2d3de
id: 12872
duration_micros: 43
attr: [name: "rf_id"
int64_val: 4903
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123372152
]
name: triton_poi_fused_add_mul_tanh_0
id: 12873
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4903
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372152
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12875
duration_micros: 52
attr: [name: "rf_id"
int64_val: 4904
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2030
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372230
]
name: aten::t
id: 12876
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4905
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372238
]
name: aten::transpose
id: 12877
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4906
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372242
]
name: aten::as_strided
id: 12878
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4907
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372248
]
name: aten::matmul
id: 12879
duration_micros: 19
attr: [name: "rf_id"
int64_val: 4908
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372276
]
name: aten::reshape
id: 12880
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4909
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372280
]
name: aten::view
id: 12881
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4910
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372283
]
name: aten::mm
id: 12882
duration_micros: 31
attr: [name: "rf_id"
int64_val: 4911
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372299
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 12883
duration_micros: 565
attr: [name: "rf_id"
int64_val: 4911
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123372347
]
name: aten::mm
id: 12884
duration_micros: 31
attr: [name: "rf_id"
int64_val: 4911
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372347
]
name: aten::_unsafe_view
id: 12886
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4912
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372368
]
name: _ReduceFromModelParallelRegion
id: 12887
duration_micros: 62
attr: [name: "rf_id"
int64_val: 4913
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2031
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372438
]
name: c10d::allreduce_
id: 12888
duration_micros: 30
attr: [name: "rf_id"
int64_val: 4914
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372466
]
name: record_param_comms
id: 12889
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4915
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372478
]
name: nccl:all_reduce
id: 12890
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4916
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372495
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 12891
duration_micros: 597
attr: [name: "rf_id"
int64_val: 4916
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123372511
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 12892
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4916
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372511
]
name: record_param_comms
id: 12894
duration_micros: 6
attr: [name: "rf_id"
int64_val: 4917
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372583
]
name: aten::view_as
id: 12895
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4918
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372606
]
name: aten::view
id: 12896
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4919
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372611
]
name: aten::expand_as
id: 12897
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4920
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372650
]
name: aten::expand
id: 12898
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4921
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372654
]
name: aten::as_strided
id: 12899
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4922
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372660
]
name: TorchDynamo Cache Lookup
id: 12900
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4923
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372702
]
name: Torch-Compiled Region
id: 12901
duration_micros: 66
attr: [name: "rf_id"
int64_val: 4924
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372714
]
name: aten::empty
id: 12902
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4925
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372751
]
name: triton_poi_fused_add_0
id: 12903
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4926
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372781
]
name: triton__0d1d2d3d4de
id: 12904
duration_micros: 114
attr: [name: "rf_id"
int64_val: 4926
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123372797
]
name: triton_poi_fused_add_0
id: 12905
duration_micros: 15
attr: [name: "rf_id"
int64_val: 4926
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372797
]
name: FusedLayerNormAffineFunction
id: 12907
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4927
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2032
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372902
]
name: aten::empty_like
id: 12908
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4928
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372914
]
name: aten::empty_strided
id: 12909
duration_micros: 22
attr: [name: "rf_id"
int64_val: 4929
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372920
]
name: aten::empty
id: 12910
duration_micros: 44
attr: [name: "rf_id"
int64_val: 4930
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123372954
]
name: aten::empty_like
id: 12911
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4931
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373004
]
name: aten::empty_strided
id: 12912
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4932
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373009
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 12913
duration_micros: 136
attr: [name: "rf_id"
int64_val: 4932
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123373048
]
name: aten::empty_strided
id: 12914
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4932
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373048
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12916
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4933
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2033
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373116
]
name: aten::t
id: 12917
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4934
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373125
]
name: aten::transpose
id: 12918
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4935
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373129
]
name: aten::as_strided
id: 12919
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4936
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373135
]
name: aten::matmul
id: 12920
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4937
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373162
]
name: aten::reshape
id: 12921
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4938
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373167
]
name: aten::view
id: 12922
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4939
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373170
]
name: aten::mm
id: 12923
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4940
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373185
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 12924
duration_micros: 400
attr: [name: "rf_id"
int64_val: 4940
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123373229
]
name: aten::mm
id: 12925
duration_micros: 28
attr: [name: "rf_id"
int64_val: 4940
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373229
]
name: aten::_unsafe_view
id: 12927
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4941
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373247
]
name: aten::add
id: 12928
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4942
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373269
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 12929
duration_micros: 54
attr: [name: "rf_id"
int64_val: 4942
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123373291
]
name: aten::add
id: 12930
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4942
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373291
]
name: aten::view
id: 12932
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4943
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373328
]
name: aten::split_with_sizes
id: 12933
duration_micros: 34
attr: [name: "rf_id"
int64_val: 4944
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373352
]
name: aten::as_strided
id: 12934
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4945
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373359
]
name: aten::as_strided
id: 12935
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4946
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373359
]
name: aten::as_strided
id: 12936
duration_micros: 36
attr: [name: "rf_id"
int64_val: 4947
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373374
]
name: aten::view
id: 12937
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4948
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373452
]
name: aten::reshape
id: 12938
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4949
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373477
]
name: aten::_reshape_alias
id: 12939
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4950
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373485
]
name: aten::view
id: 12940
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4951
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373504
]
name: aten::slice
id: 12941
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4952
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373525
]
name: aten::as_strided
id: 12942
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4953
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373530
]
name: aten::view
id: 12943
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4954
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373555
]
name: aten::transpose
id: 12944
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4955
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373569
]
name: aten::as_strided
id: 12945
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4956
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373574
]
name: aten::transpose
id: 12946
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4957
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373591
]
name: aten::as_strided
id: 12947
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4958
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373596
]
name: aten::transpose
id: 12948
duration_micros: 37
attr: [name: "rf_id"
int64_val: 4959
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373612
]
name: aten::as_strided
id: 12949
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4960
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373619
]
name: aten::baddbmm
id: 12950
duration_micros: 38
attr: [name: "rf_id"
int64_val: 4961
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373684
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 12951
duration_micros: 295
attr: [name: "rf_id"
int64_val: 4961
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123373744
]
name: aten::baddbmm
id: 12952
duration_micros: 38
attr: [name: "rf_id"
int64_val: 4961
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373744
]
name: aten::view
id: 12954
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4962
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373773
]
name: aten::view
id: 12955
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4963
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373773
]
name: ScaledUpperTriangMaskedSoftmax
id: 12956
duration_micros: 63
attr: [name: "rf_id"
int64_val: 4964
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2034
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373829
]
name: aten::empty
id: 12957
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4965
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373841
]
name: aten::to
id: 12958
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4966
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373858
]
name: aten::lift_fresh
id: 12959
duration_micros: 5
attr: [name: "rf_id"
int64_val: 4967
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373868
]
name: aten::detach_
id: 12960
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4968
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373875
]
name: detach_
id: 12961
duration_micros: 2
attr: [name: "rf_id"
int64_val: 4969
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373877
]
name: aten::select
id: 12962
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4970
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373890
]
name: aten::as_strided
id: 12963
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4971
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373895
]
name: aten::item
id: 12964
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4972
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373914
]
name: aten::_local_scalar_dense
id: 12965
duration_micros: 7
attr: [name: "rf_id"
int64_val: 4973
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373916
]
name: aten::empty
id: 12966
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4974
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373932
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 12967
duration_micros: 426
attr: [name: "rf_id"
int64_val: 4974
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123373969
]
name: aten::empty
id: 12968
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4974
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373969
]
name: aten::view
id: 12970
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4975
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123373992
]
name: aten::dropout
id: 12971
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4976
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374061
]
name: aten::view
id: 12972
duration_micros: 40
attr: [name: "rf_id"
int64_val: 4977
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374105
]
name: aten::view
id: 12973
duration_micros: 40
attr: [name: "rf_id"
int64_val: 4978
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374105
]
name: aten::transpose
id: 12974
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4979
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374171
]
name: aten::as_strided
id: 12975
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4980
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374177
]
name: aten::bmm
id: 12976
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4981
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374196
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 12977
duration_micros: 184
attr: [name: "rf_id"
int64_val: 4981
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123374239
]
name: aten::bmm
id: 12978
duration_micros: 27
attr: [name: "rf_id"
int64_val: 4981
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374239
]
name: aten::view
id: 12980
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4982
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374260
]
name: aten::permute
id: 12981
duration_micros: 13
attr: [name: "rf_id"
int64_val: 4983
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374275
]
name: aten::as_strided
id: 12982
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4984
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374281
]
name: aten::contiguous
id: 12983
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4985
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374301
]
name: aten::clone
id: 12984
duration_micros: 18
attr: [name: "rf_id"
int64_val: 4986
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374304
]
name: aten::empty_like
id: 12985
duration_micros: 11
attr: [name: "rf_id"
int64_val: 4987
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374312
]
name: aten::empty
id: 12986
duration_micros: 16
attr: [name: "rf_id"
int64_val: 4988
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374316
]
name: aten::copy_
id: 12987
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4989
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374343
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 12988
duration_micros: 21
attr: [name: "rf_id"
int64_val: 4989
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123374361
]
name: aten::copy_
id: 12989
duration_micros: 14
attr: [name: "rf_id"
int64_val: 4989
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374361
]
name: aten::view
id: 12991
duration_micros: 9
attr: [name: "rf_id"
int64_val: 4990
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374400
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 12992
duration_micros: 25
attr: [name: "rf_id"
int64_val: 4991
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2035
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374450
]
name: aten::t
id: 12993
duration_micros: 12
attr: [name: "rf_id"
int64_val: 4992
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374458
]
name: aten::transpose
id: 12994
duration_micros: 43
attr: [name: "rf_id"
int64_val: 4993
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374462
]
name: aten::as_strided
id: 12995
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4994
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374467
]
name: aten::matmul
id: 12996
duration_micros: 20
attr: [name: "rf_id"
int64_val: 4995
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374530
]
name: aten::reshape
id: 12997
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4996
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374535
]
name: aten::view
id: 12998
duration_micros: 8
attr: [name: "rf_id"
int64_val: 4997
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374538
]
name: aten::mm
id: 12999
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4998
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374554
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 13000
duration_micros: 158
attr: [name: "rf_id"
int64_val: 4998
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123374597
]
name: aten::mm
id: 13001
duration_micros: 26
attr: [name: "rf_id"
int64_val: 4998
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374597
]
name: aten::_unsafe_view
id: 13003
duration_micros: 10
attr: [name: "rf_id"
int64_val: 4999
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374613
]
name: _ReduceFromModelParallelRegion
id: 13004
duration_micros: 59
attr: [name: "rf_id"
int64_val: 5000
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2036
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374653
]
name: c10d::allreduce_
id: 13005
duration_micros: 27
attr: [name: "rf_id"
int64_val: 5001
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374679
]
name: record_param_comms
id: 13006
duration_micros: 27
attr: [name: "rf_id"
int64_val: 5002
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374691
]
name: nccl:all_reduce
id: 13007
duration_micros: 25
attr: [name: "rf_id"
int64_val: 5003
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374709
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 13008
duration_micros: 14018
attr: [name: "rf_id"
int64_val: 5003
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123374726
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 13009
duration_micros: 25
attr: [name: "rf_id"
int64_val: 5003
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374726
]
name: record_param_comms
id: 13011
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5004
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374794
]
name: aten::view_as
id: 13012
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5005
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374816
]
name: aten::view
id: 13013
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5006
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374821
]
name: aten::expand_as
id: 13014
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5007
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374863
]
name: aten::expand
id: 13015
duration_micros: 44
attr: [name: "rf_id"
int64_val: 5008
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374868
]
name: aten::as_strided
id: 13016
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5009
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374874
]
name: TorchDynamo Cache Lookup
id: 13017
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5010
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374952
]
name: Torch-Compiled Region
id: 13018
duration_micros: 70
attr: [name: "rf_id"
int64_val: 5011
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123374964
]
name: aten::empty
id: 13019
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5012
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375004
]
name: triton_poi_fused_add_0
id: 13020
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5013
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375035
]
name: triton__0d1d2d3d4de
id: 13021
duration_micros: 113
attr: [name: "rf_id"
int64_val: 5013
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123375052
]
name: triton_poi_fused_add_0
id: 13022
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5013
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375052
]
name: FusedLayerNormAffineFunction
id: 13024
duration_micros: 47
attr: [name: "rf_id"
int64_val: 5014
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2037
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375128
]
name: aten::empty_like
id: 13025
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5015
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375139
]
name: aten::empty_strided
id: 13026
duration_micros: 18
attr: [name: "rf_id"
int64_val: 5016
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375145
]
name: aten::empty
id: 13027
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5017
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375175
]
name: aten::empty_like
id: 13028
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5018
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375191
]
name: aten::empty_strided
id: 13029
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5019
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375195
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 13030
duration_micros: 139
attr: [name: "rf_id"
int64_val: 5019
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123375230
]
name: aten::empty_strided
id: 13031
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5019
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375230
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 13033
duration_micros: 24
attr: [name: "rf_id"
int64_val: 5020
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2038
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375292
]
name: aten::t
id: 13034
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5021
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375301
]
name: aten::transpose
id: 13035
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5022
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375304
]
name: aten::as_strided
id: 13036
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5023
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375311
]
name: aten::matmul
id: 13037
duration_micros: 22
attr: [name: "rf_id"
int64_val: 5024
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375339
]
name: aten::reshape
id: 13038
duration_micros: 37
attr: [name: "rf_id"
int64_val: 5025
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375343
]
name: aten::view
id: 13039
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5026
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375346
]
name: aten::mm
id: 13040
duration_micros: 30
attr: [name: "rf_id"
int64_val: 5027
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375393
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 13041
duration_micros: 521
attr: [name: "rf_id"
int64_val: 5027
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123375440
]
name: aten::mm
id: 13042
duration_micros: 30
attr: [name: "rf_id"
int64_val: 5027
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375440
]
name: aten::_unsafe_view
id: 13044
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5028
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375460
]
name: GeLUFunction
id: 13045
duration_micros: 31
attr: [name: "rf_id"
int64_val: 5029
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2039
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375506
]
name: TorchDynamo Cache Lookup
id: 13046
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5030
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375526
]
name: Torch-Compiled Region
id: 13047
duration_micros: 68
attr: [name: "rf_id"
int64_val: 5031
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375536
]
name: aten::empty
id: 13048
duration_micros: 18
attr: [name: "rf_id"
int64_val: 5032
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375574
]
name: triton_poi_fused_add_mul_tanh_0
id: 13049
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5033
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375604
]
name: triton__0d1d2d3de
id: 13050
duration_micros: 43
attr: [name: "rf_id"
int64_val: 5033
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123375620
]
name: triton_poi_fused_add_mul_tanh_0
id: 13051
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5033
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375620
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 13053
duration_micros: 53
attr: [name: "rf_id"
int64_val: 5034
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2040
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375697
]
name: aten::t
id: 13054
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5035
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375705
]
name: aten::transpose
id: 13055
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5036
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375709
]
name: aten::as_strided
id: 13056
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5037
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375716
]
name: aten::matmul
id: 13057
duration_micros: 18
attr: [name: "rf_id"
int64_val: 5038
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375748
]
name: aten::reshape
id: 13058
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5039
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375752
]
name: aten::view
id: 13059
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5040
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375755
]
name: aten::mm
id: 13060
duration_micros: 30
attr: [name: "rf_id"
int64_val: 5041
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375770
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 13061
duration_micros: 565
attr: [name: "rf_id"
int64_val: 5041
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123375819
]
name: aten::mm
id: 13062
duration_micros: 30
attr: [name: "rf_id"
int64_val: 5041
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375819
]
name: aten::_unsafe_view
id: 13064
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5042
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375836
]
name: _ReduceFromModelParallelRegion
id: 13065
duration_micros: 68
attr: [name: "rf_id"
int64_val: 5043
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2041
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375904
]
name: c10d::allreduce_
id: 13066
duration_micros: 31
attr: [name: "rf_id"
int64_val: 5044
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375938
]
name: record_param_comms
id: 13067
duration_micros: 25
attr: [name: "rf_id"
int64_val: 5045
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375950
]
name: nccl:all_reduce
id: 13068
duration_micros: 25
attr: [name: "rf_id"
int64_val: 5046
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375966
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 13069
duration_micros: 11023
attr: [name: "rf_id"
int64_val: 5046
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123375983
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 13070
duration_micros: 25
attr: [name: "rf_id"
int64_val: 5046
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123375983
]
name: record_param_comms
id: 13072
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5047
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376056
]
name: aten::view_as
id: 13073
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5048
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376079
]
name: aten::view
id: 13074
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5049
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376083
]
name: aten::expand_as
id: 13075
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5050
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376122
]
name: aten::expand
id: 13076
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5051
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376127
]
name: aten::as_strided
id: 13077
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5052
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376133
]
name: TorchDynamo Cache Lookup
id: 13078
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5053
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376175
]
name: Torch-Compiled Region
id: 13079
duration_micros: 68
attr: [name: "rf_id"
int64_val: 5054
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376186
]
name: aten::empty
id: 13080
duration_micros: 18
attr: [name: "rf_id"
int64_val: 5055
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376224
]
name: triton_poi_fused_add_0
id: 13081
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5056
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376254
]
name: triton__0d1d2d3d4de
id: 13082
duration_micros: 113
attr: [name: "rf_id"
int64_val: 5056
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123376270
]
name: triton_poi_fused_add_0
id: 13083
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5056
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376270
]
name: FusedLayerNormAffineFunction
id: 13085
duration_micros: 53
attr: [name: "rf_id"
int64_val: 5057
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2042
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376375
]
name: aten::empty_like
id: 13086
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5058
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376386
]
name: aten::empty_strided
id: 13087
duration_micros: 21
attr: [name: "rf_id"
int64_val: 5059
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376393
]
name: aten::empty
id: 13088
duration_micros: 45
attr: [name: "rf_id"
int64_val: 5060
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376426
]
name: aten::empty_like
id: 13089
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5061
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376478
]
name: aten::empty_strided
id: 13090
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5062
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376483
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 13091
duration_micros: 134
attr: [name: "rf_id"
int64_val: 5062
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123376522
]
name: aten::empty_strided
id: 13092
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5062
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376522
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 13094
duration_micros: 33
attr: [name: "rf_id"
int64_val: 5063
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2043
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376596
]
name: aten::t
id: 13095
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5064
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376605
]
name: aten::transpose
id: 13096
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5065
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376609
]
name: aten::as_strided
id: 13097
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5066
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376615
]
name: aten::matmul
id: 13098
duration_micros: 24
attr: [name: "rf_id"
int64_val: 5067
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376643
]
name: aten::reshape
id: 13099
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5068
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376648
]
name: aten::view
id: 13100
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5069
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376651
]
name: aten::mm
id: 13101
duration_micros: 28
attr: [name: "rf_id"
int64_val: 5070
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376666
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 13102
duration_micros: 400
attr: [name: "rf_id"
int64_val: 5070
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123376710
]
name: aten::mm
id: 13103
duration_micros: 28
attr: [name: "rf_id"
int64_val: 5070
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376710
]
name: aten::_unsafe_view
id: 13105
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5071
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376732
]
name: aten::add
id: 13106
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5072
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376754
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 13107
duration_micros: 54
attr: [name: "rf_id"
int64_val: 5072
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123376776
]
name: aten::add
id: 13108
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5072
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376776
]
name: aten::view
id: 13110
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5073
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376815
]
name: aten::split_with_sizes
id: 13111
duration_micros: 33
attr: [name: "rf_id"
int64_val: 5074
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376840
]
name: aten::as_strided
id: 13112
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5075
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376847
]
name: aten::as_strided
id: 13113
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5076
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376847
]
name: aten::as_strided
id: 13114
duration_micros: 38
attr: [name: "rf_id"
int64_val: 5077
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376864
]
name: aten::view
id: 13115
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5078
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376941
]
name: aten::reshape
id: 13116
duration_micros: 26581
attr: [name: "rf_id"
int64_val: 5079
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376967
]
name: aten::_reshape_alias
id: 13117
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5080
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123376974
]
name: aten::view
id: 13118
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5081
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403585
]
name: aten::slice
id: 13119
duration_micros: 18
attr: [name: "rf_id"
int64_val: 5082
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403631
]
name: aten::as_strided
id: 13120
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5083
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403639
]
name: aten::view
id: 13121
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5084
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403669
]
name: aten::transpose
id: 13122
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5085
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403686
]
name: aten::as_strided
id: 13123
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5086
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403693
]
name: aten::transpose
id: 13124
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5087
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403717
]
name: aten::as_strided
id: 13125
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5088
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403722
]
name: aten::transpose
id: 13126
duration_micros: 46
attr: [name: "rf_id"
int64_val: 5089
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403738
]
name: aten::as_strided
id: 13127
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5090
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403742
]
name: aten::baddbmm
id: 13128
duration_micros: 51
attr: [name: "rf_id"
int64_val: 5091
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403814
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 13129
duration_micros: 294
attr: [name: "rf_id"
int64_val: 5091
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123403901
]
name: aten::baddbmm
id: 13130
duration_micros: 51
attr: [name: "rf_id"
int64_val: 5091
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403901
]
name: aten::view
id: 13132
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5092
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403931
]
name: aten::view
id: 13133
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5093
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123403931
]
name: ScaledUpperTriangMaskedSoftmax
id: 13134
duration_micros: 84
attr: [name: "rf_id"
int64_val: 5094
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2044
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404014
]
name: aten::empty
id: 13135
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5095
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404034
]
name: aten::to
id: 13136
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5096
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404056
]
name: aten::lift_fresh
id: 13137
duration_micros: 5
attr: [name: "rf_id"
int64_val: 5097
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404068
]
name: aten::detach_
id: 13138
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5098
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404076
]
name: detach_
id: 13139
duration_micros: 3
attr: [name: "rf_id"
int64_val: 5099
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404078
]
name: aten::select
id: 13140
duration_micros: 18
attr: [name: "rf_id"
int64_val: 5100
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404093
]
name: aten::as_strided
id: 13141
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5101
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404104
]
name: aten::item
id: 13142
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5102
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404126
]
name: aten::_local_scalar_dense
id: 13143
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5103
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404128
]
name: aten::empty
id: 13144
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5104
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404146
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 13145
duration_micros: 424
attr: [name: "rf_id"
int64_val: 5104
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123404183
]
name: aten::empty
id: 13146
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5104
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404183
]
name: aten::view
id: 13148
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5105
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404209
]
name: aten::dropout
id: 13149
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5106
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404298
]
name: aten::view
id: 13150
duration_micros: 41
attr: [name: "rf_id"
int64_val: 5107
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404340
]
name: aten::view
id: 13151
duration_micros: 41
attr: [name: "rf_id"
int64_val: 5108
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404340
]
name: aten::transpose
id: 13152
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5109
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404407
]
name: aten::as_strided
id: 13153
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5110
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404413
]
name: aten::bmm
id: 13154
duration_micros: 25
attr: [name: "rf_id"
int64_val: 5111
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404434
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 13155
duration_micros: 183
attr: [name: "rf_id"
int64_val: 5111
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123404473
]
name: aten::bmm
id: 13156
duration_micros: 25
attr: [name: "rf_id"
int64_val: 5111
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404473
]
name: aten::view
id: 13158
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5112
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404494
]
name: aten::permute
id: 13159
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5113
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404514
]
name: aten::as_strided
id: 13160
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5114
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404521
]
name: aten::contiguous
id: 13161
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5115
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404543
]
name: aten::clone
id: 13162
duration_micros: 38
attr: [name: "rf_id"
int64_val: 5116
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404546
]
name: aten::empty_like
id: 13163
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5117
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404551
]
name: aten::empty
id: 13164
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5118
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404555
]
name: aten::copy_
id: 13165
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5119
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404605
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 13166
duration_micros: 20
attr: [name: "rf_id"
int64_val: 5119
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123404627
]
name: aten::copy_
id: 13167
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5119
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404627
]
name: aten::view
id: 13169
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5120
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404671
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 13170
duration_micros: 33
attr: [name: "rf_id"
int64_val: 5121
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2045
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404741
]
name: aten::t
id: 13171
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5122
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404755
]
name: aten::transpose
id: 13172
duration_micros: 41
attr: [name: "rf_id"
int64_val: 5123
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404759
]
name: aten::as_strided
id: 13173
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5124
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404764
]
name: aten::matmul
id: 13174
duration_micros: 22
attr: [name: "rf_id"
int64_val: 5125
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404826
]
name: aten::reshape
id: 13175
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5126
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404833
]
name: aten::view
id: 13176
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5127
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404837
]
name: aten::mm
id: 13177
duration_micros: 30
attr: [name: "rf_id"
int64_val: 5128
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404854
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 13178
duration_micros: 161
attr: [name: "rf_id"
int64_val: 5128
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123404904
]
name: aten::mm
id: 13179
duration_micros: 30
attr: [name: "rf_id"
int64_val: 5128
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404904
]
name: aten::_unsafe_view
id: 13181
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5129
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404921
]
name: _ReduceFromModelParallelRegion
id: 13182
duration_micros: 93
attr: [name: "rf_id"
int64_val: 5130
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2046
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123404961
]
name: c10d::allreduce_
id: 13183
duration_micros: 36
attr: [name: "rf_id"
int64_val: 5131
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405014
]
name: record_param_comms
id: 13184
duration_micros: 29
attr: [name: "rf_id"
int64_val: 5132
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405030
]
name: nccl:all_reduce
id: 13185
duration_micros: 31
attr: [name: "rf_id"
int64_val: 5133
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405049
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 13186
duration_micros: 587
attr: [name: "rf_id"
int64_val: 5133
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123405076
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 13187
duration_micros: 31
attr: [name: "rf_id"
int64_val: 5133
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405076
]
name: record_param_comms
id: 13189
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5134
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405154
]
name: aten::view_as
id: 13190
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5135
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405180
]
name: aten::view
id: 13191
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5136
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405184
]
name: aten::expand_as
id: 13192
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5137
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405234
]
name: aten::expand
id: 13193
duration_micros: 45
attr: [name: "rf_id"
int64_val: 5138
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405240
]
name: aten::as_strided
id: 13194
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5139
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405246
]
name: TorchDynamo Cache Lookup
id: 13195
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5140
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405344
]
name: Torch-Compiled Region
id: 13196
duration_micros: 109
attr: [name: "rf_id"
int64_val: 5141
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405363
]
name: aten::empty
id: 13197
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5142
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405428
]
name: triton_poi_fused_add_0
id: 13198
duration_micros: 22
attr: [name: "rf_id"
int64_val: 5143
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405468
]
name: triton__0d1d2d3d4de
id: 13199
duration_micros: 114
attr: [name: "rf_id"
int64_val: 5143
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123405496
]
name: triton_poi_fused_add_0
id: 13200
duration_micros: 22
attr: [name: "rf_id"
int64_val: 5143
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405496
]
name: FusedLayerNormAffineFunction
id: 13202
duration_micros: 63
attr: [name: "rf_id"
int64_val: 5144
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2047
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405593
]
name: aten::empty_like
id: 13203
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5145
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405608
]
name: aten::empty_strided
id: 13204
duration_micros: 20
attr: [name: "rf_id"
int64_val: 5146
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405615
]
name: aten::empty
id: 13205
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5147
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405647
]
name: aten::empty_like
id: 13206
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5148
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405664
]
name: aten::empty_strided
id: 13207
duration_micros: 5
attr: [name: "rf_id"
int64_val: 5149
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405668
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 13208
duration_micros: 135
attr: [name: "rf_id"
int64_val: 5149
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123405708
]
name: aten::empty_strided
id: 13209
duration_micros: 5
attr: [name: "rf_id"
int64_val: 5149
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405708
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 13211
duration_micros: 26
attr: [name: "rf_id"
int64_val: 5150
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2048
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405784
]
name: aten::t
id: 13212
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5151
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405794
]
name: aten::transpose
id: 13213
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5152
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405797
]
name: aten::as_strided
id: 13214
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5153
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405804
]
name: aten::matmul
id: 13215
duration_micros: 22
attr: [name: "rf_id"
int64_val: 5154
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405833
]
name: aten::reshape
id: 13216
duration_micros: 39
attr: [name: "rf_id"
int64_val: 5155
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405837
]
name: aten::view
id: 13217
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5156
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405840
]
name: aten::mm
id: 13218
duration_micros: 33
attr: [name: "rf_id"
int64_val: 5157
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405889
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 13219
duration_micros: 521
attr: [name: "rf_id"
int64_val: 5157
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123405943
]
name: aten::mm
id: 13220
duration_micros: 33
attr: [name: "rf_id"
int64_val: 5157
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405943
]
name: aten::_unsafe_view
id: 13222
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5158
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123405963
]
name: GeLUFunction
id: 13223
duration_micros: 38
attr: [name: "rf_id"
int64_val: 5159
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2049
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406010
]
name: TorchDynamo Cache Lookup
id: 13224
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5160
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406036
]
name: Torch-Compiled Region
id: 13225
duration_micros: 81
attr: [name: "rf_id"
int64_val: 5161
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406051
]
name: aten::empty
id: 13226
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5162
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406097
]
name: triton_poi_fused_add_mul_tanh_0
id: 13227
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5163
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406131
]
name: triton__0d1d2d3de
id: 13228
duration_micros: 43
attr: [name: "rf_id"
int64_val: 5163
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123406151
]
name: triton_poi_fused_add_mul_tanh_0
id: 13229
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5163
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406151
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 13231
duration_micros: 56
attr: [name: "rf_id"
int64_val: 5164
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2050
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406233
]
name: aten::t
id: 13232
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5165
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406243
]
name: aten::transpose
id: 13233
duration_micros: 23
attr: [name: "rf_id"
int64_val: 5166
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406246
]
name: aten::as_strided
id: 13234
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5167
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406263
]
name: aten::matmul
id: 13235
duration_micros: 18
attr: [name: "rf_id"
int64_val: 5168
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406294
]
name: aten::reshape
id: 13236
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5169
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406298
]
name: aten::view
id: 13237
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5170
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406304
]
name: aten::mm
id: 13238
duration_micros: 32
attr: [name: "rf_id"
int64_val: 5171
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406319
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 13239
duration_micros: 565
attr: [name: "rf_id"
int64_val: 5171
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123406371
]
name: aten::mm
id: 13240
duration_micros: 32
attr: [name: "rf_id"
int64_val: 5171
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406371
]
name: aten::_unsafe_view
id: 13242
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5172
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406389
]
name: _ReduceFromModelParallelRegion
id: 13243
duration_micros: 78
attr: [name: "rf_id"
int64_val: 5173
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2051
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406460
]
name: c10d::allreduce_
id: 13244
duration_micros: 29
attr: [name: "rf_id"
int64_val: 5174
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406502
]
name: record_param_comms
id: 13245
duration_micros: 27
attr: [name: "rf_id"
int64_val: 5175
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406515
]
name: nccl:all_reduce
id: 13246
duration_micros: 29
attr: [name: "rf_id"
int64_val: 5176
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406532
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 13247
duration_micros: 6673
attr: [name: "rf_id"
int64_val: 5176
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123406553
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 13248
duration_micros: 29
attr: [name: "rf_id"
int64_val: 5176
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406553
]
name: record_param_comms
id: 13250
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5177
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406629
]
name: aten::view_as
id: 13251
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5178
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406652
]
name: aten::view
id: 13252
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5179
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406657
]
name: aten::expand_as
id: 13253
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5180
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406700
]
name: aten::expand
id: 13254
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5181
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406706
]
name: aten::as_strided
id: 13255
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5182
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406712
]
name: TorchDynamo Cache Lookup
id: 13256
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5183
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406758
]
name: Torch-Compiled Region
id: 13257
duration_micros: 70
attr: [name: "rf_id"
int64_val: 5184
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406771
]
name: aten::empty
id: 13258
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5185
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406811
]
name: triton_poi_fused_add_0
id: 13259
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5186
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406842
]
name: triton__0d1d2d3d4de
id: 13260
duration_micros: 113
attr: [name: "rf_id"
int64_val: 5186
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123406860
]
name: triton_poi_fused_add_0
id: 13261
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5186
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406860
]
name: FusedLayerNormAffineFunction
id: 13263
duration_micros: 13190
attr: [name: "rf_id"
int64_val: 5187
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2052
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406982
]
name: aten::empty_like
id: 13264
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5188
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123406994
]
name: aten::empty_strided
id: 13265
duration_micros: 22
attr: [name: "rf_id"
int64_val: 5189
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123407001
]
name: aten::empty
id: 13266
duration_micros: 44
attr: [name: "rf_id"
int64_val: 5190
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123407036
]
name: aten::empty_like
id: 13267
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5191
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123407087
]
name: aten::empty_strided
id: 13268
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5192
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123407092
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 13269
duration_micros: 138
attr: [name: "rf_id"
int64_val: 5192
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123407132
]
name: aten::empty_strided
id: 13270
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5192
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123407132
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 13272
duration_micros: 37
attr: [name: "rf_id"
int64_val: 5193
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2053
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420348
]
name: aten::t
id: 13273
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5194
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420358
]
name: aten::transpose
id: 13274
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5195
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420362
]
name: aten::as_strided
id: 13275
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5196
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420368
]
name: aten::matmul
id: 13276
duration_micros: 20
attr: [name: "rf_id"
int64_val: 5197
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420397
]
name: aten::reshape
id: 13277
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5198
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420401
]
name: aten::view
id: 13278
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5199
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420407
]
name: aten::mm
id: 13279
duration_micros: 36
attr: [name: "rf_id"
int64_val: 5200
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420423
]
name: sm80_xmma_gemm_f16f16_f16f32_f32_tn_n_tilesize192x128x32_stage4_warpsize4x2x1_tensor16x8x16_kernel
id: 13280
duration_micros: 399
attr: [name: "rf_id"
int64_val: 5200
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123420484
]
name: aten::mm
id: 13281
duration_micros: 36
attr: [name: "rf_id"
int64_val: 5200
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420484
]
name: aten::_unsafe_view
id: 13283
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5201
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420502
]
name: aten::add
id: 13284
duration_micros: 18
attr: [name: "rf_id"
int64_val: 5202
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420525
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})
id: 13285
duration_micros: 54
attr: [name: "rf_id"
int64_val: 5202
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123420551
]
name: aten::add
id: 13286
duration_micros: 18
attr: [name: "rf_id"
int64_val: 5202
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420551
]
name: aten::view
id: 13288
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5203
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420590
]
name: aten::split_with_sizes
id: 13289
duration_micros: 32
attr: [name: "rf_id"
int64_val: 5204
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::split_with_sizes(Tensor(a -> *) self, SymInt[] split_sizes, int dim=0) -> Tensor(a)[]"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420620
]
name: aten::as_strided
id: 13290
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5205
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420627
]
name: aten::as_strided
id: 13291
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5206
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420627
]
name: aten::as_strided
id: 13292
duration_micros: 38
attr: [name: "rf_id"
int64_val: 5207
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420642
]
name: aten::view
id: 13293
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5208
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420720
]
name: aten::reshape
id: 13294
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5209
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420747
]
name: aten::_reshape_alias
id: 13295
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5210
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_reshape_alias(Tensor(a) self, SymInt[] size, SymInt[] stride) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420757
]
name: aten::view
id: 13296
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5211
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420777
]
name: aten::slice
id: 13297
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5212
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::slice.Tensor(Tensor(a) self, int dim=0, SymInt? start=None, SymInt? end=None, SymInt step=1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420805
]
name: aten::as_strided
id: 13298
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5213
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420811
]
name: aten::view
id: 13299
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5214
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420837
]
name: aten::transpose
id: 13300
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5215
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420850
]
name: aten::as_strided
id: 13301
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5216
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420856
]
name: aten::transpose
id: 13302
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5217
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420873
]
name: aten::as_strided
id: 13303
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5218
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420878
]
name: aten::transpose
id: 13304
duration_micros: 35
attr: [name: "rf_id"
int64_val: 5219
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420894
]
name: aten::as_strided
id: 13305
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5220
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420898
]
name: aten::baddbmm
id: 13306
duration_micros: 35
attr: [name: "rf_id"
int64_val: 5221
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123420953
]
name: ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_tn
id: 13307
duration_micros: 293
attr: [name: "rf_id"
int64_val: 5221
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123421007
]
name: aten::baddbmm
id: 13308
duration_micros: 35
attr: [name: "rf_id"
int64_val: 5221
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::baddbmm(Tensor self, Tensor batch1, Tensor batch2, *, Scalar beta=1, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421007
]
name: aten::view
id: 13310
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5222
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421035
]
name: aten::view
id: 13311
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5223
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421035
]
name: ScaledUpperTriangMaskedSoftmax
id: 13312
duration_micros: 74
attr: [name: "rf_id"
int64_val: 5224
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2054
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421098
]
name: aten::empty
id: 13313
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5225
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421114
]
name: aten::to
id: 13314
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5226
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.device(Tensor(a) self, Device device, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421132
]
name: aten::lift_fresh
id: 13315
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5227
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421143
]
name: aten::detach_
id: 13316
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5228
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::detach_(Tensor(a!) self) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421151
]
name: detach_
id: 13317
duration_micros: 2
attr: [name: "rf_id"
int64_val: 5229
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421153
]
name: aten::select
id: 13318
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5230
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::select.int(Tensor(a) self, int dim, SymInt index) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421167
]
name: aten::as_strided
id: 13319
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5231
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421173
]
name: aten::item
id: 13320
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5232
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421194
]
name: aten::_local_scalar_dense
id: 13321
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5233
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421196
]
name: aten::empty
id: 13322
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5234
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421213
]
name: void (anonymous namespace)::scaled_upper_triang_masked_softmax_warp_forward<c10::Half, c10::Half, float, 11>(c10::Half*, c10::Half const*, float, int, int, int)
id: 13323
duration_micros: 426
attr: [name: "rf_id"
int64_val: 5234
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123421246
]
name: aten::empty
id: 13324
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5234
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421246
]
name: aten::view
id: 13326
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5235
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421269
]
name: aten::dropout
id: 13327
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5236
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::dropout(Tensor input, float p, bool train) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421337
]
name: aten::view
id: 13328
duration_micros: 40
attr: [name: "rf_id"
int64_val: 5237
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421378
]
name: aten::view
id: 13329
duration_micros: 40
attr: [name: "rf_id"
int64_val: 5238
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421378
]
name: aten::transpose
id: 13330
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5239
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421447
]
name: aten::as_strided
id: 13331
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5240
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421452
]
name: aten::bmm
id: 13332
duration_micros: 24
attr: [name: "rf_id"
int64_val: 5241
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421473
]
name: ampere_fp16_s16816gemm_fp16_64x128_sliced1x2_ldg8_f2f_stages_64x3_nn
id: 13333
duration_micros: 183
attr: [name: "rf_id"
int64_val: 5241
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123421510
]
name: aten::bmm
id: 13334
duration_micros: 24
attr: [name: "rf_id"
int64_val: 5241
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bmm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421510
]
name: aten::view
id: 13336
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5242
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421531
]
name: aten::permute
id: 13337
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5243
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::permute(Tensor(a) self, int[] dims) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421546
]
name: aten::as_strided
id: 13338
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5244
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421553
]
name: aten::contiguous
id: 13339
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5245
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421575
]
name: aten::clone
id: 13340
duration_micros: 20
attr: [name: "rf_id"
int64_val: 5246
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421577
]
name: aten::empty_like
id: 13341
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5247
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421588
]
name: aten::empty
id: 13342
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5248
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421592
]
name: aten::copy_
id: 13343
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5249
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421618
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 13344
duration_micros: 21
attr: [name: "rf_id"
int64_val: 5249
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123421637
]
name: aten::copy_
id: 13345
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5249
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421637
]
name: aten::view
id: 13347
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5250
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421678
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 13348
duration_micros: 27
attr: [name: "rf_id"
int64_val: 5251
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2055
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421737
]
name: aten::t
id: 13349
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5252
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421746
]
name: aten::transpose
id: 13350
duration_micros: 46
attr: [name: "rf_id"
int64_val: 5253
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421750
]
name: aten::as_strided
id: 13351
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5254
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421759
]
name: aten::matmul
id: 13352
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5255
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421821
]
name: aten::reshape
id: 13353
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5256
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421826
]
name: aten::view
id: 13354
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5257
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421829
]
name: aten::mm
id: 13355
duration_micros: 28
attr: [name: "rf_id"
int64_val: 5258
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421845
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 13356
duration_micros: 160
attr: [name: "rf_id"
int64_val: 5258
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123421890
]
name: aten::mm
id: 13357
duration_micros: 28
attr: [name: "rf_id"
int64_val: 5258
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421890
]
name: aten::_unsafe_view
id: 13359
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5259
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421906
]
name: _ReduceFromModelParallelRegion
id: 13360
duration_micros: 65
attr: [name: "rf_id"
int64_val: 5260
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2056
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421944
]
name: c10d::allreduce_
id: 13361
duration_micros: 28
attr: [name: "rf_id"
int64_val: 5261
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421975
]
name: record_param_comms
id: 13362
duration_micros: 26
attr: [name: "rf_id"
int64_val: 5262
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123421987
]
name: nccl:all_reduce
id: 13363
duration_micros: 28
attr: [name: "rf_id"
int64_val: 5263
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422003
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 13364
duration_micros: 632
attr: [name: "rf_id"
int64_val: 5263
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123422023
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 13365
duration_micros: 28
attr: [name: "rf_id"
int64_val: 5263
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422023
]
name: record_param_comms
id: 13367
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5264
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422096
]
name: aten::view_as
id: 13368
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5265
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422120
]
name: aten::view
id: 13369
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5266
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422125
]
name: aten::expand_as
id: 13370
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5267
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422169
]
name: aten::expand
id: 13371
duration_micros: 45
attr: [name: "rf_id"
int64_val: 5268
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422174
]
name: aten::as_strided
id: 13372
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5269
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422180
]
name: TorchDynamo Cache Lookup
id: 13373
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5270
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422262
]
name: Torch-Compiled Region
id: 13374
duration_micros: 77
attr: [name: "rf_id"
int64_val: 5271
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422275
]
name: aten::empty
id: 13375
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5272
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422319
]
name: triton_poi_fused_add_0
id: 13376
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5273
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422352
]
name: triton__0d1d2d3d4de
id: 13377
duration_micros: 114
attr: [name: "rf_id"
int64_val: 5273
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123422370
]
name: triton_poi_fused_add_0
id: 13378
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5273
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422370
]
name: FusedLayerNormAffineFunction
id: 13380
duration_micros: 48
attr: [name: "rf_id"
int64_val: 5274
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2057
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422450
]
name: aten::empty_like
id: 13381
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5275
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422462
]
name: aten::empty_strided
id: 13382
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5276
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422468
]
name: aten::empty
id: 13383
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5277
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422499
]
name: aten::empty_like
id: 13384
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5278
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422515
]
name: aten::empty_strided
id: 13385
duration_micros: 5
attr: [name: "rf_id"
int64_val: 5279
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422519
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 13386
duration_micros: 137
attr: [name: "rf_id"
int64_val: 5279
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123422551
]
name: aten::empty_strided
id: 13387
duration_micros: 5
attr: [name: "rf_id"
int64_val: 5279
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422551
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 13389
duration_micros: 24
attr: [name: "rf_id"
int64_val: 5280
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2058
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422617
]
name: aten::t
id: 13390
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5281
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422626
]
name: aten::transpose
id: 13391
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5282
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422630
]
name: aten::as_strided
id: 13392
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5283
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422636
]
name: aten::matmul
id: 13393
duration_micros: 24
attr: [name: "rf_id"
int64_val: 5284
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422664
]
name: aten::reshape
id: 13394
duration_micros: 43
attr: [name: "rf_id"
int64_val: 5285
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422669
]
name: aten::view
id: 13395
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5286
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422675
]
name: aten::mm
id: 13396
duration_micros: 32
attr: [name: "rf_id"
int64_val: 5287
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422727
]
name: ampere_fp16_s16816gemm_fp16_128x128_ldg8_f2f_stages_32x5_tn
id: 13397
duration_micros: 521
attr: [name: "rf_id"
int64_val: 5287
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123422778
]
name: aten::mm
id: 13398
duration_micros: 32
attr: [name: "rf_id"
int64_val: 5287
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422778
]
name: aten::_unsafe_view
id: 13400
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5288
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422798
]
name: GeLUFunction
id: 13401
duration_micros: 35
attr: [name: "rf_id"
int64_val: 5289
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2059
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422845
]
name: TorchDynamo Cache Lookup
id: 13402
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5290
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422868
]
name: Torch-Compiled Region
id: 13403
duration_micros: 99
attr: [name: "rf_id"
int64_val: 5291
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422880
]
name: aten::empty
id: 13404
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5292
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422920
]
name: triton_poi_fused_add_mul_tanh_0
id: 13405
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5293
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422979
]
name: triton__0d1d2d3de
id: 13406
duration_micros: 43
attr: [name: "rf_id"
int64_val: 5293
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123422997
]
name: triton_poi_fused_add_mul_tanh_0
id: 13407
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5293
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123422997
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 13409
duration_micros: 57
attr: [name: "rf_id"
int64_val: 5294
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2060
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423078
]
name: aten::t
id: 13410
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5295
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423087
]
name: aten::transpose
id: 13411
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5296
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423091
]
name: aten::as_strided
id: 13412
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5297
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423097
]
name: aten::matmul
id: 13413
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5298
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423126
]
name: aten::reshape
id: 13414
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5299
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423130
]
name: aten::view
id: 13415
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5300
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423133
]
name: aten::mm
id: 13416
duration_micros: 30
attr: [name: "rf_id"
int64_val: 5301
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423149
]
name: void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_tn_align8::Params)
id: 13417
duration_micros: 566
attr: [name: "rf_id"
int64_val: 5301
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123423199
]
name: aten::mm
id: 13418
duration_micros: 30
attr: [name: "rf_id"
int64_val: 5301
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423199
]
name: aten::_unsafe_view
id: 13420
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5302
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423216
]
name: _ReduceFromModelParallelRegion
id: 13421
duration_micros: 64
attr: [name: "rf_id"
int64_val: 5303
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2061
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423289
]
name: c10d::allreduce_
id: 13422
duration_micros: 28
attr: [name: "rf_id"
int64_val: 5304
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423318
]
name: record_param_comms
id: 13423
duration_micros: 26
attr: [name: "rf_id"
int64_val: 5305
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423330
]
name: nccl:all_reduce
id: 13424
duration_micros: 27
attr: [name: "rf_id"
int64_val: 5306
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423347
]
name: ncclDevKernel_AllReduce_Sum_f16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 13425
duration_micros: 616
attr: [name: "rf_id"
int64_val: 5306
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123423368
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 67108865
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 13426
duration_micros: 27
attr: [name: "rf_id"
int64_val: 5306
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423368
]
name: record_param_comms
id: 13428
duration_micros: 5
attr: [name: "rf_id"
int64_val: 5307
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423438
]
name: aten::view_as
id: 13429
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5308
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423460
]
name: aten::view
id: 13430
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5309
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423465
]
name: aten::expand_as
id: 13431
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5310
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423504
]
name: aten::expand
id: 13432
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5311
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::expand(Tensor(a) self, SymInt[] size, *, bool implicit=False) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423508
]
name: aten::as_strided
id: 13433
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5312
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423515
]
name: TorchDynamo Cache Lookup
id: 13434
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5313
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423557
]
name: Torch-Compiled Region
id: 13435
duration_micros: 68
attr: [name: "rf_id"
int64_val: 5314
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423569
]
name: aten::empty
id: 13436
duration_micros: 18
attr: [name: "rf_id"
int64_val: 5315
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423608
]
name: triton_poi_fused_add_0
id: 13437
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5316
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423637
]
name: triton__0d1d2d3d4de
id: 13438
duration_micros: 114
attr: [name: "rf_id"
int64_val: 5316
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123423654
]
name: triton_poi_fused_add_0
id: 13439
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5316
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423654
]
name: FusedLayerNormAffineFunction
id: 13441
duration_micros: 53
attr: [name: "rf_id"
int64_val: 5317
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2062
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423755
]
name: aten::empty_like
id: 13442
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5318
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423767
]
name: aten::empty_strided
id: 13443
duration_micros: 21
attr: [name: "rf_id"
int64_val: 5319
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423774
]
name: aten::empty
id: 13444
duration_micros: 44
attr: [name: "rf_id"
int64_val: 5320
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423807
]
name: aten::empty_like
id: 13445
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5321
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423857
]
name: aten::empty_strided
id: 13446
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5322
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423862
]
name: void cuApplyLayerNorm<c10::Half, float, c10::Half>(c10::Half*, float*, float*, c10::Half const*, int, int, float, c10::Half const*, c10::Half const*)
id: 13447
duration_micros: 137
attr: [name: "rf_id"
int64_val: 5322
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123423900
]
name: aten::empty_strided
id: 13448
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5322
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423900
]
name: LinearWithGradAccumulationAndAsyncCommunication
id: 13450
duration_micros: 25
attr: [name: "rf_id"
int64_val: 5323
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2063
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423985
]
name: aten::t
id: 13451
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5324
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::t(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123423995
]
name: aten::transpose
id: 13452
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5325
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424003
]
name: aten::as_strided
id: 13453
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5326
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424011
]
name: aten::matmul
id: 13454
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5327
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::matmul(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424040
]
name: aten::reshape
id: 13455
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5328
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424044
]
name: aten::view
id: 13456
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5329
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424047
]
name: aten::mm
id: 13457
duration_micros: 30
attr: [name: "rf_id"
int64_val: 5330
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424063
]
name: ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_tn
id: 13458
duration_micros: 1698
attr: [name: "rf_id"
int64_val: 5330
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123424112
]
name: aten::mm
id: 13459
duration_micros: 30
attr: [name: "rf_id"
int64_val: 5330
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mm(Tensor self, Tensor mat2) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424112
]
name: aten::_unsafe_view
id: 13461
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5331
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_unsafe_view(Tensor self, SymInt[] size) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424130
]
name: aten::transpose
id: 13462
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5332
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::transpose.int(Tensor(a) self, int dim0, int dim1) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424160
]
name: aten::as_strided
id: 13463
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5333
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424166
]
name: aten::contiguous
id: 13464
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5334
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::contiguous(Tensor(a) self, *, MemoryFormat memory_format=0) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424188
]
name: aten::clone
id: 13465
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5335
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424191
]
name: aten::empty_like
id: 13466
duration_micros: 42
attr: [name: "rf_id"
int64_val: 5336
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_like(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424195
]
name: aten::empty
id: 13467
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5337
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424199
]
name: aten::copy_
id: 13468
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5338
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424260
]
name: void at::native::elementwise_kernel<128, 4, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1}>(at::TensorIteratorBase&, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#10}::operator()() const::{lambda(c10::Half)#1} const&)::{lambda(int)#1})
id: 13469
duration_micros: 231
attr: [name: "rf_id"
int64_val: 5338
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123424282
]
name: aten::copy_
id: 13470
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5338
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424282
]
name: aten::to
id: 13472
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5339
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424355
]
name: aten::_to_copy
id: 13473
duration_micros: 21
attr: [name: "rf_id"
int64_val: 5340
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424359
]
name: aten::empty_strided
id: 13474
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5341
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424367
]
name: aten::copy_
id: 13475
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5342
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424390
]
name: void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1> >(int, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1>)
id: 13476
duration_micros: 263
attr: [name: "rf_id"
int64_val: 5342
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123424405
]
name: aten::copy_
id: 13477
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5342
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424405
]
name: aten::to
id: 13479
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5343
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424458
]
name: _VocabParallelCrossEntropy
id: 13480
duration_micros: 421
attr: [name: "rf_id"
int64_val: 5344
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: 2064
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424482
]
name: aten::max
id: 13481
duration_micros: 58
attr: [name: "rf_id"
int64_val: 5345
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::max.dim(Tensor self, int dim, bool keepdim=False) -> (Tensor values, Tensor indices)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424494
]
name: aten::as_strided
id: 13482
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5346
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424514
]
name: aten::as_strided
id: 13483
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5347
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424514
]
name: c10d::allreduce_
id: 13484
duration_micros: 59
attr: [name: "rf_id"
int64_val: 5348
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424603
]
name: record_param_comms
id: 13485
duration_micros: 24
attr: [name: "rf_id"
int64_val: 5349
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424614
]
name: nccl:all_reduce
id: 13486
duration_micros: 23
attr: [name: "rf_id"
int64_val: 5350
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424629
]
name: ncclDevKernel_AllReduce_Sum_f32_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 13487
duration_micros: 13729
attr: [name: "rf_id"
int64_val: 5350
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123424643
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 32769
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 13488
duration_micros: 23
attr: [name: "rf_id"
int64_val: 5350
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424643
]
name: record_param_comms
id: 13490
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5351
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424747
]
name: aten::unsqueeze
id: 13491
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5352
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424771
]
name: aten::as_strided
id: 13492
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5353
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424779
]
name: aten::sub
id: 13493
duration_micros: 24
attr: [name: "rf_id"
int64_val: 5354
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424805
]
name: void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::CUDAFunctor_add<float> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<float> const&)::{lambda(int)#1})
id: 13494
duration_micros: 266
attr: [name: "rf_id"
int64_val: 5354
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123424842
]
name: aten::sub
id: 13495
duration_micros: 24
attr: [name: "rf_id"
int64_val: 5354
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424842
]
name: aten::lt
id: 13497
duration_micros: 18
attr: [name: "rf_id"
int64_val: 5355
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424880
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::compare_scalar_kernel<long>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, long)::{lambda(long)#1}, at::detail::Array<char*, 2> >(int, at::native::compare_scalar_kernel<long>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, long)::{lambda(long)#1}, at::detail::Array<char*, 2>)
id: 13498
duration_micros: 2
attr: [name: "rf_id"
int64_val: 5355
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123424905
]
name: aten::lt
id: 13499
duration_micros: 18
attr: [name: "rf_id"
int64_val: 5355
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lt.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424905
]
name: aten::ge
id: 13501
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5356
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::ge.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424924
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::compare_scalar_kernel<long>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, long)::{lambda(long)#1}, at::detail::Array<char*, 2> >(int, at::native::compare_scalar_kernel<long>(at::TensorIteratorBase&, at::native::(anonymous namespace)::OpType, long)::{lambda(long)#1}, at::detail::Array<char*, 2>)
id: 13502
duration_micros: 2
attr: [name: "rf_id"
int64_val: 5356
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::ge.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123424940
]
name: aten::ge
id: 13503
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5356
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::ge.Scalar(Tensor self, Scalar other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424940
]
name: aten::__or__
id: 13505
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5357
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::__or__.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424956
]
name: aten::bitwise_or
id: 13506
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5358
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bitwise_or.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424960
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<bool, bool, bool, at::native::BitwiseOrFunctor<bool> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<bool, bool, bool, at::native::BitwiseOrFunctor<bool> >, at::detail::Array<char*, 3>)
id: 13507
duration_micros: 1
attr: [name: "rf_id"
int64_val: 5358
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bitwise_or.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123424976
]
name: aten::bitwise_or
id: 13508
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5358
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::bitwise_or.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123424976
]
name: aten::clone
id: 13510
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5359
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123425000
]
name: aten::empty_strided
id: 13511
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5360
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123425006
]
name: aten::copy_
id: 13512
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5361
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123425024
]
name: Memcpy DtoD (Device -> Device)
id: 13513
duration_micros: 2
attr: [name: "rf_id"
int64_val: 5361
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123425043
]
name: aten::copy_
id: 13514
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5361
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123425043
]
name: aten::sub
id: 13516
duration_micros: 11179
attr: [name: "rf_id"
int64_val: 5362
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123425069
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<long>, at::detail::Array<char*, 2>)
id: 13517
duration_micros: 2
attr: [name: "rf_id"
int64_val: 5362
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123447410
]
name: aten::sub
id: 13518
duration_micros: 11179
attr: [name: "rf_id"
int64_val: 5362
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447410
]
name: aten::lift_fresh
id: 13520
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5363
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447444
]
name: aten::index_put_
id: 13521
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5364
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447462
]
name: aten::_index_put_impl_
id: 13522
duration_micros: 51
attr: [name: "rf_id"
int64_val: 5365
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447469
]
name: aten::item
id: 13523
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5366
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447473
]
name: aten::_local_scalar_dense
id: 13524
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5367
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447477
]
name: aten::masked_fill_
id: 13525
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5368
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447491
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long, bool)#1}, at::detail::Array<char*, 3>)
id: 13526
duration_micros: 2
attr: [name: "rf_id"
int64_val: 5368
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123447509
]
name: aten::masked_fill_
id: 13527
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5368
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447509
]
name: aten::view
id: 13529
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5369
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447588
]
name: aten::view
id: 13530
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5370
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447588
]
name: aten::arange
id: 13531
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5371
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::arange.start(Scalar start, Scalar end, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447624
]
name: aten::empty
id: 13532
duration_micros: 16
attr: [name: "rf_id"
int64_val: 5372
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty.memory_format(SymInt[] size, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447628
]
name: aten::arange
id: 13533
duration_micros: 30
attr: [name: "rf_id"
int64_val: 5373
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::arange.start_out(Scalar start, Scalar end, Scalar step=1, *, Tensor(a!) out) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447648
]
name: aten::resize_
id: 13534
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5374
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447653
]
name: void (anonymous namespace)::elementwise_kernel_with_index<int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>(int, at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}, function_traits<at::native::arange_cuda_out(c10::Scalar const&, c10::Scalar const&, c10::Scalar const&, at::Tensor&)::{lambda()#1}::operator()() const::{lambda()#4}::operator()() const::{lambda(long)#1}>::result_type*)
id: 13535
duration_micros: 1
attr: [name: "rf_id"
int64_val: 5374
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123447681
]
name: aten::resize_
id: 13536
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5374
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::resize_(Tensor(a!) self, SymInt[] size, *, MemoryFormat? memory_format=None) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447681
]
name: aten::index
id: 13538
duration_micros: 226
attr: [name: "rf_id"
int64_val: 5375
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::index.Tensor(Tensor self, Tensor?[] indices) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447711
]
name: aten::as_strided
id: 13539
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5376
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447719
]
name: aten::reshape
id: 13540
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5377
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447731
]
name: aten::view
id: 13541
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5378
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447733
]
name: aten::reshape
id: 13542
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5379
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::reshape(Tensor(a) self, SymInt[] shape) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447931
]
name: aten::view
id: 13543
duration_micros: 3
attr: [name: "rf_id"
int64_val: 5380
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447935
]
name: void at::native::index_elementwise_kernel<128, 4, at::native::gpu_index_kernel<at::native::index_kernel_impl<at::native::OpaqueType<4> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_kernel_impl<at::native::OpaqueType<4> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1} const&)::{lambda(int)#1}>(long, at::native::gpu_index_kernel<at::native::index_kernel_impl<at::native::OpaqueType<4> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1}>(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>, at::native::index_kernel_impl<at::native::OpaqueType<4> >(at::TensorIteratorBase&, c10::ArrayRef<long>, c10::ArrayRef<long>)::{lambda(char*, char const*, long)#1} const&)::{lambda(int)#1})
id: 13544
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5380
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123447968
]
name: aten::view
id: 13545
duration_micros: 3
attr: [name: "rf_id"
int64_val: 5380
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447968
]
name: aten::clone
id: 13547
duration_micros: 44
attr: [name: "rf_id"
int64_val: 5381
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::clone(Tensor self, *, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447987
]
name: aten::empty_strided
id: 13548
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5382
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123447993
]
name: aten::copy_
id: 13549
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5383
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448011
]
name: Memcpy DtoD (Device -> Device)
id: 13550
duration_micros: 2
attr: [name: "rf_id"
int64_val: 5383
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123448029
]
name: aten::copy_
id: 13551
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5383
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448029
]
name: aten::view_as
id: 13553
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5384
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view_as(Tensor(a) self, Tensor other) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448087
]
name: aten::view
id: 13554
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5385
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448092
]
name: aten::lift_fresh
id: 13555
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5386
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::lift_fresh(Tensor(a) self) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448118
]
name: aten::index_put_
id: 13556
duration_micros: 12
attr: [name: "rf_id"
int64_val: 5387
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::index_put_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448131
]
name: aten::_index_put_impl_
id: 13557
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5388
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_index_put_impl_(Tensor(a!) self, Tensor?[] indices, Tensor values, bool accumulate=False, bool unsafe=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448136
]
name: aten::item
id: 13558
duration_micros: 6
attr: [name: "rf_id"
int64_val: 5389
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::item(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448140
]
name: aten::_local_scalar_dense
id: 13559
duration_micros: 8
attr: [name: "rf_id"
int64_val: 5390
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_local_scalar_dense(Tensor self) -> Scalar"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448142
]
name: aten::masked_fill_
id: 13560
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5391
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448158
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float, bool)#1}, at::detail::Array<char*, 3> >(int, at::native::(anonymous namespace)::masked_fill_kernel(at::TensorIterator&, c10::Scalar const&)::{lambda()#1}::operator()() const::{lambda()#7}::operator()() const::{lambda(float, bool)#1}, at::detail::Array<char*, 3>)
id: 13561
duration_micros: 2
attr: [name: "rf_id"
int64_val: 5391
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123448176
]
name: aten::masked_fill_
id: 13562
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5391
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::masked_fill_.Scalar(Tensor(a!) self, Tensor mask, Scalar value) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448176
]
name: c10d::allreduce_
id: 13564
duration_micros: 27
attr: [name: "rf_id"
int64_val: 5392
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448232
]
name: record_param_comms
id: 13565
duration_micros: 24
attr: [name: "rf_id"
int64_val: 5393
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448243
]
name: nccl:all_reduce
id: 13566
duration_micros: 23
attr: [name: "rf_id"
int64_val: 5394
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448257
]
name: ncclDevKernel_AllReduce_Sum_f32_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 13567
duration_micros: 24
attr: [name: "rf_id"
int64_val: 5394
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123448271
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 32769
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 13568
duration_micros: 23
attr: [name: "rf_id"
int64_val: 5394
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448271
]
name: record_param_comms
id: 13570
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5395
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448339
]
name: aten::exp
id: 13571
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5396
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::exp.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448361
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::exp_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::exp_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)
id: 13572
duration_micros: 237
attr: [name: "rf_id"
int64_val: 5396
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::exp.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123448379
]
name: aten::exp
id: 13573
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5396
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::exp.out(Tensor self, *, Tensor(a!) out) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448379
]
name: aten::sum
id: 13575
duration_micros: 46
attr: [name: "rf_id"
int64_val: 5397
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448406
]
name: aten::as_strided
id: 13576
duration_micros: 4
attr: [name: "rf_id"
int64_val: 5398
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448422
]
name: void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)
id: 13577
duration_micros: 151
attr: [name: "rf_id"
int64_val: 5398
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123448449
]
name: aten::as_strided
id: 13578
duration_micros: 4
attr: [name: "rf_id"
int64_val: 5398
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448449
]
name: c10d::allreduce_
id: 13580
duration_micros: 29
attr: [name: "rf_id"
int64_val: 5399
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448483
]
name: record_param_comms
id: 13581
duration_micros: 52
attr: [name: "rf_id"
int64_val: 5400
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448494
]
name: nccl:all_reduce
id: 13582
duration_micros: 21
attr: [name: "rf_id"
int64_val: 5401
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448506
]
name: ncclDevKernel_AllReduce_Sum_f32_RING_LL(ncclDevComm*, unsigned long, ncclWork*)
id: 13583
duration_micros: 27
attr: [name: "rf_id"
int64_val: 5401
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123448519
, name: "comm_type"
int64_val: 0
, name: "comm_size"
int64_val: 32769
, name: "involved_dim"
bool_list {
  values: true
}
]
name: nccl:all_reduce
id: 13584
duration_micros: 21
attr: [name: "rf_id"
int64_val: 5401
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448519
]
name: record_param_comms
id: 13586
duration_micros: 7
attr: [name: "rf_id"
int64_val: 5402
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448620
]
name: aten::log
id: 13587
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5403
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::log(Tensor self) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448642
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::log_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2> >(int, at::native::log_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>)
id: 13588
duration_micros: 2
attr: [name: "rf_id"
int64_val: 5403
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::log(Tensor self) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123448666
]
name: aten::log
id: 13589
duration_micros: 17
attr: [name: "rf_id"
int64_val: 5403
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::log(Tensor self) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448666
]
name: aten::sub
id: 13591
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5404
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448683
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)
id: 13592
duration_micros: 2
attr: [name: "rf_id"
int64_val: 5404
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123448699
]
name: aten::sub
id: 13593
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5404
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sub.Tensor(Tensor self, Tensor other, *, Scalar alpha=1) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448699
]
name: aten::unsqueeze
id: 13595
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5405
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::unsqueeze(Tensor(a) self, int dim) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448719
]
name: aten::as_strided
id: 13596
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5406
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448727
]
name: aten::div_
id: 13597
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5407
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::div_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448749
]
name: void at::native::elementwise_kernel<128, 2, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float> > const&)::{lambda(int)#1}>(int, at::native::gpu_kernel_impl_nocast<at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::DivFunctor<float> > const&)::{lambda(int)#1})
id: 13598
duration_micros: 276
attr: [name: "rf_id"
int64_val: 5407
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::div_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123448768
]
name: aten::div_
id: 13599
duration_micros: 14
attr: [name: "rf_id"
int64_val: 5407
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::div_.Tensor(Tensor(a!) self, Tensor other) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448768
]
name: aten::view
id: 13601
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5408
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448817
]
name: aten::view
id: 13602
duration_micros: 9
attr: [name: "rf_id"
int64_val: 5409
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::view(Tensor(a) self, SymInt[] size) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448817
]
name: aten::to
id: 13603
duration_micros: 10
attr: [name: "rf_id"
int64_val: 5410
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::to.dtype(Tensor(a) self, ScalarType dtype, bool non_blocking=False, bool copy=False, MemoryFormat? memory_format=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448842
]
name: aten::_to_copy
id: 13604
duration_micros: 20
attr: [name: "rf_id"
int64_val: 5411
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::_to_copy(Tensor self, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None, bool non_blocking=False, MemoryFormat? memory_format=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448845
]
name: aten::empty_strided
id: 13605
duration_micros: 25
attr: [name: "rf_id"
int64_val: 5412
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::empty_strided(SymInt[] size, SymInt[] stride, *, ScalarType? dtype=None, Layout? layout=None, Device? device=None, bool? pin_memory=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448852
]
name: aten::copy_
id: 13606
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5413
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448881
]
name: void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1> >(int, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1>)
id: 13607
duration_micros: 5
attr: [name: "rf_id"
int64_val: 5413
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123448897
]
name: aten::copy_
id: 13608
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5413
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::copy_(Tensor(a!) self, Tensor src, bool non_blocking=False) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448897
]
name: aten::mul
id: 13610
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5414
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448931
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3> >(int, at::native::BinaryFunctor<float, float, float, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 3>)
id: 13611
duration_micros: 2
attr: [name: "rf_id"
int64_val: 5414
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123448949
]
name: aten::mul
id: 13612
duration_micros: 13
attr: [name: "rf_id"
int64_val: 5414
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::mul.Tensor(Tensor self, Tensor other) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448949
]
name: aten::sum
id: 13614
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5415
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sum(Tensor self, *, ScalarType? dtype=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448966
]
name: aten::sum
id: 13615
duration_micros: 11
attr: [name: "rf_id"
int64_val: 5416
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::sum.dim_IntList(Tensor self, int[1]? dim, bool keepdim=False, *, ScalarType? dtype=None) -> Tensor"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448966
]
name: aten::as_strided
id: 13616
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5417
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123448981
]
name: void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4> >(at::native::ReduceOp<float, at::native::func_wrapper_t<float, at::native::sum_functor<float, float, float>::operator()(at::TensorIterator&)::{lambda(float, float)#1}>, unsigned int, float, 4>)
id: 13617
duration_micros: 4
attr: [name: "rf_id"
int64_val: 5417
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123449038
]
name: aten::as_strided
id: 13618
duration_micros: 19
attr: [name: "rf_id"
int64_val: 5417
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::as_strided(Tensor(a) self, SymInt[] size, SymInt[] stride, SymInt? storage_offset=None) -> Tensor(a)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123449038
]
name: c10d::allreduce_
id: 13620
duration_micros: 26
attr: [name: "rf_id"
int64_val: 5418
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "c10d::allreduce_(Tensor[] tensors, __torch__.torch.classes.c10d.ProcessGroup process_group, __torch__.torch.classes.c10d.ReduceOp reduce_op, Tensor? sparse_indices, int timeout) -> (Tensor[], __torch__.torch.classes.c10d.Work)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123449111
]
name: record_param_comms
id: 13621
duration_micros: 21
attr: [name: "rf_id"
int64_val: 5419
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123449123
]
name: nccl:all_reduce
id: 13622
duration_micros: 24
attr: [name: "rf_id"
int64_val: 5420
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 7
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123449136
]
name: record_param_comms
id: 13623
duration_micros: 5
attr: [name: "rf_id"
int64_val: 5421
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: ""
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123449192
]
name: aten::add_
id: 13624
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5422
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123449212
]
name: void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3> >(int, at::native::CUDAFunctor_add<float>, at::detail::Array<char*, 3>)
id: 13625
duration_micros: 1
attr: [name: "rf_id"
int64_val: 5422
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 0
, name: "ts"
int64_val: 1706850123449231
]
name: aten::add_
id: 13626
duration_micros: 15
attr: [name: "rf_id"
int64_val: 5422
, name: "fw_parent"
int64_val: 0
, name: "seq_id"
int64_val: -1
, name: "scope"
int64_val: 0
, name: "tid"
int64_val: 1
, name: "fw_tid"
int64_val: 0
, name: "op_schema"
string_val: "aten::add_.Tensor(Tensor(a!) self, Tensor other, *, Scalar alpha=1) -> Tensor(a!)"
, name: "is_cpu_op"
int32_val: 1
, name: "ts"
int64_val: 1706850123449231
]
num_total_node = 6813
num_cudnn_convolution = 0
num_matmul = 161
num_mm = 322
